# ============================================================
# OpenCode Platform - Environment Configuration
# ============================================================
# Usage: copy this file to .env and fill in your values
# Version: 2.0 (Enhanced with Deep Research Features)
# Last Updated: 2026-02-12
# ============================================================

# ------------------------------------------------------------
# LLM Providers (Multi-Provider Support with Fallback)
# ------------------------------------------------------------

# Primary LLM Provider - OpenAI
OPENAI_API_KEY=sk-your-openai-api-key-here

# Model Selection Guide:
# - GPT-4 series (gpt-4, gpt-4o, gpt-4o-mini): Full features, configurable temperature
# - GPT-5 series (gpt-5, gpt-5.1, gpt-5-mini): Latest models, temperature=1.0 only
# Note: GPT-5 models use max_completion_tokens instead of max_tokens
LLM_MODEL=gpt-4o  # or gpt-5.1 for latest model
PLANNER_MODEL=gpt-4o-mini  # or gpt-5-mini for latest model

OPENAI_TIMEOUT=30
OPENAI_MAX_RETRIES=2

# GPT-5 Specific Settings (if using GPT-5 models)
# GPT5_TEMPERATURE=1.0  # GPT-5 only supports default temperature
# GPT5_MAX_COMPLETION_TOKENS=4096  # Maximum tokens for GPT-5 responses

# Secondary LLM Provider - Anthropic Claude (Fallback)
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
# ANTHROPIC_MODEL=claude-3-opus-20240229
# ANTHROPIC_TIMEOUT=30

# Tertiary LLM Provider - Google Gemini (Second Fallback)
# GEMINI_API_KEY=your-google-api-key-here
# GEMINI_MODEL=gemini-2.0-flash-exp
# GEMINI_TIMEOUT=30

# DeepSeek (Optional - for specialized tasks)
# DEEPSEEK_API_KEY=your-deepseek-api-key-here
# DEEPSEEK_MODEL=deepseek-chat

# LLM Fallback Chain Configuration
LLM_FALLBACK_CHAIN=openai,anthropic,gemini
LLM_RETRY_DELAY=1.0
LLM_EXPONENTIAL_BACKOFF=true

# ------------------------------------------------------------
# Embedding Providers
# ------------------------------------------------------------

# Cohere (Recommended - Multilingual + Reranking)
COHERE_API_KEY=your-cohere-api-key-here
EMBEDDING_PROVIDER=cohere
COHERE_EMBED_MODEL=embed-multilingual-v3.0
COHERE_RERANK_MODEL=rerank-multilingual-v3.0

# OpenAI Embeddings (Fallback)
OPENAI_EMBED_MODEL=text-embedding-3-small
EMBEDDING_DIMENSION=1536

# ------------------------------------------------------------
# Web Search Providers (Multi-Engine Support)
# ------------------------------------------------------------

# Primary Search Engine - Tavily (AI-Optimized)
# TAVILY_API_KEY=tvly-your-tavily-api-key-here
# TAVILY_MAX_RESULTS=10
# TAVILY_SEARCH_DEPTH=advanced

# Secondary - Serper (Google Search API)
# SERPER_API_KEY=your-serper-api-key-here
# SERPER_MAX_RESULTS=10

# Tertiary - Brave Search
# BRAVE_API_KEY=your-brave-api-key-here
# BRAVE_MAX_RESULTS=10

# Additional Search Providers
# EXA_API_KEY=your-exa-api-key-here
# EXA_SEARCH_TYPE=auto  # auto, fast, neural
# EXA_MAX_RESULTS=10
# EXA_CONTENT_TYPE=text  # text, highlights
# EXA_MAX_CHARACTERS=20000
# SEARXNG_URL=http://localhost:8888  # Self-hosted option

# Search Configuration
SEARCH_PRIMARY_PROVIDER=tavily
SEARCH_FALLBACK_CHAIN=exa,serper,brave,duckduckgo
SEARCH_PARALLEL_LIMIT=3
SEARCH_TIMEOUT=10
SEARCH_MAX_RESULTS=10

# Parallel Search Strategy Configuration
SEARCH_PARALLEL_STRATEGY=hybrid  # batch | race | hybrid
SEARCH_BATCH_SIZE=3  # Number of queries to process in parallel
SEARCH_ENABLE_RACE_MODE=false  # All providers compete per query
SEARCH_ENABLE_BATCH_PARALLEL=true  # Process multiple queries simultaneously

# ------------------------------------------------------------
# Vector Database - Qdrant
# ------------------------------------------------------------

QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=rag_knowledge_base
QDRANT_VECTOR_SIZE=1536
QDRANT_DISTANCE_METRIC=cosine

# Qdrant Cloud (Optional)
# QDRANT_CLOUD_URL=https://your-cluster.qdrant.io
# QDRANT_API_KEY=your-qdrant-api-key

# ------------------------------------------------------------
# Deep Research Configuration
# ------------------------------------------------------------

# Research Mode Settings
DEEP_RESEARCH_ENABLED=true
DEEP_RESEARCH_MAX_ITERATIONS=3
DEEP_RESEARCH_ITERATION_THRESHOLD=0.8
DEEP_RESEARCH_ENABLE_CITATIONS=true
DEEP_RESEARCH_CITATION_STYLE=academic  # academic, numbered, inline

# Deep Research Parallel Search
DEEP_RESEARCH_PARALLEL_SEARCHES=3  # Number of search tasks to run in parallel
DEEP_RESEARCH_RACE_MODE=false  # Enable race mode for each search task
DEEP_RESEARCH_BATCH_MODE=true  # Enable batch parallel for multiple queries

# Deep Research Search Budget Model ("少量多次，迭代收斂")
DEEP_RESEARCH_QUERIES_FIRST_ITERATION=8   # Iteration 1: broad coverage queries
DEEP_RESEARCH_QUERIES_FOLLOWUP_ITERATION=5  # Iteration 2+: targeted gap-fill
DEEP_RESEARCH_MAX_TOTAL_QUERIES=20        # Hard ceiling across all iterations
DEEP_RESEARCH_URLS_PER_QUERY=3            # Full-page content fetches per query

# SSE Streaming
SSE_ENABLED=true
SSE_HEARTBEAT_INTERVAL=30
SSE_MAX_CONNECTIONS=100

# Event System
EVENT_QUEUE_SIZE=1000
EVENT_CALLBACK_TIMEOUT=5

# ------------------------------------------------------------
# Processing Modes & Cognitive Architecture
# ------------------------------------------------------------

# System 1 (Fast, Cached)
SYSTEM1_CACHE_ENABLED=true
SYSTEM1_CACHE_TTL=300
SYSTEM1_CACHE_MAX_SIZE=1000

# System 2 (Analytical)
SYSTEM2_MAX_STEPS=10
SYSTEM2_TIMEOUT=60

# Agent Level (Stateful)
AGENT_WORKFLOW_TRACKING=true
AGENT_MAX_RETRIES=2
AGENT_RETRY_DELAY=1.0
AGENT_ERROR_CLASSIFICATION=true

# ------------------------------------------------------------
# Authentication & Security
# ------------------------------------------------------------

# JWT Configuration
JWT_SECRET_KEY=opencode-super-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=1440
JWT_REFRESH_EXPIRE_DAYS=7

# Default Admin (Change in production!)
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin123
ADMIN_EMAIL=admin@opencode.local

# API Keys for External Access
# API_KEY_ENABLED=true
# API_KEY_HEADER=X-API-Key
# API_KEYS=key1,key2,key3  # Comma-separated list

# ------------------------------------------------------------
# Server Configuration
# ------------------------------------------------------------

# API Server
API_HOST=0.0.0.0
API_PORT=8888
API_WORKERS=4
API_RELOAD=false

# CORS Settings
CORS_ENABLED=true
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
CORS_ALLOW_CREDENTIALS=true

# Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_PERIOD=60

# ------------------------------------------------------------
# Caching & Performance
# ------------------------------------------------------------

# Redis (Distributed Cache - Optional)
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_DB=0
# REDIS_PASSWORD=
# REDIS_CACHE_TTL=300

# Local Cache (Fallback when Redis unavailable)
LOCAL_CACHE_ENABLED=true
LOCAL_CACHE_MAX_SIZE=1000
LOCAL_CACHE_TTL=300

# Response Cache
RESPONSE_CACHE_ENABLED=true
RESPONSE_CACHE_TTL=300
RESPONSE_CACHE_KEY_PREFIX=opencode:cache:

# ------------------------------------------------------------
# Sandbox Execution (Code Mode)
# ------------------------------------------------------------

# Docker Sandbox
SANDBOX_ENABLED=false
SANDBOX_IMAGE=python:3.11-slim
SANDBOX_TIMEOUT=30
SANDBOX_MEMORY_LIMIT=512m
SANDBOX_CPU_LIMIT=0.5

# Sandbox Security
SANDBOX_NETWORK_ENABLED=false
SANDBOX_VOLUME_MOUNTS=

# ------------------------------------------------------------
# Monitoring & Observability
# ------------------------------------------------------------

# Logging
DEBUG=false
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE_PATH=logs/opencode.log
LOG_ROTATION=daily
LOG_RETENTION_DAYS=30

# Metrics
METRICS_ENABLED=true
METRICS_PORT=9090
METRICS_PATH=/metrics

# Tracing (OpenTelemetry)
# OTEL_ENABLED=true
# OTEL_ENDPOINT=http://localhost:4317
# OTEL_SERVICE_NAME=opencode-backend

# Error Tracking (Sentry)
# SENTRY_DSN=https://your-key@sentry.io/project-id
# SENTRY_ENVIRONMENT=production
# SENTRY_TRACES_SAMPLE_RATE=0.1

# ------------------------------------------------------------
# Cost Management
# ------------------------------------------------------------

# Budget Limits
DAILY_TOKEN_LIMIT=1000000
DAILY_COST_LIMIT=10.0
MONTHLY_COST_LIMIT=100.0

# Cost Tracking
TRACK_TOKEN_USAGE=true
TRACK_API_COSTS=true
COST_ALERT_THRESHOLD=0.8

# Token Pricing (USD per 1K tokens)
OPENAI_INPUT_PRICE=0.003
OPENAI_OUTPUT_PRICE=0.006
ANTHROPIC_INPUT_PRICE=0.003
ANTHROPIC_OUTPUT_PRICE=0.015
GEMINI_INPUT_PRICE=0.00025
GEMINI_OUTPUT_PRICE=0.0005

# ------------------------------------------------------------
# Feature Flags
# ------------------------------------------------------------

# Processing Modes
ENABLE_CHAT_MODE=true
ENABLE_KNOWLEDGE_MODE=true
ENABLE_SEARCH_MODE=true
ENABLE_CODE_MODE=true
ENABLE_THINKING_MODE=true
ENABLE_DEEP_RESEARCH_MODE=true
ENABLE_KNOWLEDGE_GRAPH_MODE=false
ENABLE_REWRITING_MODE=false

# Advanced Features
ENABLE_MULTI_AGENT=false
ENABLE_FUNCTION_CALLING=false
ENABLE_VISION_PROCESSING=false
ENABLE_VOICE_PROCESSING=false

# Experimental Features
ENABLE_EXPERIMENTAL_FEATURES=false
ENABLE_BETA_FEATURES=false

# ------------------------------------------------------------
# Database (Future)
# ------------------------------------------------------------

# PostgreSQL (for persistent storage)
# DATABASE_URL=postgresql://user:password@localhost:5432/opencode
# DATABASE_POOL_SIZE=10
# DATABASE_MAX_OVERFLOW=20

# ------------------------------------------------------------
# External Integrations (Optional)
# ------------------------------------------------------------

# Slack Integration
# SLACK_BOT_TOKEN=xoxb-your-bot-token
# SLACK_APP_TOKEN=xapp-your-app-token

# Discord Integration
# DISCORD_BOT_TOKEN=your-discord-bot-token

# Webhook Notifications
# WEBHOOK_URL=https://your-webhook-endpoint.com
# WEBHOOK_SECRET=your-webhook-secret

# ------------------------------------------------------------
# Development & Testing
# ------------------------------------------------------------

# Test Mode
TEST_MODE=false
TEST_LLM_MOCK=false
TEST_SEARCH_MOCK=false

# Development Settings
DEV_MODE=false
DEV_HOT_RELOAD=true
DEV_VERBOSE_ERRORS=true

# ------------------------------------------------------------
# END OF CONFIGURATION
# ------------------------------------------------------------
# Note: Uncomment and fill in the values you need.
# Required minimum: OPENAI_API_KEY or ANTHROPIC_API_KEY
# Recommended: Add search API (Tavily/Serper) for better results
# ------------------------------------------------------------