"""
Thinking Processor - Deep multi-stage reasoning

Conducts deep analysis through problem decomposition, critical thinking,
chain of thought reasoning, and synthesis.
Extracted from monolithic processor.py
"""

from .base import BaseProcessor
from ..models import ProcessingContext
from ..prompts import PromptTemplates
from ..logger import LogCategory
from ..error_handler import enhanced_error_handler


class ThinkingProcessor(BaseProcessor):
    """æ·±åº¦æ€è€ƒè™•ç†å™¨"""

    @enhanced_error_handler(max_retries=1, retryable_categories=["LLM"])
    async def process(self, context: ProcessingContext) -> str:
        self.logger.progress("deep-thinking", "start")
        context.set_current_step("deep-thinking")

        # è¨˜éŒ„æ€è€ƒæ±ºç­–
        await self._log_tool_decision(
            "deep_thinking",
            "è¤‡é›œå•é¡Œéœ€è¦æ·±åº¦åˆ†æå’Œæ¨ç†",
            0.95
        )

        # è¨˜éŒ„æ€è€ƒè¨ˆåŠƒ
        self.logger.info(
            f"ğŸ§  Deep Thinking: Analyzing '{context.request.query[:50]}...'",
            "thinking",
            "start",
            category=LogCategory.TOOL,
            approach="multi-perspective-reasoning"
        )

        # Step 1: Problem decomposition and understanding
        self.logger.progress("problem-analysis", "start")
        self.logger.reasoning("Decomposing and understanding core elements...", streaming=True)

        # è¨˜éŒ„éšæ®µé–‹å§‹ (åªåœ¨æ—¥èªŒä¸­é¡¯ç¤º)
        self.logger.info(
            f"ğŸ” Stage 1: Problem Understanding & Decomposition",
            "thinking",
            "stage1",
            query=context.request.query[:100]
        )

        # ä½¿ç”¨æ€è€ƒæ¨¡å¼çš„å°ˆæ¥­æç¤ºè©
        thinking_prompt = PromptTemplates.get_thinking_mode_prompt(context.request.query)

        # åŸ·è¡Œæ·±åº¦æ€è€ƒ
        thinking_response = await self._call_llm(thinking_prompt, context)

        # å°‡çµæœè¼¸å‡ºåˆ°æ—¥èªŒ (ä¸æ˜¯ message)
        self.logger.info(
            f"ğŸ’­ Stage 1 Result: {thinking_response[:500]}...",
            "thinking",
            "stage1_result",
            full_length=len(thinking_response)
        )

        # è¨˜éŒ„éšæ®µå®Œæˆ
        self.logger.info(
            f"âœ… Stage 1: Problem Analysis Complete",
            "thinking",
            "stage1_complete",
            response_length=len(thinking_response)
        )

        self.logger.progress("problem-analysis", "end", {"analyzed": True})

        # Step 2: Multi-perspective analysis
        self.logger.progress("multi-perspective", "start")
        self.logger.reasoning("Analyzing from multiple perspectives...", streaming=True)

        # è¨˜éŒ„ç¬¬äºŒéšæ®µé–‹å§‹ (åªåœ¨æ—¥èªŒä¸­é¡¯ç¤º)
        self.logger.info(
            f"ğŸ” Stage 2: Critical Multi-Perspective Analysis",
            "thinking",
            "stage2"
        )

        # ä½¿ç”¨æ‰¹åˆ¤æ€§æ€ç¶­æç¤ºè©
        critical_prompt = PromptTemplates.get_critical_thinking_prompt(
            question=context.request.query,
            context=thinking_response
        )

        critical_analysis = await self._call_llm(critical_prompt, context)

        # å°‡çµæœè¼¸å‡ºåˆ°æ—¥èªŒ (ä¸æ˜¯ message)
        self.logger.info(
            f"ğŸ’­ Stage 2 Result: {critical_analysis[:500]}...",
            "thinking",
            "stage2_result",
            full_length=len(critical_analysis)
        )

        self.logger.progress("multi-perspective", "end", {"perspectives": 5})

        # Step 3: Deep reasoning
        self.logger.progress("deep-reasoning", "start")
        self.logger.reasoning("Conducting deep reasoning and logical analysis...", streaming=True)

        # è¨˜éŒ„ç¬¬ä¸‰éšæ®µé–‹å§‹ (åªåœ¨æ—¥èªŒä¸­é¡¯ç¤º)
        self.logger.info(
            f"ğŸ” Stage 3: Chain of Deep Reasoning",
            "thinking",
            "stage3"
        )

        # ä½¿ç”¨æ¨ç†éˆæç¤ºè©
        reasoning_prompt = PromptTemplates.get_chain_of_thought_prompt(context.request.query)

        chain_reasoning = await self._call_llm(reasoning_prompt, context)

        # å°‡çµæœè¼¸å‡ºåˆ°æ—¥èªŒ (ä¸æ˜¯ message)
        self.logger.info(
            f"ğŸ’­ Stage 3 Result: {chain_reasoning[:500]}...",
            "thinking",
            "stage3_result",
            full_length=len(chain_reasoning)
        )

        self.logger.progress("deep-reasoning", "end")

        # Step 4: Synthesis and reflection
        self.logger.progress("synthesis-reflection", "start")
        self.logger.reasoning("Synthesizing all analysis and reflecting...", streaming=True)

        # è¨˜éŒ„ç¬¬å››éšæ®µé–‹å§‹ (åªåœ¨æ—¥èªŒä¸­é¡¯ç¤º)
        self.logger.info(
            f"ğŸ” Stage 4: Synthesis & Reflection",
            "thinking",
            "stage4"
        )

        # ä½¿ç”¨åæ€æç¤ºè©
        reflection_prompt = PromptTemplates.get_reflection_prompt(
            original_response=f"{thinking_response}\n\n{critical_analysis}\n\n{chain_reasoning}",
            question=context.request.query
        )

        reflection = await self._call_llm(reflection_prompt, context)

        # å°‡çµæœè¼¸å‡ºåˆ°æ—¥èªŒ (ä¸æ˜¯ message)
        self.logger.info(
            f"ğŸ’­ Stage 4 Result: {reflection[:500]}...",
            "thinking",
            "stage4_result",
            full_length=len(reflection)
        )

        self.logger.progress("synthesis-reflection", "end")

        # Step 5: Final answer generation
        self.logger.progress("final-synthesis", "start")

        # è¨˜éŒ„æœ€çµ‚éšæ®µé–‹å§‹ (åªåœ¨æ—¥èªŒä¸­é¡¯ç¤º)
        self.logger.info(
            f"ğŸ¯ Stage 5: Final Comprehensive Answer",
            "thinking",
            "stage5"
        )

        # æº–å‚™æœ€çµ‚ç­”æ¡ˆæç¤ºè©
        final_synthesis_prompt = f"""
Based on the following deep thinking process, provide a comprehensive final answer to the question: "{context.request.query}"

Thinking Process Summary:
1. Problem Understanding: {thinking_response[:200]}...
2. Critical Analysis: {critical_analysis[:200]}...
3. Chain of Reasoning: {chain_reasoning[:200]}...
4. Reflection: {reflection[:200]}...

Please provide a complete, well-structured answer that synthesizes all insights from the above analysis.
"""

        # ä½¿ç”¨è¼¸å‡ºæŒ‡å—ç¢ºä¿ç­”æ¡ˆå“è³ª
        output_guidelines = PromptTemplates.get_output_guidelines()
        final_prompt = f"{final_synthesis_prompt}\n\n{output_guidelines}"

        final_response = await self._call_llm(final_prompt, context)

        # åªè¼¸å‡ºæœ€çµ‚ç­”æ¡ˆä½œç‚ºå›æ‡‰
        self.logger.message(final_response)

        self.logger.progress("final-synthesis", "end")

        context.mark_step_complete("deep-thinking")
        self.logger.progress("deep-thinking", "end")

        # åªè¿”å›æœ€çµ‚ç­”æ¡ˆ
        return final_response
