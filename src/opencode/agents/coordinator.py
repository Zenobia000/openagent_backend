"""
Agent å”èª¿å™¨

è² è²¬ï¼š
1. ç®¡ç†æ‰€æœ‰ Agent
2. å”èª¿ä»»å‹™åŸ·è¡Œæµç¨‹
3. å‚³éä¸Šä¸‹æ–‡
4. èšåˆçµæœ
"""

import logging
import asyncio
from typing import Dict, List, Any, Optional, AsyncGenerator
from dataclasses import dataclass, field
from datetime import datetime
import uuid

from .base import BaseAgent, AgentType, AgentTask, AgentResult
from .dispatcher import DispatcherAgent
from .specialists import (
    ResearcherAgent, 
    WriterAgent, 
    CoderAgent, 
    AnalystAgent, 
    ReviewerAgent
)

logger = logging.getLogger(__name__)


class PluginAgentWrapper:
    """
    æ’ä»¶ Agent åŒ…è£å™¨
    
    å°‡æ’ä»¶ Agent åŒ…è£æˆèˆ‡å…§å»º Agent ç›¸åŒçš„ä»‹é¢
    """
    
    def __init__(self, plugin):
        self.plugin = plugin
        self.type = AgentType.REVIEWER  # ä½¿ç”¨é€šç”¨é¡å‹
        self._custom_type = plugin.agent_name
    
    @property
    def name(self) -> str:
        return self.plugin.agent_name
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "type": self._custom_type,
            "name": self.plugin.metadata.name,
            "description": self.plugin.agent_description,
            "status": "active",
            "is_plugin": True,
            "plugin_id": self.plugin.metadata.id
        }
    
    async def initialize(self) -> bool:
        return True
    
    async def process_task(self, task: AgentTask) -> AgentResult:
        """åŸ·è¡Œä»»å‹™"""
        import time
        start_time = time.time()
        
        try:
            result = await self.plugin.process_task(
                task_description=task.description,
                parameters=task.parameters,
                context=task.context
            )
            
            return AgentResult(
                task_id=task.id,
                agent_type=self._custom_type,
                success=result.get("success", False),
                output=result.get("output", {}),
                tool_calls=[],
                thinking=f"Plugin agent: {self.name}",
                execution_time=time.time() - start_time,
                error=result.get("error")
            )
            
        except Exception as e:
            logger.error(f"Plugin agent {self.name} error: {e}")
            return AgentResult(
                task_id=task.id,
                agent_type=self._custom_type,
                success=False,
                output={},
                tool_calls=[],
                thinking="",
                execution_time=time.time() - start_time,
                error=str(e)
            )


@dataclass
class WorkflowStep:
    """å·¥ä½œæµç¨‹æ­¥é©Ÿ"""
    step_id: str
    agent_type: str
    task: AgentTask
    status: str = "pending"  # pending, running, completed, failed
    result: Optional[AgentResult] = None
    depends_on: List[str] = field(default_factory=list)


@dataclass
class WorkflowExecution:
    """å·¥ä½œæµç¨‹åŸ·è¡Œè¨˜éŒ„"""
    id: str
    original_request: str
    steps: List[WorkflowStep]
    status: str = "pending"  # pending, running, completed, failed
    final_result: Optional[str] = None
    started_at: Optional[str] = None
    completed_at: Optional[str] = None


class AgentCoordinator:
    """
    Agent å”èª¿å™¨
    
    æ ¸å¿ƒè·è²¬ï¼š
    1. æ¥æ”¶ç”¨æˆ¶è«‹æ±‚
    2. èª¿ç”¨ Dispatcher åˆ†æå’Œæ‹†è§£ä»»å‹™
    3. æŒ‰é †åºèª¿ç”¨å°ˆæ¥­ Agent åŸ·è¡Œ
    4. åœ¨ Agent ä¹‹é–“å‚³éä¸Šä¸‹æ–‡
    5. èšåˆæœ€çµ‚çµæœ
    """
    
    def __init__(self):
        self._agents: Dict[str, BaseAgent] = {}
        self._dispatcher: Optional[DispatcherAgent] = None
        self._initialized = False
        self._executions: Dict[str, WorkflowExecution] = {}
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–å”èª¿å™¨å’Œæ‰€æœ‰ Agent"""
        try:
            # å…ˆåˆå§‹åŒ–å·¥å…·
            from opencode.tools import register_all_tools
            await register_all_tools()
            
            # å‰µå»ºç¸½æ©Ÿ Agent
            self._dispatcher = DispatcherAgent()
            await self._dispatcher.initialize()
            
            # å‰µå»ºå°ˆæ¥­ Agent
            agent_classes = [
                ResearcherAgent,
                WriterAgent,
                CoderAgent,
                AnalystAgent,
                ReviewerAgent
            ]
            
            for agent_class in agent_classes:
                agent = agent_class()
                await agent.initialize()
                self._agents[agent.type.value] = agent
            
            # è¼‰å…¥æ’ä»¶ Agent
            await self._load_plugin_agents()
            
            self._initialized = True
            logger.info(f"âœ… AgentCoordinator initialized with {len(self._agents)} agents")
            return True
            
        except Exception as e:
            logger.error(f"AgentCoordinator init error: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
    
    async def _load_plugin_agents(self) -> None:
        """è¼‰å…¥æ’ä»¶ Agent"""
        try:
            from opencode.plugins.manager import get_plugin_manager, PluginStatus, PluginType
            
            pm = get_plugin_manager()
            
            # ç™¼ç¾ä¸¦è¼‰å…¥æ’ä»¶
            pm.discover_plugins()
            
            for plugin_id, metadata in pm._metadata.items():
                if metadata.plugin_type == PluginType.AGENT:
                    try:
                        # è¼‰å…¥ä¸¦å•Ÿç”¨æ’ä»¶
                        if await pm.load_plugin(plugin_id):
                            await pm.enable_plugin(plugin_id)
                            
                            # åŒ…è£æˆ Agent
                            plugin = pm.get_plugin(plugin_id)
                            if plugin and hasattr(plugin, 'agent_name'):
                                wrapper = PluginAgentWrapper(plugin)
                                self._agents[plugin.agent_name] = wrapper
                                logger.info(f"ğŸ”Œ Loaded plugin agent: {plugin.agent_name}")
                    except Exception as e:
                        logger.error(f"Failed to load plugin agent {plugin_id}: {e}")
                        
        except ImportError:
            logger.warning("Plugin system not available")
        except Exception as e:
            logger.error(f"Error loading plugin agents: {e}")
    
    async def reload_plugin_agents(self) -> None:
        """ç†±é‡è¼‰æ’ä»¶ Agentï¼ˆä¸éœ€é‡å•Ÿï¼‰"""
        # ç§»é™¤ç¾æœ‰çš„æ’ä»¶ Agent
        plugin_agents = [
            name for name, agent in self._agents.items() 
            if isinstance(agent, PluginAgentWrapper)
        ]
        for name in plugin_agents:
            del self._agents[name]
        
        # é‡æ–°è¼‰å…¥
        await self._load_plugin_agents()
        logger.info(f"ğŸ”„ Reloaded plugin agents, total: {len(self._agents)}")
    
    def get_agent(self, agent_type: str) -> Optional[BaseAgent]:
        """ç²å–æŒ‡å®šé¡å‹çš„ Agent"""
        return self._agents.get(agent_type)
    
    def list_agents(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰ Agent"""
        agents = [self._dispatcher.to_dict()] if self._dispatcher else []
        agents.extend([agent.to_dict() for agent in self._agents.values()])
        return agents
    
    async def process_request(
        self, 
        user_request: str,
        context: Dict[str, Any] = None,
        stream: bool = False
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        è™•ç†ç”¨æˆ¶è«‹æ±‚ï¼ˆå®Œæ•´æµç¨‹ï¼‰
        
        Args:
            user_request: ç”¨æˆ¶è«‹æ±‚
            context: ä¸Šä¸‹æ–‡ï¼ˆå¦‚é¸ä¸­çš„æ–‡ä»¶ã€é™„ä»¶ï¼‰
            stream: æ˜¯å¦ä¸²æµè¼¸å‡º
            
        Yields:
            åŸ·è¡Œé€²åº¦å’Œçµæœ
        """
        if not self._initialized:
            logger.error("âŒ Coordinator not initialized")
            yield {"type": "error", "content": "Coordinator not initialized"}
            return
        
        execution_id = str(uuid.uuid4())[:8]
        logger.info(f"{'='*50}")
        logger.info(f"ğŸš€ Processing request [{execution_id}]")
        logger.info(f"ğŸ“ Request: {user_request[:100]}...")
        logger.info(f"ğŸ“¦ Context: {context}")
        logger.info(f"{'='*50}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å¤šæ¨¡æ…‹é™„ä»¶
        attachments = (context or {}).get("attachments", [])
        has_images = any(a.get("type") == "image" for a in attachments) if attachments else False
        has_files = any(a.get("type") == "file" for a in attachments) if attachments else False
        
        logger.info(f"[{execution_id}] ğŸ“ Attachments: {len(attachments) if attachments else 0}")
        logger.info(f"[{execution_id}] ğŸ–¼ï¸ Has images: {has_images}")
        
        # å¦‚æœæœ‰åœ–ç‰‡é™„ä»¶ï¼Œç›´æ¥ä½¿ç”¨ Vision è™•ç†
        if has_images:
            async for event in self._process_vision_request(
                execution_id, user_request, attachments, context
            ):
                yield event
            return
        
        # å¦‚æœæœ‰æ–‡ä»¶é™„ä»¶ï¼Œå…ˆæå–å…§å®¹å†è™•ç†
        if has_files:
            async for event in self._process_file_request(
                execution_id, user_request, attachments, context
            ):
                yield event
            return
        
        # Token ä½¿ç”¨é‡è¿½è¹¤
        total_usage = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
            "estimated_cost_usd": 0.0
        }
        
        def accumulate_usage(result: AgentResult):
            """ç´¯åŠ  Agent çš„ token ä½¿ç”¨é‡"""
            # å¾ AgentResult.usage ç²å–ï¼ˆæ–°ç‰ˆæœ¬ï¼‰
            if hasattr(result, 'usage') and result.usage:
                usage = result.usage
                total_usage["prompt_tokens"] += usage.get("prompt_tokens", 0)
                total_usage["completion_tokens"] += usage.get("completion_tokens", 0)
                total_usage["total_tokens"] += usage.get("total_tokens", 0)
                total_usage["estimated_cost_usd"] += usage.get("estimated_cost_usd", 0)
                logger.info(f"ğŸ“Š ç´¯åŠ  usage: +{usage.get('total_tokens', 0)} tokens")
            # å‘å¾Œå…¼å®¹ï¼šå¾ output.usage ç²å–
            elif hasattr(result, 'output') and isinstance(result.output, dict):
                usage = result.output.get('usage', {})
                if usage:
                    total_usage["prompt_tokens"] += usage.get("prompt_tokens", 0)
                    total_usage["completion_tokens"] += usage.get("completion_tokens", 0)
                    total_usage["total_tokens"] += usage.get("total_tokens", 0)
                    total_usage["estimated_cost_usd"] += usage.get("estimated_cost_usd", 0)
        
        # 1. åˆ†æè«‹æ±‚ - ç™¼é€æ€è€ƒäº‹ä»¶
        logger.info(f"[{execution_id}] Step 1: Analyzing request...")
        yield {
            "type": "thinking",
            "step": "analyzing",
            "content": "æ­£åœ¨ç†è§£æ‚¨çš„å•é¡Œ...",
            "details": f"åˆ†æè«‹æ±‚å…§å®¹ï¼š{user_request[:100]}..."
        }
        
        dispatch_task = AgentTask(
            type="dispatch",
            description="åˆ†æç”¨æˆ¶è«‹æ±‚",
            parameters={"request": user_request},
            context=context or {}
        )
        
        dispatch_result = await self._dispatcher.process_task(dispatch_task)
        accumulate_usage(dispatch_result)
        
        logger.info(f"[{execution_id}] Dispatcher result: success={dispatch_result.success}")
        logger.debug(f"[{execution_id}] Dispatcher output: {dispatch_result.output}")
        
        if not dispatch_result.success:
            logger.error(f"[{execution_id}] âŒ Dispatcher failed: {dispatch_result.error}")
            yield {"type": "error", "content": "ç„¡æ³•ç†è§£æ‚¨çš„è«‹æ±‚"}
            return
        
        analysis = dispatch_result.output.get("analysis", "")
        subtasks = dispatch_result.output.get("subtasks", [])
        is_simple_query = dispatch_result.output.get("is_simple_query", False)
        
        logger.info(f"[{execution_id}] Analysis: {analysis[:100]}...")
        logger.info(f"[{execution_id}] Is simple query: {is_simple_query}")
        logger.info(f"[{execution_id}] Subtasks: {len(subtasks)}")
        for st in subtasks:
            logger.info(f"[{execution_id}]   - {st.get('agent')}: {st.get('task', st.get('description', ''))[:50]}")
        
        # ç™¼é€åˆ†æå®Œæˆäº‹ä»¶
        yield {
            "type": "analysis_complete",
            "content": analysis,
            "is_simple_query": is_simple_query
        }
        
        # ç™¼é€è¦åŠƒäº‹ä»¶
        yield {
            "type": "plan",
            "content": analysis,
            "subtasks": subtasks,
            "total_steps": len(subtasks),
            "is_simple_query": is_simple_query
        }
        
        if not subtasks:
            logger.error(f"[{execution_id}] âŒ No subtasks generated")
            yield {"type": "error", "content": "ç„¡æ³•æ‹†è§£ä»»å‹™"}
            return
        
        # 2. æŒ‰é †åºåŸ·è¡Œå­ä»»å‹™
        logger.info(f"[{execution_id}] Step 2: Executing {len(subtasks)} subtasks...")
        results = {}  # task_id -> result
        
        for i, subtask in enumerate(subtasks):
            task_id = subtask.get("id", str(i))
            agent_type = subtask.get("agent", "researcher")
            task_description = subtask.get("description", subtask.get("task", ""))
            depends_on = subtask.get("depends_on", [])
            
            # ç™¼é€é–‹å§‹åŸ·è¡Œäº‹ä»¶
            yield {
                "type": "agent_start",
                "step": i + 1,
                "total": len(subtasks),
                "agent": agent_type,
                "task": task_description,
                "is_simple_query": is_simple_query
            }
            
            logger.info(f"[{execution_id}] Executing subtask {i+1}/{len(subtasks)}: {agent_type}")
            logger.info(f"[{execution_id}]   Task: {task_description[:100]}")
            
            # ç²å– Agent
            agent = self.get_agent(agent_type)
            if not agent:
                logger.warning(f"[{execution_id}] âš ï¸ Agent {agent_type} not found, skipping")
                yield {
                    "type": "warning",
                    "content": f"Agent {agent_type} not found, skipping"
                }
                continue
            
            # æ§‹å»ºä¸Šä¸‹æ–‡ï¼ˆåŒ…å«ä¾è³´ä»»å‹™çš„çµæœï¼‰
            task_context = dict(context or {})
            for dep_id in depends_on:
                if dep_id in results:
                    task_context["previous_result"] = results[dep_id].output
            
            # æ§‹å»ºä»»å‹™åƒæ•¸ï¼ˆåˆä½µ subtask ä¸­çš„ç‰¹æ®Šæ¬„ä½ï¼‰
            task_params = subtask.get("parameters", {})
            # å‚³éç¶²è·¯æœå°‹ç›¸é—œåƒæ•¸
            if subtask.get("use_web_search"):
                task_params["use_web_search"] = True
            if subtask.get("search_query"):
                task_params["search_query"] = subtask.get("search_query")
            
            # å‰µå»ºä»»å‹™
            agent_task = AgentTask(
                id=task_id,
                type=agent_type,
                description=task_description,
                parameters=task_params,
                context=task_context
            )
            
            # åŸ·è¡Œä»»å‹™
            try:
                logger.info(f"[{execution_id}] ğŸ¤– Agent {agent_type} processing task...")
                result = await agent.process_task(agent_task)
                results[task_id] = result
                
                logger.info(f"[{execution_id}] âœ… Agent {agent_type} completed: success={result.success}")
                logger.info(f"[{execution_id}]   Tool calls: {len(result.tool_calls)}")
                logger.info(f"[{execution_id}]   Execution time: {result.execution_time:.2f}s")
                
                # ç™¼é€æ¯å€‹å·¥å…·å‘¼å«çš„äº‹ä»¶
                for tc in result.tool_calls:
                    tool_name = tc.get("tool", "unknown")
                    tool_args = tc.get("arguments", {})
                    tool_result = tc.get("result", {})
                    
                    yield {
                        "type": "tool_call",
                        "agent": agent_type,
                        "tool": tool_name,
                        "arguments": tool_args,
                        "result": tool_result,
                        "success": tool_result.get("success", True) if isinstance(tool_result, dict) else True
                    }
                    
                    # å¦‚æœæ˜¯ç¨‹å¼ç¢¼åŸ·è¡Œï¼Œç™¼é€ç‰¹æ®Šäº‹ä»¶
                    if "sandbox" in tool_name.lower() or "execute" in tool_name.lower():
                        yield {
                            "type": "code_execution",
                            "agent": agent_type,
                            "code": tool_args.get("code", ""),
                            "result": tool_result
                        }
                
                # ç™¼é€æ­¥é©Ÿå®Œæˆäº‹ä»¶
                yield {
                    "type": "step_result",
                    "step": i + 1,
                    "agent": agent_type,
                    "success": result.success,
                    "output": result.output,
                    "tool_calls": result.tool_calls,
                    "execution_time": result.execution_time
                }
                
                # ç´¯åŠ  token ä½¿ç”¨é‡
                accumulate_usage(result)
                
            except Exception as e:
                logger.error(f"[{execution_id}] âŒ Task {task_id} failed: {e}")
                import traceback
                logger.error(f"[{execution_id}] Traceback: {traceback.format_exc()}")
                yield {
                    "type": "step_error",
                    "step": i + 1,
                    "agent": agent_type,
                    "error": str(e)
                }
        
        # 3. èšåˆæœ€çµ‚çµæœ
        yield {
            "type": "summarizing",
            "content": "æ­£åœ¨æ•´ç†æœ€çµ‚çµæœ..."
        }
        
        summary_result = await self._summarize_results(user_request, results)
        final_result = summary_result.get("answer", "è™•ç†å®Œæˆ")
        summary_usage = summary_result.get("usage", {})
        
        # ç´¯åŠ ç¸½çµæ­¥é©Ÿçš„ token
        if summary_usage:
            total_usage["prompt_tokens"] += summary_usage.get("prompt_tokens", 0)
            total_usage["completion_tokens"] += summary_usage.get("completion_tokens", 0)
            total_usage["total_tokens"] += summary_usage.get("total_tokens", 0)
            total_usage["estimated_cost_usd"] += summary_usage.get("estimated_cost_usd", 0)
        
        logger.info(f"[{execution_id}] ğŸ“Š Total token usage: {total_usage}")
        
        yield {
            "type": "final",
            "content": final_result,
            "execution_id": execution_id,
            "total_steps": len(subtasks),
            "completed_steps": len(results),
            "usage": total_usage
        }
    
    async def _summarize_results(
        self, 
        original_request: str, 
        results: Dict[str, AgentResult]
    ) -> Dict[str, Any]:
        """
        èšåˆæ‰€æœ‰ Agent çš„çµæœç‚ºæœ€çµ‚å›ç­”
        
        Returns:
            {"answer": str, "usage": dict}
        """
        if not results:
            return {"answer": "ç„¡æ³•å®Œæˆä»»å‹™", "usage": {}}
        
        # ä½¿ç”¨ Dispatcher çš„ LLM ä¾†ç¸½çµ
        results_summary = []
        for task_id, result in results.items():
            agent_type = result.agent_type
            output = result.output
            
            # æˆªæ–·éé•·çš„å…§å®¹ï¼Œé¿å… token è¶…é™
            if isinstance(output, dict):
                # ç§»é™¤ base64 åœ–ç‰‡å’Œéé•·çš„ä»£ç¢¼
                summary_output = {}
                for key, value in output.items():
                    if key == 'figures':
                        # åªè¨˜éŒ„åœ–ç‰‡æ•¸é‡
                        summary_output[key] = f"[{len(value)} å¼µåœ–è¡¨å·²ç”Ÿæˆ]"
                    elif key == 'code':
                        # æˆªæ–·ä»£ç¢¼
                        if len(str(value)) > 500:
                            summary_output[key] = str(value)[:500] + "... [ä»£ç¢¼å·²æˆªæ–·]"
                        else:
                            summary_output[key] = value
                    elif key == 'execution_result':
                        # åªä¿ç•™é—œéµä¿¡æ¯
                        if isinstance(value, dict):
                            summary_output[key] = {
                                'success': value.get('success'),
                                'stdout': str(value.get('stdout', ''))[:300],
                                'error': value.get('error')
                            }
                        else:
                            summary_output[key] = str(value)[:300]
                    elif key in ['explanation', 'content']:
                        # æˆªæ–·é•·æ–‡æœ¬
                        if len(str(value)) > 1000:
                            summary_output[key] = str(value)[:1000] + "... [å·²æˆªæ–·]"
                        else:
                            summary_output[key] = value
                    else:
                        summary_output[key] = value
                output_str = str(summary_output)
            else:
                output_str = str(output)[:2000]
            
            results_summary.append(f"**{agent_type}**:\n{output_str}")
        
        prompt = f"""ç”¨æˆ¶åŸå§‹è«‹æ±‚ï¼š{original_request}

å„ Agent çš„åŸ·è¡Œçµæœï¼š
{chr(10).join(results_summary)}

è«‹æ ¹æ“šä»¥ä¸Šæ‰€æœ‰çµæœï¼Œçµ¦ç”¨æˆ¶ä¸€å€‹å®Œæ•´ã€æ¸…æ™°çš„æœ€çµ‚å›ç­”ã€‚
ç›´æ¥å›ç­”ç”¨æˆ¶çš„å•é¡Œï¼Œä¸è¦æåŠ Agent æˆ–å·¥ä½œæµç¨‹çš„ç´°ç¯€ã€‚
å¦‚æœæœ‰è¨ˆç®—çµæœï¼Œè«‹æ˜ç¢ºèªªæ˜è¨ˆç®—çµæœã€‚"""

        result = await self._dispatcher.think(prompt, use_tools=False)
        return {
            "answer": result.get("answer", "è™•ç†å®Œæˆ"),
            "usage": result.get("usage", {})
        }
    
    async def _process_vision_request(
        self,
        execution_id: str,
        user_request: str,
        attachments: List[Dict],
        context: Dict = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        è™•ç†åŒ…å«åœ–ç‰‡çš„è«‹æ±‚ï¼ˆä½¿ç”¨ GPT-4 Visionï¼‰
        """
        import os
        from openai import AsyncOpenAI
        
        images = [a for a in attachments if a.get("type") == "image"]
        logger.info(f"[{execution_id}] ğŸ–¼ï¸ Processing {len(images)} images with Vision...")
        
        # ç™¼é€æ€è€ƒäº‹ä»¶
        yield {
            "type": "thinking",
            "step": "analyzing",
            "content": f"æ­£åœ¨åˆ†æ {len(images)} å¼µåœ–ç‰‡...",
            "details": "ä½¿ç”¨ GPT-4 Vision é€²è¡Œåœ–ç‰‡è­˜åˆ¥"
        }
        
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                yield {"type": "error", "content": "OPENAI_API_KEY æœªè¨­ç½®"}
                return
            
            client = AsyncOpenAI(api_key=api_key)
            
            # æ§‹å»ºå¤šæ¨¡æ…‹æ¶ˆæ¯
            content = []
            
            # æ·»åŠ æ–‡å­—æç¤º
            content.append({
                "type": "text",
                "text": user_request if user_request else "è«‹æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹ã€‚"
            })
            
            # æ·»åŠ åœ–ç‰‡
            for img in images:
                img_data = img.get("data", "")
                mime_type = img.get("mime_type", "image/jpeg")
                
                if img_data:
                    content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{img_data}",
                            "detail": "auto"
                        }
                    })
                    logger.info(f"[{execution_id}] Added image: {img.get('name', 'unknown')}")
            
            # ç™¼é€è™•ç†ä¸­äº‹ä»¶
            yield {
                "type": "step_start",
                "agent": "vision",
                "task": "åˆ†æåœ–ç‰‡å…§å®¹"
            }
            
            # èª¿ç”¨ GPT-4 Vision
            response = await client.chat.completions.create(
                model="gpt-4o",  # GPT-4 Vision
                messages=[
                    {
                        "role": "user",
                        "content": content
                    }
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            answer = response.choices[0].message.content
            logger.info(f"[{execution_id}] âœ… Vision analysis completed")
            
            # è¨ˆç®—ä½¿ç”¨é‡
            usage = {}
            if response.usage:
                input_tokens = response.usage.prompt_tokens
                output_tokens = response.usage.completion_tokens
                total_tokens = input_tokens + output_tokens
                
                # GPT-4o åƒ¹æ ¼ä¼°ç®—
                estimated_cost = (input_tokens * 0.005 + output_tokens * 0.015) / 1000
                
                usage = {
                    "input_tokens": input_tokens,
                    "output_tokens": output_tokens,
                    "total_tokens": total_tokens,
                    "estimated_cost_usd": estimated_cost
                }
                logger.info(f"[{execution_id}] ğŸ“Š Vision usage: {total_tokens} tokens (${estimated_cost:.4f})")
            
            # ç™¼é€å®Œæˆäº‹ä»¶
            yield {
                "type": "step_complete",
                "agent": "vision",
                "task": "åˆ†æåœ–ç‰‡å…§å®¹",
                "success": True
            }
            
            # ç™¼é€æœ€çµ‚çµæœ
            yield {
                "type": "final",
                "content": answer,
                "usage": usage
            }
            
        except Exception as e:
            logger.error(f"[{execution_id}] âŒ Vision error: {e}")
            import traceback
            logger.error(traceback.format_exc())
            yield {
                "type": "final",
                "content": f"åœ–ç‰‡åˆ†æå¤±æ•—: {str(e)}",
                "usage": {}
            }
    
    async def _process_file_request(
        self,
        execution_id: str,
        user_request: str,
        attachments: List[Dict],
        context: Dict = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        è™•ç†åŒ…å«æ–‡ä»¶çš„è«‹æ±‚ï¼ˆæå–å…§å®¹å¾Œåˆ†æï¼‰
        """
        import os
        import base64
        from openai import AsyncOpenAI
        
        files = [a for a in attachments if a.get("type") == "file"]
        logger.info(f"[{execution_id}] ğŸ“„ Processing {len(files)} files...")
        
        # ç™¼é€æ€è€ƒäº‹ä»¶
        yield {
            "type": "thinking",
            "step": "analyzing",
            "content": f"æ­£åœ¨åˆ†æ {len(files)} å€‹æ–‡ä»¶...",
            "details": "æå–æ–‡ä»¶å…§å®¹é€²è¡Œåˆ†æ"
        }
        
        # æå–æ–‡ä»¶å…§å®¹
        file_contents = []
        for f in files:
            name = f.get("name", "æœªçŸ¥æ–‡ä»¶")
            mime_type = f.get("mime_type", "")
            data = f.get("data", "")
            
            content = ""
            try:
                if mime_type.startswith("text/") or name.endswith((".txt", ".md", ".csv", ".json")):
                    # æ–‡å­—æ–‡ä»¶ç›´æ¥è§£ç¢¼
                    content = base64.b64decode(data).decode("utf-8")[:10000]
                elif "excel" in mime_type or "spreadsheet" in mime_type or name.endswith((".xls", ".xlsx")):
                    # Excel æ–‡ä»¶å˜—è©¦è®€å–
                    try:
                        import io
                        import pandas as pd
                        
                        file_bytes = base64.b64decode(data)
                        df = pd.read_excel(io.BytesIO(file_bytes))
                        content = f"Excel å…§å®¹ï¼ˆå‰ 50 è¡Œï¼‰:\n\n{df.head(50).to_string()}"
                    except Exception as e:
                        content = f"[ç„¡æ³•è®€å– Excel: {e}]"
                else:
                    content = f"[ä¸æ”¯æ´çš„æ–‡ä»¶é¡å‹: {mime_type}]"
            except Exception as e:
                content = f"[æ–‡ä»¶è§£ç¢¼éŒ¯èª¤: {e}]"
            
            file_contents.append(f"### æ–‡ä»¶: {name}\n\n{content}")
            logger.info(f"[{execution_id}] Extracted content from: {name}")
        
        # ç™¼é€è™•ç†ä¸­äº‹ä»¶
        yield {
            "type": "step_start",
            "agent": "analyst",
            "task": "åˆ†ææ–‡ä»¶å…§å®¹"
        }
        
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                yield {"type": "error", "content": "OPENAI_API_KEY æœªè¨­ç½®"}
                return
            
            client = AsyncOpenAI(api_key=api_key)
            
            combined_content = "\n\n---\n\n".join(file_contents)
            
            response = await client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡ä»¶åˆ†æåŠ©æ‰‹ã€‚æ ¹æ“šç”¨æˆ¶ä¸Šå‚³çš„æ–‡ä»¶å…§å®¹å’Œå•é¡Œï¼Œæä¾›è©³ç´°çš„åˆ†æå’Œå›ç­”ã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"
                    },
                    {
                        "role": "user",
                        "content": f"## ç”¨æˆ¶å•é¡Œ\n{user_request}\n\n## æ–‡ä»¶å…§å®¹\n{combined_content}\n\nè«‹åˆ†æé€™äº›æ–‡ä»¶ä¸¦å›ç­”å•é¡Œã€‚"
                    }
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            answer = response.choices[0].message.content
            logger.info(f"[{execution_id}] âœ… File analysis completed")
            
            # è¨ˆç®—ä½¿ç”¨é‡
            usage = {}
            if response.usage:
                input_tokens = response.usage.prompt_tokens
                output_tokens = response.usage.completion_tokens
                total_tokens = input_tokens + output_tokens
                estimated_cost = (input_tokens * 0.005 + output_tokens * 0.015) / 1000
                
                usage = {
                    "input_tokens": input_tokens,
                    "output_tokens": output_tokens,
                    "total_tokens": total_tokens,
                    "estimated_cost_usd": estimated_cost
                }
            
            # ç™¼é€å®Œæˆäº‹ä»¶
            yield {
                "type": "step_complete",
                "agent": "analyst",
                "task": "åˆ†ææ–‡ä»¶å…§å®¹",
                "success": True
            }
            
            # ç™¼é€æœ€çµ‚çµæœ
            yield {
                "type": "final",
                "content": answer,
                "usage": usage
            }
            
        except Exception as e:
            logger.error(f"[{execution_id}] âŒ File analysis error: {e}")
            yield {
                "type": "final",
                "content": f"æ–‡ä»¶åˆ†æå¤±æ•—: {str(e)}",
                "usage": {}
            }

    async def execute_single_agent(
        self,
        agent_type: str,
        task_description: str,
        parameters: Dict = None,
        context: Dict = None
    ) -> AgentResult:
        """
        ç›´æ¥åŸ·è¡Œå–®å€‹ Agentï¼ˆè·³é Dispatcherï¼‰
        
        ç”¨æ–¼ç°¡å–®ä»»å‹™æˆ–æ¸¬è©¦
        """
        agent = self.get_agent(agent_type)
        if not agent:
            return AgentResult(
                task_id="",
                agent_type=agent_type,
                success=False,
                output={},
                error=f"Agent {agent_type} not found"
            )
        
        task = AgentTask(
            type=agent_type,
            description=task_description,
            parameters=parameters or {},
            context=context or {}
        )
        
        return await agent.process_task(task)


# å…¨åŸŸå¯¦ä¾‹
_coordinator: Optional[AgentCoordinator] = None


async def get_coordinator() -> AgentCoordinator:
    """ç²å–å”èª¿å™¨å¯¦ä¾‹"""
    global _coordinator
    if _coordinator is None:
        _coordinator = AgentCoordinator()
        await _coordinator.initialize()
    return _coordinator
