"""
Orchestrator Actor - ä¸»ç·¨æ’å™¨
å”èª¿ Plannerã€Routerã€Executorã€Memory åŸ·è¡Œä»»å‹™
"""

from typing import Dict, Any, Optional, AsyncIterator, List
import asyncio
import logging
import time
import os
from pathlib import Path

# ä½¿ç”¨çµ±ä¸€çš„è·¯å¾‘å·¥å…·è¼‰å…¥ç’°å¢ƒè®Šæ•¸
from opencode.core.utils import load_env, get_project_root
load_env()

from opencode.orchestrator.actors.base import Actor, ActorMessage, SupervisorActor
from opencode.core.protocols import (
    Event, EventType, Intent, Task, TaskStatus,
    Context
)
from opencode.core.events import create_event

logger = logging.getLogger(__name__)


class OrchestratorActor(SupervisorActor):
    """
    ä¸»ç·¨æ’ Actor
    
    è·è²¬:
    - æ¥æ”¶ç”¨æˆ¶æ„åœ–
    - å”èª¿ Planner åˆ†è§£ä»»å‹™
    - è·¯ç”±ä»»å‹™åˆ°é©ç•¶æœå‹™
    - è¿½è¹¤åŸ·è¡Œç‹€æ…‹
    - ç®¡ç†è¨˜æ†¶
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(name="orchestrator", config=config)
        
        # å­ Actor
        self.planner = None
        self.router = None
        self.executor = None
        self.memory_actor = None
        
        # ç‹€æ…‹
        self.active_intents: Dict[str, Dict] = {}
        self.task_results: Dict[str, Any] = {}
        
        # å›èª¿
        self._response_callbacks: Dict[str, asyncio.Queue] = {}
    
    async def on_start(self) -> None:
        """å•Ÿå‹•æ™‚åˆå§‹åŒ–å­ Actor"""
        # å»ºç«‹å­ Actor
        from opencode.orchestrator.actors.planner import PlannerActor
        from opencode.orchestrator.actors.router import RouterActor
        from opencode.orchestrator.actors.executor import ExecutorActor
        from opencode.orchestrator.actors.memory import MemoryActor
        
        self.planner = self.spawn_child(
            PlannerActor, 
            "planner",
            config=self.config.get("planner", {})
        )
        
        self.router = self.spawn_child(
            RouterActor,
            "router",
            config=self.config.get("router", {})
        )
        
        self.executor = self.spawn_child(
            ExecutorActor,
            "executor",
            config=self.config.get("executor", {})
        )
        
        self.memory_actor = self.spawn_child(
            MemoryActor,
            "memory",
            config=self.config.get("memory", {})
        )
        
        logger.info("Orchestrator children created")
    
    async def handle_message(self, message: ActorMessage) -> Optional[Any]:
        """è™•ç†è¨Šæ¯"""
        content = message.content
        msg_type = content.get("type")
        
        if msg_type == "intent":
            # è™•ç†ç”¨æˆ¶æ„åœ–
            return await self._handle_intent(content, message.correlation_id)
        
        elif msg_type == "plan":
            # æ”¶åˆ° Planner çš„è¨ˆç•«
            await self._handle_plan(content, message.correlation_id)
        
        elif msg_type == "task_result":
            # æ”¶åˆ°ä»»å‹™åŸ·è¡Œçµæœ
            await self._handle_task_result(content, message.correlation_id)
        
        elif msg_type == "child_error":
            # å­ Actor éŒ¯èª¤
            await self._handle_child_error(content)
        
        return None
    
    async def process_intent(
        self, 
        intent_data: Dict[str, Any]
    ) -> AsyncIterator[Event]:
        """
        è™•ç†ç”¨æˆ¶æ„åœ– (å¤–éƒ¨å‘¼å«å…¥å£)
        
        Args:
            intent_data: æ„åœ–è³‡æ–™
            
        Yields:
            è™•ç†éç¨‹ä¸­çš„äº‹ä»¶
        """
        correlation_id = intent_data.get("id", str(time.time()))
        
        # å»ºç«‹å›æ‡‰ä½‡åˆ—
        response_queue = asyncio.Queue()
        self._response_callbacks[correlation_id] = response_queue
        
        try:
            # ç™¼é€æ„åœ–è¨Šæ¯çµ¦è‡ªå·±
            await self.send(ActorMessage(
                sender="external",
                content={
                    "type": "intent",
                    "payload": intent_data
                },
                correlation_id=correlation_id
            ))
            
            # æŒçºŒç”¢å‡ºäº‹ä»¶ç›´åˆ°å®Œæˆ
            while True:
                try:
                    event = await asyncio.wait_for(
                        response_queue.get(),
                        timeout=60.0  # ç¸½è¶…æ™‚
                    )
                    
                    yield event
                    
                    # æª¢æŸ¥æ˜¯å¦å®Œæˆ
                    if event.type in (EventType.DONE, EventType.ERROR):
                        break
                        
                except asyncio.TimeoutError:
                    yield create_event(
                        EventType.ERROR,
                        content="Processing timeout",
                        correlation_id=correlation_id
                    )
                    break
                    
        finally:
            self._response_callbacks.pop(correlation_id, None)
    
    async def _handle_intent(
        self, 
        content: Dict[str, Any],
        correlation_id: str
    ) -> None:
        """è™•ç†æ„åœ–"""
        intent_data = content.get("payload", {})
        
        # è¨˜éŒ„æ´»èºæ„åœ–
        self.active_intents[correlation_id] = {
            "intent": intent_data,
            "status": "planning",
            "started_at": time.time()
        }
        
        # ç™¼é€ thinking äº‹ä»¶
        await self._emit_event(
            EventType.THINKING,
            "åˆ†æå•é¡Œä¸¦è¦åŠƒä»»å‹™...",
            correlation_id
        )
        
        # ç™¼é€çµ¦ Planner
        await self.tell(self.planner, {
            "type": "create_plan",
            "intent": intent_data
        }, correlation_id)
    
    async def _handle_plan(
        self, 
        content: Dict[str, Any],
        correlation_id: str
    ) -> None:
        """è™•ç†è¦åŠƒçµæœ"""
        plan = content.get("plan", {})
        tasks = plan.get("tasks", [])
        
        if correlation_id in self.active_intents:
            self.active_intents[correlation_id]["status"] = "executing"
            self.active_intents[correlation_id]["plan"] = plan
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦ Vision åˆ†æ
        if plan.get("needs_vision"):
            await self._handle_vision_analysis(plan, correlation_id)
            return
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æª”æ¡ˆåˆ†æ
        if plan.get("needs_file_analysis"):
            await self._handle_file_analysis(plan, correlation_id)
            return
        
        if not tasks:
            # æ²’æœ‰ä»»å‹™éœ€è¦åŸ·è¡Œï¼Œç›´æ¥ç”Ÿæˆå›ç­”
            await self._generate_response(
                plan.get("analysis", ""),
                correlation_id
            )
            return
        
        # ç™¼é€ thinking äº‹ä»¶ï¼ˆåˆ†æçµæœï¼‰
        analysis = plan.get("analysis", "")
        if analysis:
            await self._emit_event(
                EventType.THINKING,
                analysis,
                correlation_id
            )
        
        # ç™¼é€ planning äº‹ä»¶ï¼ˆè©³ç´°çš„ä»»å‹™è¦åŠƒï¼‰- æ–°å¢ï¼
        # æ”¶é›†æ‰€æœ‰æŸ¥è©¢
        all_queries = []
        task_descriptions = []
        for task in tasks:
            params = task.get("parameters", {})
            if "queries" in params:
                all_queries.extend(params["queries"])
            elif "query" in params:
                all_queries.append(params["query"])
            task_descriptions.append({
                "id": task.get("id"),
                "tool": task.get("tool"),
                "description": task.get("description", task.get("tool"))
            })
        
        # ç™¼é€ planning äº‹ä»¶
        await self._emit_planning_event(
            correlation_id,
            summary=f"å°‡åŸ·è¡Œ {len(tasks)} å€‹ä»»å‹™ä¾†å›ç­”å•é¡Œ",
            queries=all_queries,
            tasks=task_descriptions
        )
        
        # æŒ‰åŸ·è¡Œé †åºåŸ·è¡Œä»»å‹™
        execution_order = plan.get("execution_order", [t["id"] for t in tasks])
        task_map = {t["id"]: t for t in tasks}
        
        for task_id in execution_order:
            task_data = task_map.get(task_id)
            if not task_data:
                continue
            
            tool_name = task_data.get("tool", "unknown")
            params = task_data.get("parameters", {})
            
            # ç™¼é€æ›´è©³ç´°çš„ tool_call äº‹ä»¶
            await self._emit_event(
                EventType.TOOL_CALL,
                tool_name,
                correlation_id,
                data={
                    "arguments": params,
                    "queries": params.get("queries", [params.get("query")] if params.get("query") else []),
                    "description": task_data.get("description", "")
                }
            )
            
            # åŸ·è¡Œä»»å‹™
            await self.tell(self.executor, {
                "type": "execute_task",
                "task": task_data,
                "context": self.active_intents.get(correlation_id, {}).get("intent", {}).get("context", {})
            }, correlation_id)
            
            # ç­‰å¾…ä»»å‹™çµæœ
            result = await self._wait_for_task_result(task_id, correlation_id)
            
            # ç™¼é€æ›´è©³ç´°çš„ tool_result äº‹ä»¶
            results_count = 0
            if isinstance(result, dict):
                results_count = len(result.get('results', []))
            
            await self._emit_event(
                EventType.TOOL_RESULT,
                f"æ‰¾åˆ° {results_count} å€‹ç›¸é—œçµæœ",
                correlation_id,
                data={
                    "preview": str(result)[:200],
                    "results_count": results_count
                }
            )
            
            # å„²å­˜çµæœä¾›å¾ŒçºŒä»»å‹™ä½¿ç”¨
            self.task_results[task_id] = result
        
        # æ‰€æœ‰ä»»å‹™å®Œæˆï¼Œç”Ÿæˆæœ€çµ‚å›ç­”
        await self._generate_final_answer(correlation_id)
    
    async def _handle_task_result(
        self, 
        content: Dict[str, Any],
        correlation_id: str
    ) -> None:
        """è™•ç†ä»»å‹™çµæœ"""
        task_id = content.get("task_id")
        result = content.get("result")
        
        if task_id:
            self.task_results[task_id] = result
    
    async def _wait_for_task_result(
        self, 
        task_id: str,
        correlation_id: str,
        timeout: float = 30.0
    ) -> Any:
        """ç­‰å¾…ä»»å‹™çµæœ"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            if task_id in self.task_results:
                return self.task_results.pop(task_id)
            await asyncio.sleep(0.1)
        
        return {"error": "Task timeout"}
    
    async def _generate_response(
        self,
        content: str,
        correlation_id: str
    ) -> None:
        """ç”Ÿæˆç°¡å–®å›æ‡‰"""
        await self._emit_event(EventType.ANSWER, content, correlation_id)
        await self._emit_event(EventType.DONE, "", correlation_id)
    
    async def _generate_final_answer(
        self,
        correlation_id: str
    ) -> None:
        """æ ¹æ“šä»»å‹™çµæœç”Ÿæˆæœ€çµ‚å›ç­”"""
        intent_data = self.active_intents.get(correlation_id, {}).get("intent", {})
        plan = self.active_intents.get(correlation_id, {}).get("plan", {})
        
        # æ”¶é›†æ‰€æœ‰ä»»å‹™çµæœ
        all_results = []
        all_sources = []
        context_texts = []
        
        logger.info(f"ğŸ“ [Orchestrator] é–‹å§‹ç”Ÿæˆæœ€çµ‚å›ç­”...")
        logger.info(f"ğŸ“ [Orchestrator] ä»»å‹™æ•¸é‡: {len(plan.get('tasks', []))}")
        logger.info(f"ğŸ“ [Orchestrator] å·²ä¿å­˜çµæœæ•¸é‡: {len(self.task_results)}")
        
        for task in plan.get("tasks", []):
            task_id = task.get("id")
            if task_id in self.task_results:
                result = self.task_results[task_id]
                all_results.append({
                    "task": task,
                    "result": result
                })
                
                logger.info(f"ğŸ“ [Orchestrator] è™•ç†ä»»å‹™ {task_id} çµæœ...")
                
                # æå–ä¸Šä¸‹æ–‡æ–‡æœ¬
                if isinstance(result, dict):
                    # ç›´æ¥å¾ results åˆ—è¡¨æå–ï¼ˆé©ç”¨æ–¼ rag_search å’Œ rag_search_multipleï¼‰
                    if "results" in result and isinstance(result["results"], list):
                        for r in result["results"]:
                            if isinstance(r, dict) and "text" in r:
                                text = r["text"]
                                if text and len(text) > 20:  # éæ¿¾éçŸ­çš„æ–‡æœ¬
                                    context_texts.append(text)
                                    logger.debug(f"ğŸ“ æå–æ–‡æœ¬: {text[:50]}...")
                    
                    # æ”¶é›†ä¾†æº
                    if "sources" in result:
                        all_sources.extend(result["sources"])
        
        logger.info(f"ğŸ“ [Orchestrator] æå–åˆ° {len(context_texts)} å€‹ä¸Šä¸‹æ–‡æ–‡æœ¬")
        logger.info(f"ğŸ“ [Orchestrator] æ”¶é›†åˆ° {len(all_sources)} å€‹ä¾†æº")
        
        # å»é‡ä¾†æº
        seen_sources = set()
        unique_sources = []
        for src in all_sources:
            key = (src.get("file_name", ""), src.get("page_label", ""))
            if key not in seen_sources:
                seen_sources.add(key)
                unique_sources.append(src)
        
        # ç™¼é€ "æ­£åœ¨ç”Ÿæˆå›ç­”" äº‹ä»¶
        await self._emit_generating_event(
            correlation_id,
            context_count=len(context_texts),
            source_count=len(unique_sources)
        )
        
        # ä½¿ç”¨ LLM ç”Ÿæˆæœ€çµ‚å›ç­”
        try:
            from openai import AsyncOpenAI
            
            # ç¢ºä¿ .env å·²è¼‰å…¥
            load_env()
            
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                logger.error("OPENAI_API_KEY not set for final answer generation")
                answer = "ç„¡æ³•ç”Ÿæˆå›ç­”ï¼šAPI Key æœªè¨­ç½®"
                await self._emit_event(EventType.ANSWER, answer, correlation_id)
            else:
                client = AsyncOpenAI(api_key=api_key)
                
                # å»ºæ§‹ä¸Šä¸‹æ–‡
                context_text = "\n\n---\n\n".join(context_texts[:15])  # é™åˆ¶ä¸Šä¸‹æ–‡é•·åº¦
                
                # å»ºæ§‹æç¤º
                messages = [
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„çŸ¥è­˜åŠ©æ‰‹ã€‚æ ¹æ“šç”¨æˆ¶çš„å•é¡Œå’Œæª¢ç´¢åˆ°çš„ç›¸é—œè³‡æ–™ï¼Œç”Ÿæˆæ¸…æ™°ã€æº–ç¢ºã€æœ‰çµæ§‹çš„å›ç­”ã€‚

## å›ç­”åŸå‰‡
1. **æº–ç¢ºæ€§**: åªåŸºæ–¼æä¾›çš„è³‡æ–™å›ç­”ï¼Œä¸è¦ç·¨é€ 
2. **çµæ§‹åŒ–**: ä½¿ç”¨æ¨™é¡Œã€æ¢åˆ—ã€æ®µè½çµ„ç¹”å›ç­”
3. **å®Œæ•´æ€§**: ç›¡å¯èƒ½æ¶µè“‹å•é¡Œçš„å„å€‹é¢å‘
4. **å¯è®€æ€§**: ç”¨ç¹é«”ä¸­æ–‡ï¼Œèªè¨€æ¸…æ™°æ˜“æ‡‚

## å›ç­”æ ¼å¼
- å¦‚æœæ˜¯æ¦‚è¿°é¡å•é¡Œï¼šå…ˆçµ¦å‡ºç¸½çµï¼Œå†åˆ†é»è©³è¿°
- å¦‚æœæ˜¯æ¯”è¼ƒé¡å•é¡Œï¼šä½¿ç”¨è¡¨æ ¼æˆ–å°æ¯”åˆ—è¡¨
- å¦‚æœæ˜¯è§£é‡‹é¡å•é¡Œï¼šç”±æ·ºå…¥æ·±ï¼Œé€æ­¥è§£é‡‹
- å¦‚æœè³‡æ–™ä¸è¶³ï¼šèª å¯¦èªªæ˜ï¼Œä¸¦æŒ‡å‡ºå·²çŸ¥çš„éƒ¨åˆ†"""
                    },
                    {
                        "role": "user",
                        "content": f"""## ç”¨æˆ¶å•é¡Œ
{intent_data.get('content', '')}

## æª¢ç´¢åˆ°çš„ç›¸é—œè³‡æ–™
{context_text}

## ä»»å‹™
è«‹æ ¹æ“šä»¥ä¸Šè³‡æ–™ï¼Œå›ç­”ç”¨æˆ¶çš„å•é¡Œã€‚å›ç­”è¦å…¨é¢ä¸”æœ‰çµæ§‹ã€‚"""
                    }
                ]
                
                response = await client.chat.completions.create(
                    model="gpt-4o",
                    messages=messages,
                    temperature=0.7
                )
                
                answer = response.choices[0].message.content
                
                # è¨˜éŒ„æˆæœ¬
                try:
                    from opencode.control_plane.cost import get_cost_service, CostType
                    cost_service = get_cost_service()
                    usage = response.usage
                    if usage:
                        cost_service.record_usage(
                            model="gpt-4o",
                            cost_type=CostType.LLM_INPUT,
                            input_tokens=usage.prompt_tokens,
                            output_tokens=usage.completion_tokens,
                            action="chat_answer"
                        )
                except Exception as cost_err:
                    logger.warning(f"Cost tracking failed: {cost_err}")
                
                # ç™¼é€å›ç­”
                await self._emit_event(EventType.ANSWER, answer, correlation_id)
                
                # ç™¼é€ä¾†æº
                if unique_sources:
                    await self._emit_event(
                        EventType.SOURCE,
                        f"{len(unique_sources)} å€‹åƒè€ƒä¾†æº",
                        correlation_id,
                        data={"sources": unique_sources[:5]}
                    )
            
        except Exception as e:
            logger.error(f"Answer generation error: {e}")
            await self._emit_event(
                EventType.ANSWER,
                f"è™•ç†å®Œæˆï¼Œä½†ç”Ÿæˆå›ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}",
                correlation_id
            )
        
        # å®Œæˆ
        await self._emit_event(EventType.DONE, "", correlation_id)
        
        # æ¸…ç†
        self.active_intents.pop(correlation_id, None)
    
    async def _handle_vision_analysis(
        self,
        plan: Dict[str, Any],
        correlation_id: str
    ) -> None:
        """è™•ç†åœ–ç‰‡åˆ†æ (Vision)"""
        tasks = plan.get("tasks", [])
        if not tasks:
            await self._emit_event(EventType.ERROR, "æ²’æœ‰åœ–ç‰‡å¯åˆ†æ", correlation_id)
            await self._emit_event(EventType.DONE, "", correlation_id)
            return
        
        task = tasks[0]
        params = task.get("parameters", {})
        query = params.get("query", "")
        images = params.get("images", [])
        
        await self._emit_event(
            EventType.THINKING,
            f"æ­£åœ¨åˆ†æ {len(images)} å¼µåœ–ç‰‡...",
            correlation_id,
            data={"type": "vision", "image_count": len(images)}
        )
        
        try:
            from openai import AsyncOpenAI
            load_env()
            
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise Exception("OPENAI_API_KEY æœªè¨­ç½®")
            
            client = AsyncOpenAI(api_key=api_key)
            
            # å»ºæ§‹å¤šæ¨¡æ…‹æ¶ˆæ¯
            content = []
            
            # æ·»åŠ æ–‡å­—æç¤º
            content.append({
                "type": "text",
                "text": query if query else "è«‹æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹ã€‚"
            })
            
            # æ·»åŠ åœ–ç‰‡
            for img in images:
                img_data = img.get("data", "")
                mime_type = img.get("mime_type", "image/jpeg")
                
                if img_data:
                    content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{img_data}",
                            "detail": "auto"
                        }
                    })
            
            response = await client.chat.completions.create(
                model="gpt-4o",  # GPT-4 Vision
                messages=[
                    {
                        "role": "user",
                        "content": content
                    }
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            answer = response.choices[0].message.content
            
            # è¨ˆç®—ä½¿ç”¨é‡
            usage = None
            if response.usage:
                input_tokens = response.usage.prompt_tokens
                output_tokens = response.usage.completion_tokens
                total_tokens = input_tokens + output_tokens
                
                # GPT-4o åƒ¹æ ¼ä¼°ç®—
                estimated_cost = (input_tokens * 0.005 + output_tokens * 0.015) / 1000
                
                usage = {
                    "input_tokens": input_tokens,
                    "output_tokens": output_tokens,
                    "total_tokens": total_tokens,
                    "estimated_cost_usd": estimated_cost
                }
            
            # ç™¼é€å›ç­”
            await self._emit_event(
                EventType.ANSWER,
                answer,
                correlation_id,
                data={"usage": usage} if usage else None
            )
            
        except Exception as e:
            logger.error(f"Vision åˆ†æéŒ¯èª¤: {e}")
            await self._emit_event(
                EventType.ANSWER,
                f"åœ–ç‰‡åˆ†æå¤±æ•—: {str(e)}",
                correlation_id
            )
        
        await self._emit_event(EventType.DONE, "", correlation_id)
        self.active_intents.pop(correlation_id, None)
    
    async def _handle_file_analysis(
        self,
        plan: Dict[str, Any],
        correlation_id: str
    ) -> None:
        """è™•ç†æª”æ¡ˆåˆ†æ"""
        tasks = plan.get("tasks", [])
        if not tasks:
            await self._emit_event(EventType.ERROR, "æ²’æœ‰æª”æ¡ˆå¯åˆ†æ", correlation_id)
            await self._emit_event(EventType.DONE, "", correlation_id)
            return
        
        task = tasks[0]
        params = task.get("parameters", {})
        query = params.get("query", "")
        files = params.get("files", [])
        
        await self._emit_event(
            EventType.THINKING,
            f"æ­£åœ¨åˆ†æ {len(files)} å€‹æª”æ¡ˆ...",
            correlation_id,
            data={"type": "file_analysis", "file_count": len(files)}
        )
        
        # æå–æª”æ¡ˆå…§å®¹
        file_contents = []
        for f in files:
            name = f.get("name", "æœªçŸ¥æª”æ¡ˆ")
            mime_type = f.get("mime_type", "")
            data = f.get("data", "")
            
            content = ""
            if mime_type.startswith("text/") or name.endswith((".txt", ".md", ".csv", ".json")):
                # æ–‡å­—æª”æ¡ˆç›´æ¥è§£ç¢¼
                try:
                    import base64
                    content = base64.b64decode(data).decode("utf-8")[:10000]  # é™åˆ¶é•·åº¦
                except:
                    content = "[ç„¡æ³•è§£ç¢¼æª”æ¡ˆå…§å®¹]"
            elif mime_type == "application/pdf" or name.endswith(".pdf"):
                content = "[PDF æª”æ¡ˆ - è«‹å…ˆä¸Šå‚³åˆ°çŸ¥è­˜åº«é€²è¡Œç´¢å¼•]"
            elif "excel" in mime_type or "spreadsheet" in mime_type or name.endswith((".xls", ".xlsx")):
                # Excel æª”æ¡ˆå˜—è©¦è®€å–
                try:
                    import base64
                    import io
                    import pandas as pd
                    
                    file_bytes = base64.b64decode(data)
                    df = pd.read_excel(io.BytesIO(file_bytes))
                    content = f"Excel æª”æ¡ˆå…§å®¹ï¼ˆå‰ 50 è¡Œï¼‰:\n\n{df.head(50).to_string()}"
                except Exception as e:
                    content = f"[ç„¡æ³•è®€å– Excel æª”æ¡ˆ: {e}]"
            else:
                content = f"[ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {mime_type}]"
            
            file_contents.append(f"### æª”æ¡ˆ: {name}\n\n{content}")
        
        # ä½¿ç”¨ LLM åˆ†æ
        try:
            from openai import AsyncOpenAI
            load_env()
            
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise Exception("OPENAI_API_KEY æœªè¨­ç½®")
            
            client = AsyncOpenAI(api_key=api_key)
            
            combined_content = "\n\n---\n\n".join(file_contents)
            
            response = await client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æª”æ¡ˆåˆ†æåŠ©æ‰‹ã€‚æ ¹æ“šç”¨æˆ¶ä¸Šå‚³çš„æª”æ¡ˆå…§å®¹å’Œå•é¡Œï¼Œæä¾›è©³ç´°çš„åˆ†æå’Œå›ç­”ã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"
                    },
                    {
                        "role": "user",
                        "content": f"## ç”¨æˆ¶å•é¡Œ\n{query}\n\n## æª”æ¡ˆå…§å®¹\n{combined_content}\n\nè«‹åˆ†æé€™äº›æª”æ¡ˆä¸¦å›ç­”å•é¡Œã€‚"
                    }
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            answer = response.choices[0].message.content
            
            # è¨ˆç®—ä½¿ç”¨é‡
            usage = None
            if response.usage:
                input_tokens = response.usage.prompt_tokens
                output_tokens = response.usage.completion_tokens
                total_tokens = input_tokens + output_tokens
                estimated_cost = (input_tokens * 0.005 + output_tokens * 0.015) / 1000
                
                usage = {
                    "input_tokens": input_tokens,
                    "output_tokens": output_tokens,
                    "total_tokens": total_tokens,
                    "estimated_cost_usd": estimated_cost
                }
            
            await self._emit_event(
                EventType.ANSWER,
                answer,
                correlation_id,
                data={"usage": usage} if usage else None
            )
            
        except Exception as e:
            logger.error(f"æª”æ¡ˆåˆ†æéŒ¯èª¤: {e}")
            await self._emit_event(
                EventType.ANSWER,
                f"æª”æ¡ˆåˆ†æå¤±æ•—: {str(e)}",
                correlation_id
            )
        
        await self._emit_event(EventType.DONE, "", correlation_id)
        self.active_intents.pop(correlation_id, None)
    
    async def _emit_event(
        self,
        event_type: EventType,
        content: str,
        correlation_id: str,
        data: Optional[Dict] = None
    ) -> None:
        """ç™¼é€äº‹ä»¶åˆ°å›èª¿ä½‡åˆ—"""
        event = create_event(
            event_type,
            content=content,
            data=data,
            source="orchestrator",
            correlation_id=correlation_id
        )
        
        queue = self._response_callbacks.get(correlation_id)
        if queue:
            await queue.put(event)
    
    async def _emit_planning_event(
        self,
        correlation_id: str,
        summary: str,
        queries: List[str],
        tasks: List[Dict]
    ) -> None:
        """ç™¼é€è¦åŠƒäº‹ä»¶ï¼ˆåŒ…å«æŸ¥è©¢åˆ—è¡¨å’Œä»»å‹™æè¿°ï¼‰"""
        # ä½¿ç”¨è‡ªå®šç¾©äº‹ä»¶æ ¼å¼
        import json
        from opencode.core.protocols import Event
        
        event = Event(
            type=EventType.PLAN,  # ä½¿ç”¨ PLAN äº‹ä»¶é¡å‹
            payload={
                "content": summary,
                "data": {
                    "type": "planning",  # å‰ç«¯ç”¨é€™å€‹åˆ¤æ–·
                    "summary": summary,
                    "queries": queries,
                    "tasks": tasks
                }
            },
            timestamp=time.time(),
            source="orchestrator",
            correlation_id=correlation_id
        )
        
        queue = self._response_callbacks.get(correlation_id)
        if queue:
            await queue.put(event)
    
    async def _emit_generating_event(
        self,
        correlation_id: str,
        context_count: int,
        source_count: int
    ) -> None:
        """ç™¼é€æ­£åœ¨ç”Ÿæˆå›ç­”çš„äº‹ä»¶"""
        from opencode.core.protocols import Event
        
        event = Event(
            type=EventType.THINKING,  # ä½¿ç”¨ THINKING é¡å‹ï¼Œå‰ç«¯æœƒè­˜åˆ¥ç‚º generating
            payload={
                "content": f"æ­£åœ¨æ ¹æ“š {context_count} æ®µå…§å®¹å’Œ {source_count} å€‹ä¾†æºç”Ÿæˆå›ç­”...",
                "data": {
                    "type": "generating",
                    "context_count": context_count,
                    "source_count": source_count
                }
            },
            timestamp=time.time(),
            source="orchestrator",
            correlation_id=correlation_id
        )
        
        queue = self._response_callbacks.get(correlation_id)
        if queue:
            await queue.put(event)
