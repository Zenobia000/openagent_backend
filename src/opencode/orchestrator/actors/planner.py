"""
Planner Actor - ä»»å‹™è¦åŠƒå™¨
å°‡ç”¨æˆ¶æ„åœ–åˆ†è§£ç‚ºå¯åŸ·è¡Œçš„ä»»å‹™åºåˆ—
"""

from typing import Dict, Any, Optional, List
import asyncio
import json
import logging
import os
from pathlib import Path

# ä½¿ç”¨çµ±ä¸€çš„è·¯å¾‘å·¥å…·è¼‰å…¥ç’°å¢ƒè®Šæ•¸
from opencode.core.utils import load_env, get_project_root
load_env()

from opencode.orchestrator.actors.base import Actor, ActorMessage
from opencode.core.protocols import Task, Intent

logger = logging.getLogger(__name__)


class PlannerActor(Actor):
    """
    è¦åŠƒ Actor
    
    è·è²¬:
    - åˆ†æç”¨æˆ¶æ„åœ–
    - é¸æ“‡åˆé©çš„å·¥å…·
    - å»ºç«‹ä»»å‹™åŸ·è¡Œè¨ˆç•«
    - è™•ç†ä»»å‹™ä¾è³´é—œä¿‚
    """
    
    def __init__(self, name: str = "planner", config: Optional[Dict[str, Any]] = None):
        super().__init__(name=name, config=config)
        
        self.llm_client = None
        self.model = config.get("model", "gpt-4o") if config else "gpt-4o"
        
        # å¯ç”¨å·¥å…·å®šç¾©
        self.available_tools = {
            "rag_search": {
                "service": "knowledge_base",
                "description": "åœ¨çŸ¥è­˜åº«ä¸­é€²è¡Œèªæ„æœå°‹",
                "parameters": ["query", "top_k"]
            },
            "rag_search_multiple": {
                "service": "knowledge_base", 
                "description": "ç”¨å¤šå€‹æŸ¥è©¢æœå°‹çŸ¥è­˜åº«",
                "parameters": ["queries", "top_k"]
            },
            "rag_ask": {
                "service": "knowledge_base",
                "description": "å‘çŸ¥è­˜åº«æå•ä¸¦ç²å¾— AI å›ç­”",
                "parameters": ["question", "top_k"]
            },
            "web_search": {
                "service": "web_search",
                "description": "æœå°‹ç¶²è·¯ç²å–æœ€æ–°è³‡è¨Šï¼Œé©åˆæŸ¥è©¢çŸ¥è­˜åº«æ²’æœ‰çš„å…§å®¹",
                "parameters": ["query", "max_results"]
            },
            "web_search_summarize": {
                "service": "web_search",
                "description": "æœå°‹ç¶²è·¯ä¸¦è‡ªå‹•æ‘˜è¦çµæœ",
                "parameters": ["query", "max_results"]
            },
            "sandbox_execute_python": {
                "service": "sandbox",
                "description": "å®‰å…¨åŸ·è¡Œ Python ç¨‹å¼ç¢¼ï¼Œæ”¯æ´ numpy, pandas, matplotlib ç­‰å¥—ä»¶",
                "parameters": ["code", "timeout"]
            },
            "execute_python": {
                "service": "sandbox",
                "description": "åŸ·è¡Œ Python ç¨‹å¼ç¢¼",
                "parameters": ["code", "timeout"]
            },
            "execute_bash": {
                "service": "sandbox",
                "description": "åŸ·è¡Œ Bash å‘½ä»¤",
                "parameters": ["command"]
            },
            "git_clone": {
                "service": "repo_ops",
                "description": "Clone Git å€‰åº«åˆ°æœ¬åœ°",
                "parameters": ["url", "path", "branch"]
            },
            "git_status": {
                "service": "repo_ops",
                "description": "æŸ¥çœ‹ Git å€‰åº«ç‹€æ…‹",
                "parameters": ["path"]
            },
            "git_commit": {
                "service": "repo_ops",
                "description": "æäº¤è®Šæ›´åˆ° Git",
                "parameters": ["path", "message", "files"]
            },
            "git_push": {
                "service": "repo_ops",
                "description": "æ¨é€è®Šæ›´åˆ°é ç«¯",
                "parameters": ["path", "remote", "branch"]
            },
            "git_pull": {
                "service": "repo_ops",
                "description": "å¾é ç«¯æ‹‰å–æ›´æ–°",
                "parameters": ["path", "remote", "branch"]
            },
            "git_log": {
                "service": "repo_ops",
                "description": "æŸ¥çœ‹ Git æäº¤æ­·å²",
                "parameters": ["path", "limit"]
            },
            "git_diff": {
                "service": "repo_ops",
                "description": "æŸ¥çœ‹ Git å·®ç•°",
                "parameters": ["path", "cached"]
            }
        }
        
        self.planning_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ™ºèƒ½ä»»å‹™è¦åŠƒå™¨ï¼Œè² è²¬ç†è§£ç”¨æˆ¶çš„å£èªåŒ–å•é¡Œä¸¦å°‡å…¶è½‰æ›ç‚ºç²¾ç¢ºçš„ä»»å‹™åºåˆ—ã€‚

## ä½ çš„æ ¸å¿ƒèƒ½åŠ›

### 1. èªæ„ç†è§£
- ç†è§£å£èªåŒ–ã€æ¨¡ç³Šçš„å•é¡Œè¡¨é”
- è­˜åˆ¥ç”¨æˆ¶çœŸæ­£æƒ³è¦çŸ¥é“ä»€éº¼
- å¾ä¸Šä¸‹æ–‡æ¨æ–·éš±å«çš„éœ€æ±‚

### 2. å•é¡Œæ‹†è§£
- å°‡è¤‡é›œå•é¡Œæ‹†è§£ç‚ºå¤šå€‹å­å•é¡Œ
- ç‚ºæ¯å€‹å­å•é¡Œç”Ÿæˆç²¾ç¢ºçš„æœå°‹æŸ¥è©¢
- ç¢ºä¿æŸ¥è©¢è¦†è“‹å•é¡Œçš„å„å€‹é¢å‘

### 3. æŸ¥è©¢å„ªåŒ–
- å°‡å£èªåŒ–è¡¨é”è½‰æ›ç‚ºç²¾ç¢ºçš„é—œéµè©
- ç”Ÿæˆå¤šç¨®è§’åº¦çš„æŸ¥è©¢ä»¥ç¢ºä¿å¬å›ç‡
- ä½¿ç”¨åŒç¾©è©å’Œç›¸é—œè¡“èªæ“´å±•æŸ¥è©¢

## å¯ç”¨å·¥å…·

{tools}

### å·¥å…·èªªæ˜

#### çŸ¥è­˜åº«å·¥å…· (æœå°‹å·²ä¸Šå‚³çš„æ–‡ä»¶)
- **rag_search_multiple**: å¤šè§’åº¦æœå°‹çŸ¥è­˜åº«ï¼Œé©åˆè¤‡é›œå•é¡Œ
- **rag_ask**: ç›´æ¥å•ç­”ï¼Œé©åˆç°¡å–®å•é¡Œ

#### ç¶²è·¯æœå°‹å·¥å…· (æœå°‹ç¶²è·¯æœ€æ–°è³‡è¨Š)
- **web_search**: æœå°‹ç¶²è·¯ï¼Œé©åˆæŸ¥è©¢çŸ¥è­˜åº«æ²’æœ‰çš„è³‡è¨Šã€æœ€æ–°æ¶ˆæ¯ã€å¤–éƒ¨çŸ¥è­˜
- **web_search_summarize**: æœå°‹ç¶²è·¯ä¸¦è‡ªå‹•æ‘˜è¦çµæœ

#### ç¨‹å¼ç¢¼åŸ·è¡Œå·¥å…· (sandbox_execute_python)
- æ”¯æ´ numpy, pandas, matplotlib, scipy, sklearn ç­‰å¥—ä»¶
- é©ç”¨æ–¼ï¼šæ•¸å­¸è¨ˆç®—ã€æ•¸æ“šåˆ†æã€ç”Ÿæˆåœ–è¡¨ã€è™•ç†æ•¸æ“š
- å°‡çµæœå­˜å…¥ `result` è®Šæ•¸æœƒè‡ªå‹•è¿”å›
- matplotlib åœ–è¡¨æœƒè‡ªå‹•æ•ç²

#### Git æ“ä½œå·¥å…·
- **git_clone**: Clone é ç«¯å€‰åº«åˆ°æœ¬åœ°
- **git_status**: æŸ¥çœ‹å€‰åº«ç‹€æ…‹
- **git_log**: æŸ¥çœ‹æäº¤æ­·å²
- **git_diff**: æŸ¥çœ‹æª”æ¡ˆå·®ç•°
- **git_commit**: æäº¤è®Šæ›´
- **git_push/git_pull**: æ¨é€/æ‹‰å–

## å£èªåŒ–å•é¡Œè½‰æ›ç¯„ä¾‹

ç”¨æˆ¶èªª: "é€™ç¯‡è«–æ–‡è¬›äº†ä»€éº¼"
â†’ æ‹†è§£ç‚º:
  - æœå°‹ "ä¸»è¦ç ”ç©¶å…§å®¹ ä¸»é¡Œ èƒŒæ™¯"
  - æœå°‹ "ç ”ç©¶æ–¹æ³• æŠ€è¡“æ–¹æ¡ˆ"
  - æœå°‹ "ä¸»è¦è²¢ç» çµè«– çµæœ"

ç”¨æˆ¶èªª: "CLIP æ˜¯æ€éº¼è¨“ç·´çš„"
â†’ æ‹†è§£ç‚º:
  - æœå°‹ "CLIP training method è¨“ç·´æ–¹æ³•"
  - æœå°‹ "contrastive learning loss function å°æ¯”å­¸ç¿’"
  - æœå°‹ "dataset training data è¨“ç·´æ•¸æ“š"

ç”¨æˆ¶èªª: "é€™å€‹æŠ€è¡“æœ‰ä»€éº¼å„ªç¼ºé»"
â†’ æ‹†è§£ç‚º:
  - æœå°‹ "advantages benefits å„ªé» å„ªå‹¢"
  - æœå°‹ "limitations disadvantages ç¼ºé» é™åˆ¶"
  - æœå°‹ "comparison benchmark æ¯”è¼ƒ æ€§èƒ½"

ç”¨æˆ¶èªª: "å¹«æˆ‘è¨ˆç®— 1+1" æˆ– "ç”¨ Python ç®—..."
â†’ ä½¿ç”¨ sandbox_execute_python åŸ·è¡Œç¨‹å¼ç¢¼

ç”¨æˆ¶èªª: "ç•«ä¸€å€‹åœ–è¡¨" æˆ– "ç”¨ matplotlib..."
â†’ ä½¿ç”¨ sandbox_execute_python ç”Ÿæˆåœ–è¡¨

ç”¨æˆ¶èªª: "æœ€è¿‘ AI æœ‰ä»€éº¼æ–°è" æˆ– "OpenAI æœ€æ–°å‹•æ…‹"
â†’ ä½¿ç”¨ web_search æœå°‹ç¶²è·¯

ç”¨æˆ¶èªª: "æœå°‹ä¸€ä¸‹ xxx æ˜¯ä»€éº¼" (ä¸”çŸ¥è­˜åº«æ²’æœ‰ç›¸é—œæ–‡ä»¶)
â†’ ä½¿ç”¨ web_search æœå°‹ç¶²è·¯

ç”¨æˆ¶èªª: "clone é€™å€‹ repo" æˆ– "ä¸‹è¼‰é€™å€‹å°ˆæ¡ˆ"
â†’ ä½¿ç”¨ git_clone

ç”¨æˆ¶èªª: "çœ‹ä¸€ä¸‹ git ç‹€æ…‹" æˆ– "æœ‰ä»€éº¼è®Šæ›´"
â†’ ä½¿ç”¨ git_status

## é‡è¦è¦å‰‡

1. **å§‹çµ‚ç”Ÿæˆå¤šå€‹æŸ¥è©¢**: å°æ–¼çŸ¥è­˜åº«å•é¡Œï¼Œè‡³å°‘ç”Ÿæˆ 2-3 å€‹ä¸åŒè§’åº¦çš„æœå°‹æŸ¥è©¢
2. **ä½¿ç”¨ rag_search_multiple**: ç•¶éœ€è¦å¤šè§’åº¦æœå°‹æ™‚ï¼Œä½¿ç”¨æ­¤å·¥å…·å‚³å…¥å¤šå€‹ queries
3. **ä½¿ç”¨ rag_ask**: ç•¶ç”¨æˆ¶éœ€è¦ç¶œåˆå›ç­”æ™‚ï¼ˆå¦‚ç¸½çµã€æ¯”è¼ƒã€è§£é‡‹ï¼‰
4. **ä½¿ç”¨ sandbox_execute_python**: ç•¶ç”¨æˆ¶éœ€è¦è¨ˆç®—ã€åˆ†ææ•¸æ“šã€ç”Ÿæˆåœ–è¡¨æ™‚
5. **ä½¿ç”¨ web_search**: ç•¶å•é¡Œèˆ‡çŸ¥è­˜åº«ç„¡é—œã€éœ€è¦æœ€æ–°è³‡è¨Šã€æˆ–æ˜ç¢ºè¦æ±‚æœå°‹ç¶²è·¯æ™‚
6. **ä½¿ç”¨ git_* å·¥å…·**: ç•¶ç”¨æˆ¶éœ€è¦æ“ä½œ Git å€‰åº«æ™‚
7. **æŸ¥è©¢è¦å…·é«”**: é¿å…å¤ªæ¨¡ç³Šçš„æŸ¥è©¢ï¼ŒåŠ å…¥å…·é«”çš„é—œéµè©
8. **ä¸­è‹±æ··åˆ**: å°æ–¼æŠ€è¡“å•é¡Œï¼ŒåŒæ™‚ä½¿ç”¨ä¸­è‹±æ–‡é—œéµè©

## è¼¸å‡ºæ ¼å¼

è«‹ä»¥ JSON æ ¼å¼è¿”å›è¨ˆç•«ï¼š
{{
    "analysis": "å°ç”¨æˆ¶æ„åœ–çš„æ·±å…¥åˆ†æ",
    "sub_questions": ["æ‹†è§£å‡ºçš„å­å•é¡Œ1", "å­å•é¡Œ2", ...],
    "tasks": [
        {{
            "id": "task_1",
            "tool": "å·¥å…·åç¨± (rag_search_multiple/rag_ask/sandbox_execute_python)",
            "parameters": {{
                "queries": ["æŸ¥è©¢1", "æŸ¥è©¢2"],  // for rag_search_multiple
                "question": "å•é¡Œ",              // for rag_ask
                "code": "python ä»£ç¢¼",           // for sandbox_execute_python
                "top_k": 5
            }},
            "dependencies": [],
            "description": "ä»»å‹™èªªæ˜"
        }}
    ],
    "reasoning": "ç‚ºä»€éº¼é€™æ¨£è¦åŠƒ"
}}

## ç‰¹æ®Šæƒ…æ³

- å¦‚æœå•é¡Œç°¡å–®ç›´æ¥ï¼Œå¯ä»¥åªç”¨ä¸€å€‹ rag_ask
- å¦‚æœç”¨æˆ¶æ˜ç¢ºæŒ‡å®šäº†æ–‡ä»¶ï¼Œç¢ºä¿ filters æ­£ç¢ºå‚³é
- å¦‚æœç”¨æˆ¶è¦æ±‚è¨ˆç®—æˆ–åˆ†æï¼Œä½¿ç”¨ sandbox_execute_python
- å°æ–¼å®Œå…¨ä¸ç›¸é—œçš„å•é¡Œï¼ˆå¦‚é–’èŠï¼‰ï¼Œè¿”å›ç©º tasks ä¸¦åœ¨ analysis ä¸­å‹å¥½å›æ‡‰"""
    
    async def on_start(self) -> None:
        """åˆå§‹åŒ– LLM å®¢æˆ¶ç«¯"""
        try:
            # ç¢ºä¿ .env å·²è¼‰å…¥
            load_env()
            
            from openai import AsyncOpenAI
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                self.llm_client = AsyncOpenAI(api_key=api_key)
                logger.info("Planner LLM client initialized")
            else:
                logger.error("OPENAI_API_KEY not set for Planner")
        except Exception as e:
            logger.error(f"Failed to initialize LLM client: {e}")
    
    async def handle_message(self, message: ActorMessage) -> Optional[Any]:
        """è™•ç†è¨Šæ¯"""
        content = message.content
        msg_type = content.get("type")
        
        if msg_type == "create_plan":
            intent = content.get("intent", {})
            plan = await self.create_plan(intent)
            
            # å›å‚³è¨ˆç•«çµ¦ parent (Orchestrator)
            if self.parent:
                await self.tell(self.parent, {
                    "type": "plan",
                    "plan": plan
                }, message.correlation_id)
            
            return plan
        
        return None
    
    async def create_plan(self, intent_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å»ºç«‹åŸ·è¡Œè¨ˆç•«
        
        Args:
            intent_data: æ„åœ–è³‡æ–™
            
        Returns:
            åŸ·è¡Œè¨ˆç•«
        """
        user_content = intent_data.get("content", "")
        context = intent_data.get("context", {})
        
        # å–å¾— selected_docs å’Œ attachments
        metadata = context.get("metadata", {})
        selected_docs = metadata.get("selected_docs", [])
        attachments = metadata.get("attachments", [])  # å¤šæ¨¡æ…‹é™„ä»¶
        
        logger.info(f"ğŸ“‹ ====== é–‹å§‹è¦åŠƒ ======")
        logger.info(f"ğŸ“‹ ç”¨æˆ¶è¼¸å…¥: {user_content[:100]}...")
        logger.info(f"ğŸ“‹ é¸å®šæ–‡ä»¶: {selected_docs}")
        logger.info(f"ğŸ“‹ é™„ä»¶æ•¸é‡: {len(attachments) if attachments else 0}")
        logger.info(f"ğŸ“‹ LLM å¯ç”¨: {self.llm_client is not None}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åœ–ç‰‡é™„ä»¶ - éœ€è¦ç‰¹æ®Šè™•ç†
        has_images = attachments and any(a.get('type') == 'image' for a in attachments)
        has_files = attachments and any(a.get('type') == 'file' for a in attachments)
        
        if has_images:
            logger.info(f"ğŸ“‹ æª¢æ¸¬åˆ°åœ–ç‰‡é™„ä»¶ï¼Œå°‡ä½¿ç”¨ Vision æ¨¡å¼")
            # å°æ–¼åœ–ç‰‡ï¼Œè¿”å›ä¸€å€‹ç‰¹æ®Šçš„ vision_analysis è¨ˆç•«
            return {
                "analysis": "ç”¨æˆ¶ä¸Šå‚³äº†åœ–ç‰‡ï¼Œéœ€è¦é€²è¡Œåœ–ç‰‡åˆ†æ",
                "is_simple": False,
                "needs_vision": True,
                "tasks": [{
                    "id": "task_vision",
                    "tool": "vision_analysis",
                    "service": "vision",
                    "description": "åˆ†æç”¨æˆ¶ä¸Šå‚³çš„åœ–ç‰‡",
                    "parameters": {
                        "query": user_content,
                        "images": [a for a in attachments if a.get('type') == 'image']
                    },
                    "dependencies": []
                }]
            }
        
        if has_files:
            logger.info(f"ğŸ“‹ æª¢æ¸¬åˆ°æª”æ¡ˆé™„ä»¶ï¼Œå°‡æå–å…§å®¹å¾Œåˆ†æ")
            # å°æ–¼æª”æ¡ˆï¼Œè¿”å› file_analysis è¨ˆç•«
            return {
                "analysis": "ç”¨æˆ¶ä¸Šå‚³äº†æª”æ¡ˆï¼Œéœ€è¦æå–å…§å®¹é€²è¡Œåˆ†æ",
                "is_simple": False,
                "needs_file_analysis": True,
                "tasks": [{
                    "id": "task_file_analysis",
                    "tool": "file_analysis",
                    "service": "file",
                    "description": "åˆ†æç”¨æˆ¶ä¸Šå‚³çš„æª”æ¡ˆ",
                    "parameters": {
                        "query": user_content,
                        "files": [a for a in attachments if a.get('type') == 'file']
                    },
                    "dependencies": []
                }]
            }
        
        # å»ºæ§‹å·¥å…·èªªæ˜
        tools_desc = "\n".join([
            f"- {name}: {info['description']} (åƒæ•¸: {', '.join(info['parameters'])})"
            for name, info in self.available_tools.items()
        ])
        
        # å»ºæ§‹æç¤º
        prompt = self.planning_prompt.format(tools=tools_desc)
        
        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": f"ç”¨æˆ¶æ„åœ–: {user_content}"}
        ]
        
        # åŠ å…¥å°è©±æ­·å² (å¦‚æœæœ‰)
        conversation_history = context.get("conversation_history", [])
        if conversation_history:
            history_text = "\n".join([
                f"{msg.get('role', 'user')}: {msg.get('content', '')}"
                for msg in conversation_history[-5:]  # æœ€è¿‘ 5 æ¢
            ])
            messages[1]["content"] += f"\n\næœ€è¿‘å°è©±:\n{history_text}"
        
        try:
            if self.llm_client is None:
                logger.info(f"ğŸ“‹ ä½¿ç”¨ç°¡å–®è¦åŠƒï¼ˆç„¡ LLMï¼‰")
                plan = self._simple_plan(user_content, selected_docs)
                logger.info(f"ğŸ“‹ ç°¡å–®è¦åŠƒçµæœ: {len(plan.get('tasks', []))} å€‹ä»»å‹™")
                for task in plan.get('tasks', []):
                    logger.info(f"  - {task.get('tool')}: {task.get('description')}")
                    logger.info(f"    åƒæ•¸: {task.get('parameters')}")
                return plan
            
            # å‘¼å« LLM
            logger.info(f"ğŸ“‹ å‘¼å« LLM é€²è¡Œè¦åŠƒ...")
            response = await self.llm_client.chat.completions.create(
                model=self.model,
                messages=messages,
                response_format={"type": "json_object"},
                temperature=0.7
            )
            
            # è¨˜éŒ„æˆæœ¬
            try:
                from opencode.control_plane.cost import get_cost_service, CostType
                cost_service = get_cost_service()
                usage = response.usage
                if usage:
                    cost_service.record_usage(
                        model=self.model,
                        cost_type=CostType.LLM_INPUT,
                        input_tokens=usage.prompt_tokens,
                        output_tokens=usage.completion_tokens,
                        action="planning"
                    )
            except Exception as cost_err:
                logger.warning(f"Cost tracking failed: {cost_err}")
            
            plan_json = json.loads(response.choices[0].message.content)
            logger.info(f"ğŸ“‹ LLM å›æ‡‰: {json.dumps(plan_json, ensure_ascii=False)[:200]}...")
            
            # é©—è­‰å’Œè£œå……è¨ˆç•«ï¼ˆå‚³å…¥ selected_docsï¼‰
            plan = self._validate_and_enrich_plan(plan_json, selected_docs)
            
            logger.info(f"ğŸ“‹ æœ€çµ‚è¨ˆç•«: {len(plan.get('tasks', []))} å€‹ä»»å‹™")
            for task in plan.get('tasks', []):
                logger.info(f"  - {task.get('tool')}: {task.get('description')}")
                logger.info(f"    åƒæ•¸: {task.get('parameters')}")
            return plan
            
        except Exception as e:
            logger.error(f"âŒ Planning error: {e}")
            import traceback
            logger.error(traceback.format_exc())
            # å›é€€åˆ°ç°¡å–®è¦åŠƒ
            return self._simple_plan(user_content, selected_docs)
    
    def _simple_plan(self, user_content: str, selected_docs: list = None) -> Dict[str, Any]:
        """
        æ™ºèƒ½ç°¡å–®è¦åŠƒ (ç•¶ LLM ä¸å¯ç”¨æ™‚)
        
        æ”¯æŒï¼š
        - å£èªåŒ–å•é¡Œç†è§£
        - è‡ªå‹•ç”Ÿæˆå¤šè§’åº¦æŸ¥è©¢
        - å¤šæ–‡ä»¶æŸ¥è©¢
        """
        content_lower = user_content.lower()
        tasks = []
        
        # å»ºæ§‹ filtersï¼ˆå¦‚æœæœ‰é¸å®šæ–‡ä»¶ï¼‰
        filters = None
        if selected_docs and len(selected_docs) > 0:
            filters = {"file_name": selected_docs}
        
        # å£èªåŒ–é—œéµè©æ˜ å°„
        query_expansions = {
            # è«–æ–‡/æ–‡ä»¶ç†è§£
            "è¬›äº†ä»€éº¼": ["ä¸»è¦å…§å®¹ ç ”ç©¶ä¸»é¡Œ èƒŒæ™¯ä»‹ç´¹", "ç ”ç©¶æ–¹æ³• æŠ€è¡“æ–¹æ¡ˆ", "ä¸»è¦è²¢ç» çµè«– çµæœ"],
            "æ˜¯ä»€éº¼": ["å®šç¾© æ¦‚å¿µ ä»‹ç´¹", "åŸç† æ©Ÿåˆ¶ æ–¹æ³•"],
            "ç ”ç©¶äº†ä»€éº¼": ["ç ”ç©¶ç›®æ¨™ ç ”ç©¶å•é¡Œ", "ç ”ç©¶æ–¹æ³• å¯¦é©—è¨­è¨ˆ", "ç ”ç©¶çµæœ ç™¼ç¾"],
            "æ€éº¼åš": ["æ–¹æ³• æ­¥é©Ÿ æµç¨‹", "å¯¦ç¾ æŠ€è¡“ ç®—æ³•"],
            "è¨“ç·´": ["training method è¨“ç·´æ–¹æ³•", "loss function æå¤±å‡½æ•¸", "dataset æ•¸æ“šé›†"],
            "å„ªç¼ºé»": ["advantages å„ªé» å„ªå‹¢", "limitations ç¼ºé» é™åˆ¶", "comparison æ¯”è¼ƒ"],
            "æ•ˆæœ": ["performance æ€§èƒ½", "results çµæœ æ•ˆæœ", "benchmark è©•ä¼°"],
            "å‰µæ–°": ["contribution è²¢ç» å‰µæ–°", "novel æ–°ç© æ”¹é€²"],
            "æ‡‰ç”¨": ["application æ‡‰ç”¨ å ´æ™¯", "use case ç”¨é€”"],
        }
        
        # æª¢æ¸¬æ˜¯å¦éœ€è¦å¤šæŸ¥è©¢
        queries = []
        matched_pattern = None
        
        for pattern, expansions in query_expansions.items():
            if pattern in content_lower:
                matched_pattern = pattern
                # ç”Ÿæˆå¤šè§’åº¦æŸ¥è©¢
                base_terms = user_content.replace(pattern, "").strip()
                for expansion in expansions:
                    if base_terms:
                        queries.append(f"{base_terms} {expansion}")
                    else:
                        queries.append(expansion)
                break
        
        # å¦‚æœæ²’æœ‰åŒ¹é…åˆ°æ¨¡å¼ï¼Œä½¿ç”¨åŸå§‹å•é¡Œç”Ÿæˆå¤šæŸ¥è©¢
        if not queries:
            # æå–é—œéµè©ä¸¦ç”Ÿæˆè®Šé«”
            keywords = [w for w in user_content.split() if len(w) > 1]
            queries = [user_content]  # åŸå§‹å•é¡Œ
            if len(keywords) > 0:
                queries.append(" ".join(keywords))  # åƒ…é—œéµè©
            # åŠ å…¥è‹±æ–‡é—œéµè©ï¼ˆå¦‚æœæœ‰ä¸­æ–‡ï¼‰
            if any('\u4e00' <= c <= '\u9fff' for c in user_content):
                queries.append(user_content)  # ä¿æŒåŸæ–‡
        
        # ç¢ºä¿è‡³å°‘æœ‰æŸ¥è©¢
        if not queries:
            queries = [user_content]
        
        # åˆ¤æ–·ä½¿ç”¨å“ªå€‹å·¥å…·
        is_question = any(kw in content_lower for kw in ["ä»€éº¼", "å¦‚ä½•", "ç‚ºä»€éº¼", "æ€éº¼", "?", "ï¼Ÿ", "å—", "å‘¢", "å‘Šè¨´æˆ‘", "è«‹å•", "è§£é‡‹"])
        is_search = any(kw in content_lower for kw in ["æœå°‹", "æ‰¾", "æŸ¥è©¢", "search", "find", "åˆ—å‡º"])
        is_bash = any(kw in content_lower for kw in ["åŸ·è¡Œ", "run", "bash", "shell", "å‘½ä»¤"])
        is_python = any(kw in content_lower for kw in ["python", "ç¨‹å¼ç¢¼", "code"])
        
        if is_bash:
            command = user_content.split("åŸ·è¡Œ")[-1].strip() if "åŸ·è¡Œ" in user_content else user_content
            tasks.append({
                "id": "task_1",
                "tool": "execute_bash",
                "parameters": {"command": command},
                "dependencies": [],
                "description": "åŸ·è¡Œå‘½ä»¤"
            })
        elif is_python:
            tasks.append({
                "id": "task_1",
                "tool": "execute_python",
                "parameters": {"code": user_content},
                "dependencies": [],
                "description": "åŸ·è¡Œ Python ç¨‹å¼"
            })
        elif is_search:
            # ç´”æœå°‹ - ä½¿ç”¨å¤šæŸ¥è©¢
            tasks.append({
                "id": "task_1",
                "tool": "rag_search_multiple",
                "parameters": {"queries": queries[:3], "top_k": 5, "filters": filters},
                "dependencies": [],
                "description": "å¤šè§’åº¦æœå°‹çŸ¥è­˜åº«"
            })
        else:
            # å•ç­”æ¨¡å¼ - å…ˆæœå°‹å†å›ç­”
            if len(queries) > 1:
                # å¤šæŸ¥è©¢æœå°‹
                tasks.append({
                    "id": "task_1",
                    "tool": "rag_search_multiple",
                    "parameters": {"queries": queries[:3], "top_k": 5, "filters": filters},
                    "dependencies": [],
                    "description": "å¤šè§’åº¦æœå°‹ç›¸é—œå…§å®¹"
                })
            # ç„¶å¾Œç”¨ rag_ask ç”Ÿæˆå›ç­”
            tasks.append({
                "id": "task_2" if len(queries) > 1 else "task_1",
                "tool": "rag_ask",
                "parameters": {"question": user_content, "top_k": 8, "filters": filters},
                "dependencies": ["task_1"] if len(queries) > 1 else [],
                "description": "æ ¹æ“šæœå°‹çµæœç”Ÿæˆå›ç­”"
            })
        
        return {
            "analysis": f"æ™ºèƒ½åˆ†æç”¨æˆ¶æ„åœ–ï¼Œç”Ÿæˆ {len(queries)} å€‹æŸ¥è©¢è§’åº¦",
            "sub_questions": queries,
            "tasks": tasks,
            "execution_order": [t["id"] for t in tasks],
            "reasoning": "åŸºæ–¼å£èªåŒ–ç†è§£çš„æ™ºèƒ½è¦åŠƒ"
        }
    
    def _validate_and_enrich_plan(self, plan: Dict[str, Any], selected_docs: list = None) -> Dict[str, Any]:
        """é©—è­‰å’Œè±å¯Œè¨ˆç•«"""
        tasks = plan.get("tasks", [])
        
        # å»ºæ§‹ filtersï¼ˆå¦‚æœæœ‰é¸å®šæ–‡ä»¶ï¼‰
        filters = None
        if selected_docs and len(selected_docs) > 0:
            filters = {"file_name": selected_docs}
        
        # ç¢ºä¿æ¯å€‹ä»»å‹™æœ‰å¿…è¦æ¬„ä½
        for i, task in enumerate(tasks):
            if "id" not in task:
                task["id"] = f"task_{i+1}"
            if "dependencies" not in task:
                task["dependencies"] = []
            if "description" not in task:
                task["description"] = f"åŸ·è¡Œ {task.get('tool', 'unknown')}"
            
            # é©—è­‰å·¥å…·æ˜¯å¦å­˜åœ¨
            tool = task.get("tool")
            if tool and tool in self.available_tools:
                task["service"] = self.available_tools[tool]["service"]
            
            # ç‚º RAG æœå°‹ä»»å‹™åŠ å…¥ filters
            if tool in ["rag_search", "rag_ask", "rag_search_multiple"] and filters:
                if "parameters" not in task:
                    task["parameters"] = {}
                task["parameters"]["filters"] = filters
        
        # è¨ˆç®—åŸ·è¡Œé †åº
        if "execution_order" not in plan:
            plan["execution_order"] = self._calculate_execution_order(tasks)
        
        return plan
    
    def _calculate_execution_order(self, tasks: List[Dict]) -> List[str]:
        """è¨ˆç®—ä»»å‹™åŸ·è¡Œé †åº (æ‹“æ’²æ’åº)"""
        if not tasks:
            return []
        
        task_map = {t["id"]: t for t in tasks}
        result = []
        remaining = set(task_map.keys())
        
        while remaining:
            # æ‰¾å‡ºæ²’æœ‰æœªå®Œæˆä¾è³´çš„ä»»å‹™
            ready = []
            for task_id in remaining:
                task = task_map[task_id]
                deps = set(task.get("dependencies", []))
                if not deps.intersection(remaining):
                    ready.append(task_id)
            
            if not ready:
                # å¯èƒ½æœ‰å¾ªç’°ä¾è³´ï¼Œå¼·åˆ¶å–ç¬¬ä¸€å€‹
                ready = [list(remaining)[0]]
            
            for task_id in ready:
                result.append(task_id)
                remaining.remove(task_id)
        
        return result
