"""
Retriever - Hybrid Search (å‘é‡ + BM25) + Cohere Rerank

ç‰¹é»ï¼š
1. èªç¾©æœå°‹ (Cohere/OpenAI Embedding + Qdrant)
2. å…¨æ–‡æª¢ç´¢ (BM25)
3. æ··åˆæ’åº (RRF - Reciprocal Rank Fusion)
4. Cohere Rerank é‡æ’åº (å¯é¸)
"""

import os
import logging
from typing import List, Dict, Any, Optional, Tuple
from collections import defaultdict

# ä½¿ç”¨çµ±ä¸€çš„è·¯å¾‘å·¥å…·è¼‰å…¥ç’°å¢ƒè®Šæ•¸
from opencode.core.utils import load_env
load_env()

logger = logging.getLogger(__name__)

# å…¨åŸŸå¯¦ä¾‹
_retriever_instance = None


class BM25Index:
    """
    ç°¡æ˜“ BM25 ç´¢å¼•
    
    ç”¨æ–¼å…¨æ–‡é—œéµå­—æª¢ç´¢ï¼Œè£œå……èªç¾©æœå°‹çš„ä¸è¶³
    ç‰¹åˆ¥é©ç”¨æ–¼ï¼š
    - å°ˆæœ‰åè© (å¦‚ BERT, GPT, RNN)
    - ç¸®å¯« (å¦‚ NLP, CV, RL)
    - ç²¾ç¢ºåŒ¹é…éœ€æ±‚
    """
    
    def __init__(self, k1: float = 1.5, b: float = 0.75):
        self.k1 = k1
        self.b = b
        self.documents = []       # [(doc_id, text, metadata), ...]
        self.doc_freqs = defaultdict(int)  # term -> document frequency
        self.doc_lens = []        # document lengths
        self.avg_doc_len = 0
        self.vocab = set()
        self._tokenized_docs = []
        self._initialized = False
    
    def _tokenize(self, text: str) -> List[str]:
        """ç°¡å–®åˆ†è© (æ”¯æ´ä¸­è‹±æ–‡)"""
        import re
        
        # è‹±æ–‡ï¼šæŒ‰ç©ºæ ¼å’Œæ¨™é»åˆ†è©ï¼Œè½‰å°å¯«
        # ä¸­æ–‡ï¼šæŒ‰å­—ç¬¦åˆ†è©
        tokens = []
        
        # å…ˆæå–è‹±æ–‡å–®è©
        words = re.findall(r'[a-zA-Z0-9]+', text.lower())
        tokens.extend(words)
        
        # æå–ä¸­æ–‡å­—ç¬¦
        chinese = re.findall(r'[\u4e00-\u9fff]+', text)
        for word in chinese:
            # ä¸­æ–‡æŒ‰ 2-gram åˆ†è©
            for i in range(len(word) - 1):
                tokens.append(word[i:i+2])
            if len(word) == 1:
                tokens.append(word)
        
        return tokens
    
    def build_index(self, documents: List[Tuple[str, str, Dict]]):
        """
        å»ºç«‹ BM25 ç´¢å¼•
        
        Args:
            documents: [(doc_id, text, metadata), ...]
        """
        self.documents = documents
        self._tokenized_docs = []
        self.doc_freqs = defaultdict(int)
        self.doc_lens = []
        self.vocab = set()
        
        # åˆ†è©ä¸¦çµ±è¨ˆ
        for doc_id, text, metadata in documents:
            tokens = self._tokenize(text)
            self._tokenized_docs.append(tokens)
            self.doc_lens.append(len(tokens))
            
            # æ›´æ–°è©é »
            unique_tokens = set(tokens)
            for token in unique_tokens:
                self.doc_freqs[token] += 1
                self.vocab.add(token)
        
        self.avg_doc_len = sum(self.doc_lens) / len(self.doc_lens) if self.doc_lens else 0
        self._initialized = True
        
        logger.info(f"ğŸ“š [BM25] ç´¢å¼•å»ºç«‹å®Œæˆ: {len(documents)} æ–‡æª”, {len(self.vocab)} è©å½™")
    
    def search(self, query: str, top_k: int = 10) -> List[Tuple[int, float]]:
        """
        BM25 æœå°‹
        
        Returns:
            [(doc_index, score), ...] æŒ‰åˆ†æ•¸é™åº
        """
        if not self._initialized or not self.documents:
            return []
        
        query_tokens = self._tokenize(query)
        scores = []
        n_docs = len(self.documents)
        
        for doc_idx, doc_tokens in enumerate(self._tokenized_docs):
            score = 0.0
            doc_len = self.doc_lens[doc_idx]
            
            # è¨ˆç®—æ¯å€‹ query term çš„ BM25 åˆ†æ•¸
            token_counts = defaultdict(int)
            for t in doc_tokens:
                token_counts[t] += 1
            
            for term in query_tokens:
                if term not in self.vocab:
                    continue
                
                tf = token_counts.get(term, 0)
                df = self.doc_freqs.get(term, 0)
                
                if tf == 0 or df == 0:
                    continue
                
                # IDF
                idf = max(0, (n_docs - df + 0.5) / (df + 0.5))
                import math
                idf = math.log(1 + idf)
                
                # TF normalization
                tf_norm = (tf * (self.k1 + 1)) / (tf + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len))
                
                score += idf * tf_norm
            
            if score > 0:
                scores.append((doc_idx, score))
        
        # æŒ‰åˆ†æ•¸æ’åº
        scores.sort(key=lambda x: x[1], reverse=True)
        return scores[:top_k]


class HybridRetriever:
    """
    æ··åˆæª¢ç´¢å™¨
    
    çµåˆèªç¾©æœå°‹å’Œ BM25 å…¨æ–‡æª¢ç´¢ï¼š
    1. èªç¾©æœå°‹ï¼šæ•æ‰èªç¾©ç›¸ä¼¼æ€§
    2. BM25 æœå°‹ï¼šæ•æ‰é—œéµå­—åŒ¹é…
    3. RRF èåˆï¼šåˆä½µå…©ç¨®çµæœ
    4. Cohere Rerankï¼šé€²ä¸€æ­¥å„ªåŒ–æ’åº (å¯é¸)
    
    é‡è¦ï¼šCohere æŸ¥è©¢æ™‚å¿…é ˆä½¿ç”¨ input_type="search_query"
    """
    
    def __init__(
        self,
        collection_name: str = "rag_knowledge_base",
        qdrant_url: str = "http://localhost:6333",
        use_rerank: bool = True
    ):
        self.collection_name = collection_name
        self.qdrant_url = qdrant_url
        self.use_rerank = use_rerank
        
        # API clients
        self.cohere_client = None
        self.openai_client = None
        self.qdrant_client = None
        
        # Embedding è¨­å®š
        self.embed_provider = None
        self.embed_model = None
        
        # BM25 ç´¢å¼•
        self.bm25_index = BM25Index()
        self._bm25_docs_cache = {}  # file_name -> docs
        
        self._initialize()
    
    def _initialize(self):
        """åˆå§‹åŒ– clients"""
        # ç¢ºä¿ç’°å¢ƒè®Šæ•¸å·²è¼‰å…¥
        load_env()
        
        cohere_key = os.getenv("COHERE_API_KEY")
        openai_key = os.getenv("OPENAI_API_KEY")
        
        # å„ªå…ˆä½¿ç”¨ Cohere
        if cohere_key:
            try:
                import cohere
                self.cohere_client = cohere.Client(api_key=cohere_key)
                self.embed_provider = "cohere"
                self.embed_model = os.getenv("COHERE_EMBED_MODEL", "embed-multilingual-v3.0")
                logger.info(f"âœ… [HybridRetriever] ä½¿ç”¨ Cohere embedding: {self.embed_model}")
                
                # æª¢æŸ¥æ˜¯å¦æœ‰ rerank æ¨¡å‹
                if self.use_rerank:
                    logger.info(f"âœ… [HybridRetriever] Rerank å·²å•Ÿç”¨ (rerank-multilingual-v3.0)")
            except ImportError:
                logger.warning("âš ï¸ [HybridRetriever] cohere å¥—ä»¶æœªå®‰è£")
            except Exception as e:
                logger.error(f"âŒ [HybridRetriever] Cohere åˆå§‹åŒ–å¤±æ•—: {e}")
        
        # å‚™ç”¨ï¼šOpenAI
        if not self.cohere_client and openai_key:
            try:
                from openai import OpenAI
                self.openai_client = OpenAI(api_key=openai_key)
                self.embed_provider = "openai"
                self.embed_model = "text-embedding-3-small"
                self.use_rerank = False  # OpenAI æ²’æœ‰ rerank
                logger.info(f"âœ… [HybridRetriever] ä½¿ç”¨ OpenAI embedding: {self.embed_model}")
            except ImportError:
                logger.warning("âš ï¸ [HybridRetriever] openai å¥—ä»¶æœªå®‰è£")
            except Exception as e:
                logger.error(f"âŒ [HybridRetriever] OpenAI åˆå§‹åŒ–å¤±æ•—: {e}")
        
        if not self.cohere_client and not self.openai_client:
            logger.error("âŒ [HybridRetriever] æ²’æœ‰å¯ç”¨çš„ embedding providerï¼")
            raise ValueError("éœ€è¦è¨­å®š COHERE_API_KEY æˆ– OPENAI_API_KEY")
        
        # åˆå§‹åŒ– Qdrant
        self._init_qdrant()
    
    def _init_qdrant(self):
        """åˆå§‹åŒ– Qdrant client"""
        try:
            from qdrant_client import QdrantClient
            self.qdrant_client = QdrantClient(url=self.qdrant_url)
            logger.info(f"âœ… [HybridRetriever] Qdrant é€£æ¥æˆåŠŸ: {self.qdrant_url}")
        except Exception as e:
            logger.error(f"âŒ [HybridRetriever] Qdrant åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    def _build_bm25_index_from_qdrant(self, filters: Optional[Dict[str, Any]] = None):
        """å¾ Qdrant è¼‰å…¥æ–‡æª”ä¸¦å»ºç«‹ BM25 ç´¢å¼•"""
        try:
            from qdrant_client.models import Filter, FieldCondition, MatchValue
            
            # å»ºæ§‹éæ¿¾æ¢ä»¶
            search_filter = None
            cache_key = str(filters) if filters else "all"
            
            # æª¢æŸ¥å¿«å–
            if cache_key in self._bm25_docs_cache:
                logger.info(f"ğŸ“š [BM25] ä½¿ç”¨å¿«å–ç´¢å¼•: {cache_key}")
                return
            
            if filters:
                conditions = []
                for key, value in filters.items():
                    if isinstance(value, list):
                        conditions.append(Filter(should=[
                            FieldCondition(key=key, match=MatchValue(value=v))
                            for v in value
                        ]))
                    else:
                        conditions.append(
                            FieldCondition(key=key, match=MatchValue(value=value))
                        )
                if conditions:
                    search_filter = Filter(must=conditions)
            
            # å¾ Qdrant è¼‰å…¥æ–‡æª”
            # æ³¨æ„ï¼šé€™è£¡åªè¼‰å…¥å‰ 1000 å€‹æ–‡æª”ï¼Œé¿å…è¨˜æ†¶é«”å•é¡Œ
            points, _ = self.qdrant_client.scroll(
                collection_name=self.collection_name,
                scroll_filter=search_filter,
                limit=1000,
                with_payload=True,
                with_vectors=False
            )
            
            # å»ºç«‹ç´¢å¼•
            documents = [
                (str(p.id), p.payload.get("text", ""), p.payload)
                for p in points
            ]
            
            self.bm25_index.build_index(documents)
            self._bm25_docs_cache[cache_key] = documents
            
        except Exception as e:
            logger.warning(f"âš ï¸ [BM25] ç´¢å¼•å»ºç«‹å¤±æ•—: {e}ï¼Œå°‡åªä½¿ç”¨èªç¾©æœå°‹")
    
    def get_query_embedding(self, query: str) -> List[float]:
        """å–å¾—æŸ¥è©¢çš„ embedding å‘é‡"""
        if self.cohere_client:
            return self._get_cohere_embedding(query)
        else:
            return self._get_openai_embedding(query)
    
    def _get_cohere_embedding(self, text: str) -> List[float]:
        """ä½¿ç”¨ Cohere å–å¾—æŸ¥è©¢ embedding"""
        try:
            response = self.cohere_client.embed(
                texts=[text],
                model=self.embed_model,
                input_type="search_query"
            )
            return response.embeddings[0]
        except Exception as e:
            logger.error(f"âŒ [HybridRetriever] Cohere embedding å¤±æ•—: {e}")
            raise
    
    def _get_openai_embedding(self, text: str) -> List[float]:
        """ä½¿ç”¨ OpenAI å–å¾— embedding"""
        try:
            response = self.openai_client.embeddings.create(
                model=self.embed_model,
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"âŒ [HybridRetriever] OpenAI embedding å¤±æ•—: {e}")
            raise
    
    def _vector_search(
        self,
        query: str,
        top_k: int = 20,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """ç´”å‘é‡èªç¾©æœå°‹"""
        from qdrant_client.models import Filter, FieldCondition, MatchValue
        
        query_vector = self.get_query_embedding(query)
        
        # å»ºæ§‹éæ¿¾æ¢ä»¶
        search_filter = None
        if filters:
            conditions = []
            for key, value in filters.items():
                if isinstance(value, list):
                    conditions.append(Filter(should=[
                        FieldCondition(key=key, match=MatchValue(value=v))
                        for v in value
                    ]))
                else:
                    conditions.append(
                        FieldCondition(key=key, match=MatchValue(value=value))
                    )
            if conditions:
                search_filter = Filter(must=conditions)
        
        results = self.qdrant_client.query_points(
            collection_name=self.collection_name,
            query=query_vector,
            query_filter=search_filter,
            limit=top_k,
            with_payload=True
        )
        
        return [
            {
                "id": str(p.id),
                "text": p.payload.get("text", ""),
                "file_name": p.payload.get("file_name", "unknown"),
                "page_label": p.payload.get("page_label", "?"),
                "score": p.score,
                "metadata": p.payload,
                "source": "vector"
            }
            for p in results.points
        ]
    
    def _bm25_search(
        self,
        query: str,
        top_k: int = 20,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """BM25 é—œéµå­—æœå°‹"""
        # å»ºç«‹/æ›´æ–° BM25 ç´¢å¼•
        self._build_bm25_index_from_qdrant(filters)
        
        cache_key = str(filters) if filters else "all"
        if cache_key not in self._bm25_docs_cache:
            return []
        
        documents = self._bm25_docs_cache[cache_key]
        results = self.bm25_index.search(query, top_k=top_k)
        
        return [
            {
                "id": documents[idx][0],
                "text": documents[idx][1],
                "file_name": documents[idx][2].get("file_name", "unknown"),
                "page_label": documents[idx][2].get("page_label", "?"),
                "score": score,
                "metadata": documents[idx][2],
                "source": "bm25"
            }
            for idx, score in results
        ]
    
    def _rrf_fusion(
        self,
        vector_results: List[Dict],
        bm25_results: List[Dict],
        k: int = 60
    ) -> List[Dict]:
        """
        Reciprocal Rank Fusion (RRF)
        
        åˆä½µå‘é‡æœå°‹å’Œ BM25 çµæœ
        RRF score = 1 / (k + rank)
        """
        scores = defaultdict(float)
        docs = {}
        
        # è™•ç†å‘é‡æœå°‹çµæœ
        for rank, doc in enumerate(vector_results):
            doc_id = doc["text"][:100]  # ç”¨å‰ 100 å­—ç¬¦ä½œç‚º ID
            scores[doc_id] += 1.0 / (k + rank + 1)
            if doc_id not in docs:
                docs[doc_id] = doc.copy()
                docs[doc_id]["vector_rank"] = rank + 1
                docs[doc_id]["bm25_rank"] = None
        
        # è™•ç† BM25 çµæœ
        for rank, doc in enumerate(bm25_results):
            doc_id = doc["text"][:100]
            scores[doc_id] += 1.0 / (k + rank + 1)
            if doc_id not in docs:
                docs[doc_id] = doc.copy()
                docs[doc_id]["vector_rank"] = None
                docs[doc_id]["bm25_rank"] = rank + 1
            else:
                docs[doc_id]["bm25_rank"] = rank + 1
        
        # æŒ‰ RRF åˆ†æ•¸æ’åº
        sorted_ids = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)
        
        results = []
        for doc_id in sorted_ids:
            doc = docs[doc_id]
            doc["rrf_score"] = scores[doc_id]
            results.append(doc)
        
        return results
    
    def _cohere_rerank(
        self,
        query: str,
        documents: List[Dict],
        top_k: int = 10
    ) -> List[Dict]:
        """
        ä½¿ç”¨ Cohere Rerank é‡æ’åº
        
        Rerank æ¨¡å‹æœƒæ ¹æ“š query å’Œ document çš„ç›¸é—œæ€§é‡æ–°æ‰“åˆ†
        ç‰¹åˆ¥æ“…é•·è™•ç†è¤‡é›œçš„èªç¾©é—œä¿‚
        """
        if not self.cohere_client or not self.use_rerank:
            return documents[:top_k]
        
        if not documents:
            return []
        
        try:
            # æº–å‚™æ–‡æª”
            texts = [doc["text"] for doc in documents]
            
            # èª¿ç”¨ Cohere Rerank
            response = self.cohere_client.rerank(
                model="rerank-multilingual-v3.0",
                query=query,
                documents=texts,
                top_n=top_k
            )
            
            # é‡æ–°æ’åº
            reranked = []
            for item in response.results:
                doc = documents[item.index].copy()
                doc["rerank_score"] = item.relevance_score
                doc["original_index"] = item.index
                reranked.append(doc)
            
            logger.info(f"âœ… [Rerank] é‡æ’åºå®Œæˆï¼Œè¿”å› top {len(reranked)}")
            return reranked
            
        except Exception as e:
            logger.warning(f"âš ï¸ [Rerank] å¤±æ•—: {e}ï¼Œä½¿ç”¨åŸå§‹æ’åº")
            return documents[:top_k]
    
    def search(
        self,
        query: str,
        top_k: int = 5,
        filters: Optional[Dict[str, Any]] = None,
        use_hybrid: bool = True,
        use_rerank: bool = None
    ) -> List[Dict[str, Any]]:
        """
        æ··åˆæœå°‹
        
        Args:
            query: æœå°‹æŸ¥è©¢
            top_k: è¿”å›çµæœæ•¸é‡
            filters: éæ¿¾æ¢ä»¶
            use_hybrid: æ˜¯å¦ä½¿ç”¨æ··åˆæœå°‹ (å‘é‡ + BM25)
            use_rerank: æ˜¯å¦ä½¿ç”¨ Rerank (None è¡¨ç¤ºä½¿ç”¨é è¨­è¨­å®š)
            
        Returns:
            æœå°‹çµæœåˆ—è¡¨
        """
        logger.info(f"ğŸ” [HybridRetriever] ====== é–‹å§‹æœå°‹ ======")
        logger.info(f"ğŸ” Query: {query[:50]}...")
        logger.info(f"ğŸ” Top-K: {top_k}, Hybrid: {use_hybrid}, Rerank: {use_rerank}")
        logger.info(f"ğŸ” Filters: {filters}")
        
        try:
            # 1. å‘é‡æœå°‹ (æ“´å¤§æœå°‹ç¯„åœçµ¦ rerank ç”¨)
            search_k = top_k * 4 if (use_rerank or self.use_rerank) else top_k * 2
            vector_results = self._vector_search(query, top_k=search_k, filters=filters)
            logger.info(f"âœ… å‘é‡æœå°‹: {len(vector_results)} çµæœ")
            
            if use_hybrid:
                # 2. BM25 æœå°‹
                bm25_results = self._bm25_search(query, top_k=search_k, filters=filters)
                logger.info(f"âœ… BM25 æœå°‹: {len(bm25_results)} çµæœ")
                
                # 3. RRF èåˆ
                fused_results = self._rrf_fusion(vector_results, bm25_results)
                logger.info(f"âœ… RRF èåˆ: {len(fused_results)} çµæœ")
            else:
                fused_results = vector_results
            
            # 4. Rerank (å¯é¸)
            should_rerank = use_rerank if use_rerank is not None else self.use_rerank
            if should_rerank and self.cohere_client:
                final_results = self._cohere_rerank(query, fused_results, top_k=top_k)
            else:
                final_results = fused_results[:top_k]
            
            # è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
            results = [
                {
                    "text": r["text"],
                    "file_name": r["file_name"],
                    "page_label": r["page_label"],
                    "score": r.get("rerank_score", r.get("rrf_score", r.get("score", 0))),
                    "metadata": r.get("metadata", {}),
                    "search_info": {
                        "vector_rank": r.get("vector_rank"),
                        "bm25_rank": r.get("bm25_rank"),
                        "rrf_score": r.get("rrf_score"),
                        "rerank_score": r.get("rerank_score"),
                        "source": r.get("source", "hybrid")
                    }
                }
                for r in final_results
            ]
            
            logger.info(f"âœ… [HybridRetriever] æœ€çµ‚è¿”å› {len(results)} çµæœ")
            for i, r in enumerate(results[:3]):
                logger.info(f"  [{i+1}] score={r['score']:.4f}, file={r['file_name']}")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ [HybridRetriever] æœå°‹å¤±æ•—: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []
    
    def search_multiple(
        self,
        queries: List[str],
        top_k: int = 3,
        filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """å¤šæŸ¥è©¢æœå°‹"""
        logger.info(f"ğŸ” [HybridRetriever] å¤šæŸ¥è©¢æœå°‹: {len(queries)} å€‹æŸ¥è©¢")
        
        all_results = []
        seen_texts = set()
        
        for query in queries:
            results = self.search(query, top_k=top_k, filters=filters)
            
            for r in results:
                text_key = r["text"][:100] if r["text"] else ""
                if text_key and text_key not in seen_texts:
                    seen_texts.add(text_key)
                    all_results.append(r)
        
        # æŒ‰åˆ†æ•¸æ’åº
        all_results.sort(key=lambda x: x.get("score", 0), reverse=True)
        
        logger.info(f"âœ… [HybridRetriever] å¤šæŸ¥è©¢æœå°‹å®Œæˆ: {len(all_results)} å€‹ä¸é‡è¤‡çµæœ")
        
        return {
            "queries": queries,
            "results": all_results,
            "total": len(all_results)
        }


# å‘å¾Œå…¼å®¹çš„åˆ¥å
Retriever = HybridRetriever


def get_retriever() -> HybridRetriever:
    """å–å¾—å…¨åŸŸ Retriever å¯¦ä¾‹"""
    global _retriever_instance
    if _retriever_instance is None:
        _retriever_instance = HybridRetriever()
    return _retriever_instance


def reset_retriever():
    """é‡ç½®å…¨åŸŸ Retriever å¯¦ä¾‹"""
    global _retriever_instance
    _retriever_instance = None
