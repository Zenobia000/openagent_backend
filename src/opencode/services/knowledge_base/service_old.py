"""
Knowledge Base Service - RAG çŸ¥è­˜åº«æœå‹™
å¾ rag-project é·ç§»ä¸¦å¢å¼·
"""

from typing import List, Dict, Any, Optional
import logging
import os
import uuid
from pathlib import Path

# ä½¿ç”¨çµ±ä¸€çš„è·¯å¾‘å·¥å…·è¼‰å…¥ç’°å¢ƒè®Šæ•¸
from opencode.core.utils import load_env, get_project_root
load_env()

from opencode.core.protocols import MCPServiceProtocol, LongTermMemoryProtocol

logger = logging.getLogger(__name__)


class KnowledgeBaseService(MCPServiceProtocol, LongTermMemoryProtocol):
    """
    çŸ¥è­˜åº«æœå‹™
    
    åŠŸèƒ½:
    - èªæ„æœå°‹ (rag_search)
    - å¤šæŸ¥è©¢æœå°‹ (rag_search_multiple)
    - å•ç­”ç”Ÿæˆ (rag_ask)
    - æ–‡ä»¶ç®¡ç† (upload, delete, list)
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self._service_id = "knowledge_base"
        self._capabilities = [
            "rag_search",
            "rag_search_multiple",
            "rag_ask",
            "document_upload",
            "document_delete",
            "document_list",
            "get_stats"
        ]
        
        # å®¢æˆ¶ç«¯
        self.qdrant_client = None
        self.openai_client = None
        
        # é…ç½®
        self.collection_name = self.config.get("collection", "rag_knowledge_base")
        self.qdrant_host = self.config.get("qdrant_host", "localhost")
        self.qdrant_port = self.config.get("qdrant_port", 6333)
        self.embedding_model = self.config.get("embedding_model", "text-embedding-3-small")
        self.chat_model = self.config.get("chat_model", "gpt-4o")
        
        self._initialized = False
    
    @property
    def service_id(self) -> str:
        return self._service_id
    
    @property
    def capabilities(self) -> List[str]:
        return self._capabilities
    
    async def initialize(self) -> None:
        """åˆå§‹åŒ–æœå‹™"""
        try:
            from qdrant_client import QdrantClient
            
            # å¼·åˆ¶é‡æ–°è¼‰å…¥ .envï¼ˆç¢ºä¿ç’°å¢ƒè®Šæ•¸å¯ç”¨ï¼‰
            load_dotenv(_env_path, override=True)
            
            # Qdrant å®¢æˆ¶ç«¯ (å¿…éœ€)
            self.qdrant_client = QdrantClient(
                host=self.qdrant_host,
                port=self.qdrant_port
            )
            
            # OpenAI å®¢æˆ¶ç«¯ (å¯é¸ï¼Œç”¨æ–¼ embedding)
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                from openai import AsyncOpenAI
                self.openai_client = AsyncOpenAI(api_key=api_key)
            else:
                logger.warning("OPENAI_API_KEY not set - search/ask features will be limited")
                self.openai_client = None
            
            # ç¢ºä¿ collection å­˜åœ¨
            await self._ensure_collection()
            
            self._initialized = True
            logger.info(f"âœ… {self.service_id} initialized")
            
        except Exception as e:
            logger.error(f"Failed to initialize {self.service_id}: {e}")
            raise
    
    async def execute(self, method: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        åŸ·è¡Œæ–¹æ³•
        
        Args:
            method: æ–¹æ³•åç¨±
            params: åƒæ•¸
            
        Returns:
            åŸ·è¡Œçµæœ
        """
        if not self._initialized:
            await self.initialize()
        
        if method == "rag_search":
            return await self._search(
                query=params.get("query", ""),
                top_k=params.get("top_k", 5),
                filters=params.get("filters")
            )
        
        elif method == "rag_search_multiple":
            return await self._search_multiple(
                queries=params.get("queries", []),
                top_k=params.get("top_k", 3),
                filters=params.get("filters")
            )
        
        elif method == "rag_ask":
            return await self._ask(
                question=params.get("question", ""),
                top_k=params.get("top_k", 5),
                filters=params.get("filters")
            )
        
        elif method == "document_list":
            return await self._list_documents()
        
        elif method == "document_delete":
            return await self._delete_document(params.get("document_name", ""))
        
        elif method == "get_stats":
            return await self._get_stats()
        
        else:
            raise ValueError(f"Unknown method: {method}")
    
    async def health_check(self) -> bool:
        """å¥åº·æª¢æŸ¥"""
        try:
            if self.qdrant_client:
                self.qdrant_client.get_collections()
            return True
        except:
            return False
    
    async def shutdown(self) -> None:
        """é—œé–‰æœå‹™"""
        logger.info(f"{self.service_id} shutdown")
    
    # ========== LongTermMemoryProtocol ==========
    
    async def store(
        self, 
        content: str, 
        metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """å„²å­˜å…§å®¹"""
        from qdrant_client.models import PointStruct
        
        doc_id = str(uuid.uuid4())
        embedding = await self._get_embedding(content)
        
        self.qdrant_client.upsert(
            collection_name=self.collection_name,
            points=[
                PointStruct(
                    id=doc_id,
                    vector=embedding,
                    payload={
                        "text": content,
                        **(metadata or {})
                    }
                )
            ]
        )
        
        return doc_id
    
    async def retrieve(
        self, 
        query: str, 
        top_k: int = 5,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """æª¢ç´¢å…§å®¹"""
        result = await self._search(query, top_k, filters)
        return result.get("results", [])
    
    async def delete(self, doc_id: str) -> bool:
        """åˆªé™¤å…§å®¹"""
        try:
            self.qdrant_client.delete(
                collection_name=self.collection_name,
                points_selector=[doc_id]
            )
            return True
        except:
            return False
    
    # ========== å…§éƒ¨æ–¹æ³• ==========
    
    async def _ensure_collection(self) -> None:
        """ç¢ºä¿ collection å­˜åœ¨"""
        from qdrant_client.models import VectorParams, Distance
        
        try:
            collections = self.qdrant_client.get_collections()
            names = [c.name for c in collections.collections]
            
            if self.collection_name not in names:
                self.qdrant_client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(
                        size=1536,  # text-embedding-3-small ç¶­åº¦
                        distance=Distance.COSINE
                    )
                )
                logger.info(f"Created collection: {self.collection_name}")
        except Exception as e:
            logger.warning(f"Could not ensure collection: {e}")
    
    async def _get_embedding(self, text: str) -> List[float]:
        """å–å¾—æ–‡å­—å‘é‡"""
        if self.openai_client is None:
            raise RuntimeError("OpenAI client not initialized. Please set OPENAI_API_KEY environment variable.")
        
        text = text.replace("\n", " ")
        response = await self.openai_client.embeddings.create(
            model=self.embedding_model,
            input=text
        )
        return response.data[0].embedding
    
    async def _search(
        self, 
        query: str, 
        top_k: int = 5,
        filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """èªæ„æœå°‹"""
        logger.info(f"ğŸ” é–‹å§‹æœå°‹: query='{query[:50]}...', top_k={top_k}, filters={filters}")
        
        if self.openai_client is None:
            logger.error("âŒ OpenAI client æœªåˆå§‹åŒ–")
            return {
                "query": query,
                "results": [],
                "sources": [],
                "error": "OPENAI_API_KEY æœªè¨­ç½®ï¼Œç„¡æ³•åŸ·è¡Œèªæ„æœå°‹"
            }
        
        from qdrant_client.models import Filter, FieldCondition, MatchValue
        
        try:
            query_vector = await self._get_embedding(query)
            logger.info(f"âœ… Embedding ç”ŸæˆæˆåŠŸ, ç¶­åº¦: {len(query_vector)}")
        except Exception as e:
            logger.error(f"âŒ Embedding ç”Ÿæˆå¤±æ•—: {e}")
            return {"query": query, "results": [], "sources": [], "error": str(e)}
        
        # å»ºæ§‹éæ¿¾æ¢ä»¶
        search_filter = None
        if filters:
            conditions = []
            for key, value in filters.items():
                logger.info(f"ğŸ“‹ å»ºæ§‹éæ¿¾æ¢ä»¶: {key}={value}")
                if isinstance(value, list):
                    # å¤šå€¼ç¯©é¸ (OR)
                    conditions.append(Filter(should=[
                        FieldCondition(key=key, match=MatchValue(value=v))
                        for v in value
                    ]))
                else:
                    conditions.append(
                        FieldCondition(key=key, match=MatchValue(value=value))
                    )
            if conditions:
                search_filter = Filter(must=conditions)
                logger.info(f"ğŸ“‹ éæ¿¾æ¢ä»¶å·²å»ºæ§‹: {len(conditions)} å€‹æ¢ä»¶")
        
        # åŸ·è¡Œæœå°‹
        try:
            results = self.qdrant_client.query_points(
                collection_name=self.collection_name,
                query=query_vector,
                query_filter=search_filter,
                limit=top_k,
                with_payload=True
            )
            logger.info(f"âœ… Qdrant æœå°‹å®Œæˆ, æ‰¾åˆ° {len(results.points)} å€‹çµæœ")
            
            # è©³ç´°è¨˜éŒ„æ¯å€‹çµæœ
            for i, p in enumerate(results.points):
                payload_keys = list(p.payload.keys()) if p.payload else []
                file_name = p.payload.get("file_name", "NOT_FOUND")
                text_preview = p.payload.get("text", "")[:50] if p.payload else ""
                logger.info(f"  [{i+1}] score={p.score:.4f}, file={file_name}, payload_keys={payload_keys}")
                logger.debug(f"      text_preview: {text_preview}...")
                
        except Exception as e:
            logger.error(f"âŒ Qdrant æœå°‹å¤±æ•—: {e}")
            return {"query": query, "results": [], "sources": [], "error": str(e)}
        
        return {
            "query": query,
            "results": [
                {
                    "text": p.payload.get("text", ""),
                    "file_name": p.payload.get("file_name", "unknown"),
                    "page_label": p.payload.get("page_label", "?"),
                    "score": p.score
                }
                for p in results.points
            ],
            "sources": [
                {
                    "file_name": p.payload.get("file_name", "unknown"),
                    "page_label": p.payload.get("page_label", "?"),
                    "score": p.score,
                    "summary": p.payload.get("text", "")[:100] + "..."
                }
                for p in results.points
            ]
        }
    
    async def _search_multiple(
        self, 
        queries: List[str], 
        top_k: int = 3,
        filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """å¤šæŸ¥è©¢æœå°‹ - æ”¯æŒå£èªåŒ–å•é¡Œçš„å¤šè§’åº¦æª¢ç´¢"""
        all_results = []
        all_sources = []
        seen_texts = set()  # ç”¨æ–¼å»é‡
        
        for query in queries:
            result = await self._search(query, top_k, filters)
            
            # æ”¶é›†çµæœä¸¦å»é‡
            unique_results = []
            for r in result["results"]:
                # ä½¿ç”¨æ–‡æœ¬çš„å‰100å­—ç¬¦ä½œç‚ºå»é‡éµ
                text_key = r["text"][:100] if r["text"] else ""
                if text_key and text_key not in seen_texts:
                    seen_texts.add(text_key)
                    unique_results.append(r)
                    
            all_results.append({
                "query": query,
                "results": unique_results
            })
            
            # æ”¶é›†ä¾†æºï¼ˆå»é‡ï¼‰
            for source in result.get("sources", []):
                key = (source.get("file_name", ""), source.get("page_label", ""))
                if key not in [(s.get("file_name"), s.get("page_label")) for s in all_sources]:
                    all_sources.append(source)
        
        return {
            "queries": queries,
            "results": all_results,
            "sources": all_sources,
            "total_unique_results": len(seen_texts)
        }
    
    async def _ask(
        self, 
        question: str, 
        top_k: int = 5,
        filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """å•ç­”ç”Ÿæˆ"""
        if self.openai_client is None:
            return {
                "answer": "éŒ¯èª¤ï¼šOPENAI_API_KEY æœªè¨­ç½®ï¼Œç„¡æ³•ä½¿ç”¨å•ç­”åŠŸèƒ½ã€‚",
                "sources": []
            }
        
        # å…ˆæœå°‹ï¼ˆå‚³å…¥ filtersï¼‰
        search_result = await self._search(question, top_k, filters)
        results = search_result.get("results", [])
        
        if not results:
            return {
                "answer": "çŸ¥è­˜åº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œè³‡è¨Šã€‚",
                "sources": []
            }
        
        # å»ºæ§‹ context
        context_parts = []
        for i, r in enumerate(results, 1):
            context_parts.append(
                f"[{i}] ä¾†æº: {r['file_name']} (é  {r['page_label']})\n{r['text']}"
            )
        context = "\n\n".join(context_parts)
        
        # ç”Ÿæˆå›ç­”
        messages = [
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ä¼æ¥­çŸ¥è­˜åº«åŠ©æ‰‹ã€‚æ ¹æ“šæä¾›çš„åƒè€ƒè³‡æ–™å›ç­”ç”¨æˆ¶å•é¡Œã€‚

è¦å‰‡ï¼š
- ç”¨ç¹é«”ä¸­æ–‡å›ç­”
- åŸºæ–¼åƒè€ƒè³‡æ–™å›ç­”ï¼Œä¸è¦ç·¨é€ 
- å›ç­”è¦æœ‰çµæ§‹ï¼Œæ¸…æ™°æ˜ç¢º
- å¦‚æœè³‡æ–™ä¸è¶³ä»¥å›ç­”ï¼Œèª å¯¦èªªæ˜"""
            },
            {
                "role": "user",
                "content": f"åƒè€ƒè³‡æ–™:\n{context}\n\nå•é¡Œ: {question}"
            }
        ]
        
        response = await self.openai_client.chat.completions.create(
            model=self.chat_model,
            messages=messages,
            temperature=0.7
        )
        
        answer = response.choices[0].message.content
        
        return {
            "answer": answer,
            "sources": search_result.get("sources", [])
        }
    
    async def _list_documents(self) -> Dict[str, Any]:
        """åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶"""
        try:
            # Scroll å–å¾—æ‰€æœ‰æ–‡ä»¶åç¨±
            documents = {}
            offset = None
            
            while True:
                results, offset = self.qdrant_client.scroll(
                    collection_name=self.collection_name,
                    limit=100,
                    offset=offset,
                    with_payload=True,
                    with_vectors=False
                )
                
                for point in results:
                    file_name = point.payload.get("file_name", "unknown")
                    if file_name not in documents:
                        documents[file_name] = {
                            "name": file_name,
                            "chunks": 0
                        }
                    documents[file_name]["chunks"] += 1
                
                if offset is None:
                    break
            
            return {
                "documents": list(documents.values()),
                "total": len(documents)
            }
            
        except Exception as e:
            logger.error(f"List documents failed: {e}")
            return {"documents": [], "total": 0, "error": str(e)}
    
    async def _delete_document(self, document_name: str) -> Dict[str, Any]:
        """åˆªé™¤æ–‡ä»¶"""
        from qdrant_client.models import Filter, FieldCondition, MatchValue
        
        try:
            self.qdrant_client.delete(
                collection_name=self.collection_name,
                points_selector=Filter(
                    must=[
                        FieldCondition(
                            key="file_name",
                            match=MatchValue(value=document_name)
                        )
                    ]
                )
            )
            
            logger.info(f"Deleted document: {document_name}")
            return {"success": True, "message": f"Deleted: {document_name}"}
            
        except Exception as e:
            logger.error(f"Delete document failed: {e}")
            return {"success": False, "error": str(e)}
    
    async def _get_stats(self) -> Dict[str, Any]:
        """å–å¾—çµ±è¨ˆè³‡è¨Š"""
        try:
            info = self.qdrant_client.get_collection(self.collection_name)
            docs = await self._list_documents()
            
            return {
                "document_count": docs.get("total", 0),
                "total_chunks": info.points_count,
                "vector_dim": info.config.params.vectors.size,
                "index_size": f"{info.points_count * 1536 * 4 / 1024:.1f} KB"
            }
        except Exception as e:
            return {"error": str(e)}
