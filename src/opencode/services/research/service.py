"""
Deep Research Service - æ·±åº¦ç ”ç©¶æœå‹™
æ”¯æ´è‡ªå‹•å­å•é¡Œç”Ÿæˆã€å¤šè¼ªæœå°‹ã€å ±å‘Šæ•´åˆ
"""

import os
import time
import asyncio
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path

# ä½¿ç”¨çµ±ä¸€çš„è·¯å¾‘å·¥å…·è¼‰å…¥ç’°å¢ƒè®Šæ•¸
from opencode.core.utils import load_env, get_project_root
load_env()

logger = logging.getLogger(__name__)


class ResearchStatus(Enum):
    """ç ”ç©¶ç‹€æ…‹"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class ResearchStep:
    """ç ”ç©¶æ­¥é©Ÿ"""
    step: str
    status: str = "pending"  # pending, running, done, error
    result: Optional[str] = None
    error: Optional[str] = None
    started_at: Optional[float] = None
    completed_at: Optional[float] = None


@dataclass
class ResearchTask:
    """ç ”ç©¶ä»»å‹™"""
    id: str
    topic: str
    documents: Optional[List[str]] = None
    status: ResearchStatus = ResearchStatus.PENDING
    progress: int = 0
    steps: List[ResearchStep] = field(default_factory=list)
    findings: List[Dict[str, Any]] = field(default_factory=list)
    sources: List[Dict[str, Any]] = field(default_factory=list)
    report: Optional[str] = None
    error: Optional[str] = None
    created_at: float = field(default_factory=time.time)
    completed_at: Optional[float] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "topic": self.topic,
            "documents": self.documents,
            "status": self.status.value,
            "progress": self.progress,
            "steps": [
                {
                    "step": s.step,
                    "status": s.status,
                    "result": s.result,
                    "error": s.error
                }
                for s in self.steps
            ],
            "findings_count": len(self.findings),
            "sources_count": len(self.sources),
            "report": self.report,
            "error": self.error,
            "created_at": datetime.fromtimestamp(self.created_at).isoformat(),
            "completed_at": datetime.fromtimestamp(self.completed_at).isoformat() if self.completed_at else None
        }


class ResearchService:
    """æ·±åº¦ç ”ç©¶æœå‹™"""
    
    def __init__(self):
        self.tasks: Dict[str, ResearchTask] = {}
        self._openai_client = None
        self._initialized = False
    
    async def initialize(self) -> None:
        """åˆå§‹åŒ–æœå‹™"""
        if self._initialized:
            return
        
        try:
            # å¼·åˆ¶é‡æ–°è¼‰å…¥ .envï¼ˆç¢ºä¿ç’°å¢ƒè®Šæ•¸å¯ç”¨ï¼‰
            load_env()
            
            from openai import OpenAI
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                self._openai_client = OpenAI(api_key=api_key)
                self._initialized = True
                logger.info("âœ… ResearchService initialized")
            else:
                logger.warning("âš ï¸ OPENAI_API_KEY not set, ResearchService limited")
        except Exception as e:
            logger.error(f"âŒ ResearchService init failed: {e}")
    
    async def start_research(
        self,
        topic: str,
        documents: Optional[List[str]] = None
    ) -> str:
        """
        å•Ÿå‹•æ·±åº¦ç ”ç©¶ä»»å‹™
        
        Args:
            topic: ç ”ç©¶ä¸»é¡Œ
            documents: é™å®šæ–‡ä»¶åˆ—è¡¨
            
        Returns:
            task_id
        """
        task_id = f"research_{int(time.time() * 1000)}"
        
        task = ResearchTask(
            id=task_id,
            topic=topic,
            documents=documents
        )
        
        self.tasks[task_id] = task
        
        # èƒŒæ™¯åŸ·è¡Œç ”ç©¶
        asyncio.create_task(self._run_research(task_id))
        
        return task_id
    
    async def get_task(self, task_id: str) -> Optional[ResearchTask]:
        """å–å¾—ç ”ç©¶ä»»å‹™"""
        return self.tasks.get(task_id)
    
    async def list_tasks(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰ç ”ç©¶ä»»å‹™"""
        return [
            {
                "task_id": tid,
                "topic": task.topic,
                "status": task.status.value,
                "progress": task.progress,
                "created_at": datetime.fromtimestamp(task.created_at).isoformat()
            }
            for tid, task in self.tasks.items()
        ]
    
    async def _run_research(self, task_id: str) -> None:
        """åŸ·è¡Œæ·±åº¦ç ”ç©¶"""
        task = self.tasks.get(task_id)
        if not task:
            return
        
        task.status = ResearchStatus.RUNNING
        
        try:
            # Step 1: åˆ†æä¸»é¡Œä¸¦ç”Ÿæˆå­å•é¡Œ
            task.steps.append(ResearchStep(
                step="ğŸ” åˆ†æç ”ç©¶ä¸»é¡Œ",
                status="running",
                started_at=time.time()
            ))
            task.progress = 5
            
            sub_questions = await self._generate_sub_questions(task.topic)
            
            task.steps[-1].status = "done"
            task.steps[-1].result = f"ç”Ÿæˆ {len(sub_questions)} å€‹å­å•é¡Œ"
            task.steps[-1].completed_at = time.time()
            task.progress = 15
            
            # Step 2: å°æ¯å€‹å­å•é¡Œé€²è¡Œç ”ç©¶
            progress_per_question = 60 / max(len(sub_questions), 1)
            
            for i, question in enumerate(sub_questions):
                task.steps.append(ResearchStep(
                    step=f"ğŸ“š ç ”ç©¶: {question[:50]}...",
                    status="running",
                    started_at=time.time()
                ))
                
                # æœå°‹ç›¸é—œå…§å®¹
                search_results = await self._search_for_research(question, task.documents)
                
                # ç”Ÿæˆå›ç­”
                if search_results:
                    answer = await self._generate_section_answer(question, search_results)
                    
                    task.findings.append({
                        "question": question,
                        "answer": answer,
                        "sources_count": len(search_results)
                    })
                    
                    # æ”¶é›†ä¾†æºï¼ˆå»é‡ï¼‰
                    for result in search_results:
                        source_key = f"{result.get('source', '')}_{result.get('page', '')}"
                        if not any(
                            f"{s.get('source', '')}_{s.get('page', '')}" == source_key 
                            for s in task.sources
                        ):
                            task.sources.append(result)
                    
                    task.steps[-1].result = f"æ‰¾åˆ° {len(search_results)} å€‹ç›¸é—œç‰‡æ®µ"
                else:
                    task.steps[-1].result = "æœªæ‰¾åˆ°ç›¸é—œè³‡æ–™"
                
                task.steps[-1].status = "done"
                task.steps[-1].completed_at = time.time()
                task.progress = int(15 + progress_per_question * (i + 1))
                
                # å°å»¶é²é¿å…éåº¦è«‹æ±‚
                await asyncio.sleep(0.5)
            
            # Step 3: ç”Ÿæˆæœ€çµ‚å ±å‘Š
            task.steps.append(ResearchStep(
                step="ğŸ“ æ’°å¯«ç ”ç©¶å ±å‘Š",
                status="running",
                started_at=time.time()
            ))
            task.progress = 85
            
            if task.findings:
                report = await self._generate_final_report(task.topic, task.findings)
                task.report = report
                task.steps[-1].result = "å ±å‘Šç”Ÿæˆå®Œæˆ"
            else:
                task.report = f"# {task.topic}\n\næœªèƒ½æ‰¾åˆ°è¶³å¤ çš„ç›¸é—œè³‡æ–™ä¾†ç”Ÿæˆå ±å‘Šã€‚"
                task.steps[-1].result = "è³‡æ–™ä¸è¶³ï¼Œç”ŸæˆåŸºç¤å ±å‘Š"
            
            task.steps[-1].status = "done"
            task.steps[-1].completed_at = time.time()
            task.progress = 100
            task.status = ResearchStatus.COMPLETED
            task.completed_at = time.time()
            
            logger.info(f"âœ… Research completed: {task_id}")
            
        except Exception as e:
            logger.error(f"âŒ Research failed: {e}")
            task.status = ResearchStatus.FAILED
            task.error = str(e)
            if task.steps:
                task.steps[-1].status = "error"
                task.steps[-1].error = str(e)
    
    async def _generate_sub_questions(self, topic: str) -> List[str]:
        """ç”Ÿæˆå­å•é¡Œ"""
        if not self._openai_client:
            return [topic]  # ç„¡ OpenAI æ™‚ç›´æ¥ç”¨åŸä¸»é¡Œ
        
        try:
            response = self._openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€å€‹ç ”ç©¶åŠ©æ‰‹ã€‚é‡å°çµ¦å®šçš„ç ”ç©¶ä¸»é¡Œï¼Œç”Ÿæˆ 3-5 å€‹å…·é«”çš„å­å•é¡Œï¼Œ
é€™äº›å•é¡Œæ‡‰è©²èƒ½å¹«åŠ©å…¨é¢äº†è§£é€™å€‹ä¸»é¡Œã€‚

æ¯è¡Œä¸€å€‹å•é¡Œï¼Œä¸è¦åŠ åºè™Ÿæˆ–ç¬¦è™Ÿã€‚"""
                    },
                    {"role": "user", "content": f"ç ”ç©¶ä¸»é¡Œï¼š{topic}"}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            questions = response.choices[0].message.content.strip().split('\n')
            return [
                q.strip().lstrip('0123456789.-â€¢) ')
                for q in questions 
                if q.strip() and len(q.strip()) > 5
            ][:5]  # æœ€å¤š 5 å€‹
            
        except Exception as e:
            logger.error(f"Generate sub-questions failed: {e}")
            return [topic]
    
    async def _search_for_research(
        self,
        query: str,
        documents: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """åŸ·è¡Œå‘é‡æœå°‹ï¼ˆä½¿ç”¨ Cohere embeddingï¼Œèˆ‡ RAG ç³»çµ±ä¸€è‡´ï¼‰"""
        try:
            from qdrant_client import QdrantClient
            from qdrant_client.models import Filter, FieldCondition, MatchValue
            import cohere
            
            # ç¢ºä¿ .env å·²è¼‰å…¥
            load_env()
            
            # ä½¿ç”¨ Cohere embeddingï¼ˆ1024 ç¶­ï¼Œèˆ‡ RAG ç³»çµ±ä¸€è‡´ï¼‰
            cohere_key = os.getenv("COHERE_API_KEY")
            if not cohere_key:
                logger.error("COHERE_API_KEY not set for search")
                return []
            
            client = QdrantClient(host="localhost", port=6333)
            cohere_client = cohere.Client(cohere_key)
            
            # ç”ŸæˆæŸ¥è©¢å‘é‡ï¼ˆä½¿ç”¨ Cohereï¼‰
            embed_response = cohere_client.embed(
                texts=[query],
                model="embed-multilingual-v3.0",
                input_type="search_query"
            )
            query_vector = embed_response.embeddings[0]
            
            # å»ºç«‹ç¯©é¸æ¢ä»¶
            search_filter = None
            if documents and len(documents) > 0:
                if len(documents) == 1:
                    search_filter = Filter(
                        must=[FieldCondition(key="file_name", match=MatchValue(value=documents[0]))]
                    )
                else:
                    search_filter = Filter(
                        should=[
                            FieldCondition(key="file_name", match=MatchValue(value=f))
                            for f in documents
                        ]
                    )
            
            # åŸ·è¡Œæœå°‹
            results = client.query_points(
                collection_name="rag_knowledge_base",
                query=query_vector,
                query_filter=search_filter,
                limit=5,
                with_payload=True
            )
            
            return [
                {
                    "content": point.payload.get("text", ""),
                    "source": point.payload.get("file_name", ""),
                    "page": point.payload.get("page_label", "1"),
                    "score": point.score
                }
                for point in results.points
            ]
            
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []
    
    async def _generate_section_answer(
        self,
        question: str,
        sources: List[Dict[str, Any]]
    ) -> str:
        """ç”Ÿæˆå–®å€‹å•é¡Œçš„ç­”æ¡ˆ"""
        if not self._openai_client:
            return "ç„¡æ³•ç”Ÿæˆç­”æ¡ˆï¼ˆOpenAI æœªé…ç½®ï¼‰"
        
        try:
            context = "\n\n".join([
                f"[ä¾†æº: {s['source']}, é ç¢¼: {s['page']}]\n{s['content']}"
                for s in sources
            ])
            
            response = self._openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "æ ¹æ“šæä¾›çš„è³‡æ–™ä¾†æºï¼Œå›ç­”å•é¡Œã€‚ä¿æŒå®¢è§€ã€æº–ç¢ºï¼Œä¸¦æ¨™è¨»é—œéµè³‡è¨Šçš„ä¾†æºã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"
                    },
                    {"role": "user", "content": f"å•é¡Œï¼š{question}\n\nåƒè€ƒè³‡æ–™ï¼š\n{context}"}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Generate answer failed: {e}")
            return f"ç”Ÿæˆç­”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
    
    async def _generate_final_report(
        self,
        topic: str,
        findings: List[Dict[str, Any]]
    ) -> str:
        """ç”Ÿæˆæœ€çµ‚å ±å‘Š"""
        if not self._openai_client:
            # ç„¡ OpenAI æ™‚ç”Ÿæˆç°¡å–®å ±å‘Š
            report = f"# {topic}\n\n## ç ”ç©¶ç™¼ç¾\n\n"
            for f in findings:
                report += f"### {f['question']}\n\n{f['answer']}\n\n"
            return report
        
        try:
            findings_text = "\n\n---\n\n".join([
                f"### {f['question']}\n\n{f['answer']}"
                for f in findings
            ])
            
            response = self._openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç ”ç©¶å ±å‘Šæ’°å¯«è€…ã€‚æ ¹æ“šæä¾›çš„ç ”ç©¶ç™¼ç¾ï¼Œç”Ÿæˆä¸€ä»½çµæ§‹å®Œæ•´çš„ç ”ç©¶å ±å‘Šã€‚

å ±å‘Šæ ¼å¼ï¼ˆä½¿ç”¨ Markdownï¼‰ï¼š
# æ¨™é¡Œ

## ğŸ“‹ åŸ·è¡Œæ‘˜è¦
ç°¡æ½”ç¸½çµä¸»è¦ç™¼ç¾ï¼ˆ3-5 å¥ï¼‰

## ğŸ” ä¸»è¦ç™¼ç¾
åˆ—å‡º 3-5 å€‹é—œéµç™¼ç¾

## ğŸ“– è©³ç´°åˆ†æ
æ•´åˆæ‰€æœ‰ç ”ç©¶ç™¼ç¾ï¼Œå½¢æˆé€£è²«çš„åˆ†æ

## ğŸ’¡ çµè«–èˆ‡å»ºè­°
ç¸½çµä¸¦æå‡ºå»ºè­°

ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«ã€‚"""
                    },
                    {"role": "user", "content": f"ç ”ç©¶ä¸»é¡Œï¼š{topic}\n\nç ”ç©¶ç™¼ç¾ï¼š\n{findings_text}"}
                ],
                temperature=0.4,
                max_tokens=3000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Generate report failed: {e}")
            # å¤±æ•—æ™‚è¿”å›ç°¡å–®å ±å‘Š
            report = f"# {topic}\n\n## ç ”ç©¶ç™¼ç¾\n\n"
            for f in findings:
                report += f"### {f['question']}\n\n{f['answer']}\n\n"
            return report


# å…¨åŸŸæœå‹™å¯¦ä¾‹
_research_service: Optional[ResearchService] = None


async def get_research_service() -> ResearchService:
    """å–å¾—ç ”ç©¶æœå‹™å–®ä¾‹"""
    global _research_service
    if _research_service is None:
        _research_service = ResearchService()
        await _research_service.initialize()
    return _research_service
