"""
Deep Research Service - æ·±åº¦ç ”ç©¶æœå‹™
æ”¯æ´è‡ªå‹•å­å•é¡Œç”Ÿæˆã€å¤šè¼ªæœå°‹ã€å ±å‘Šæ•´åˆ
"""

import os
import time
import asyncio
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path

# ä½¿ç”¨çµ±ä¸€çš„è·¯å¾‘å·¥å…·è¼‰å…¥ç’°å¢ƒè®Šæ•¸
from core.utils import load_env, get_project_root
from core.prompts import PromptTemplates
load_env()

logger = logging.getLogger(__name__)


class ResearchStatus(Enum):
    """ç ”ç©¶ç‹€æ…‹"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class ResearchStep:
    """ç ”ç©¶æ­¥é©Ÿ"""
    step: str
    status: str = "pending"  # pending, running, done, error
    result: Optional[str] = None
    error: Optional[str] = None
    started_at: Optional[float] = None
    completed_at: Optional[float] = None


@dataclass
class ResearchTask:
    """ç ”ç©¶ä»»å‹™"""
    id: str
    topic: str
    documents: Optional[List[str]] = None
    status: ResearchStatus = ResearchStatus.PENDING
    progress: int = 0
    steps: List[ResearchStep] = field(default_factory=list)
    findings: List[Dict[str, Any]] = field(default_factory=list)
    sources: List[Dict[str, Any]] = field(default_factory=list)
    report: Optional[str] = None
    error: Optional[str] = None
    created_at: float = field(default_factory=time.time)
    completed_at: Optional[float] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "topic": self.topic,
            "documents": self.documents,
            "status": self.status.value,
            "progress": self.progress,
            "steps": [
                {
                    "step": s.step,
                    "status": s.status,
                    "result": s.result,
                    "error": s.error
                }
                for s in self.steps
            ],
            "findings_count": len(self.findings),
            "sources_count": len(self.sources),
            "report": self.report,
            "error": self.error,
            "created_at": datetime.fromtimestamp(self.created_at).isoformat(),
            "completed_at": datetime.fromtimestamp(self.completed_at).isoformat() if self.completed_at else None
        }


class ResearchService:
    """æ·±åº¦ç ”ç©¶æœå‹™"""
    
    def __init__(self):
        self.tasks: Dict[str, ResearchTask] = {}
        self._openai_client = None
        self._initialized = False
    
    async def initialize(self) -> None:
        """åˆå§‹åŒ–æœå‹™"""
        if self._initialized:
            return
        
        try:
            # å¼·åˆ¶é‡æ–°è¼‰å…¥ .envï¼ˆç¢ºä¿ç’°å¢ƒè®Šæ•¸å¯ç”¨ï¼‰
            load_env()
            
            from openai import OpenAI
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                self._openai_client = OpenAI(api_key=api_key)
                self._initialized = True
                logger.info("âœ… ResearchService initialized")
            else:
                logger.warning("âš ï¸ OPENAI_API_KEY not set, ResearchService limited")
        except Exception as e:
            logger.error(f"âŒ ResearchService init failed: {e}")
    
    async def start_research(
        self,
        topic: str,
        documents: Optional[List[str]] = None
    ) -> str:
        """
        å•Ÿå‹•æ·±åº¦ç ”ç©¶ä»»å‹™
        
        Args:
            topic: ç ”ç©¶ä¸»é¡Œ
            documents: é™å®šæ–‡ä»¶åˆ—è¡¨
            
        Returns:
            task_id
        """
        task_id = f"research_{int(time.time() * 1000)}"
        
        task = ResearchTask(
            id=task_id,
            topic=topic,
            documents=documents
        )
        
        self.tasks[task_id] = task
        
        # èƒŒæ™¯åŸ·è¡Œç ”ç©¶
        asyncio.create_task(self._run_research(task_id))
        
        return task_id
    
    async def get_task(self, task_id: str) -> Optional[ResearchTask]:
        """å–å¾—ç ”ç©¶ä»»å‹™"""
        return self.tasks.get(task_id)
    
    async def list_tasks(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰ç ”ç©¶ä»»å‹™"""
        return [
            {
                "task_id": tid,
                "topic": task.topic,
                "status": task.status.value,
                "progress": task.progress,
                "created_at": datetime.fromtimestamp(task.created_at).isoformat()
            }
            for tid, task in self.tasks.items()
        ]
    
    async def _run_research(self, task_id: str) -> None:
        """åŸ·è¡Œæ·±åº¦ç ”ç©¶"""
        task = self.tasks.get(task_id)
        if not task:
            return
        
        task.status = ResearchStatus.RUNNING
        
        try:
            # Step 1: åˆ†æä¸»é¡Œä¸¦ç”Ÿæˆå­å•é¡Œ
            task.steps.append(ResearchStep(
                step="ğŸ” åˆ†æç ”ç©¶ä¸»é¡Œ",
                status="running",
                started_at=time.time()
            ))
            task.progress = 5
            
            sub_questions = await self._generate_sub_questions(task.topic)
            
            task.steps[-1].status = "done"
            task.steps[-1].result = f"ç”Ÿæˆ {len(sub_questions)} å€‹å­å•é¡Œ"
            task.steps[-1].completed_at = time.time()
            task.progress = 15
            
            # Step 2: å°æ¯å€‹å­å•é¡Œé€²è¡Œç ”ç©¶
            progress_per_question = 60 / max(len(sub_questions), 1)
            
            for i, question in enumerate(sub_questions):
                task.steps.append(ResearchStep(
                    step=f"ğŸ“š ç ”ç©¶: {question[:50]}...",
                    status="running",
                    started_at=time.time()
                ))
                
                # æœå°‹ç›¸é—œå…§å®¹
                search_results = await self._search_for_research(question, task.documents)
                
                # ç”Ÿæˆå›ç­”
                if search_results:
                    answer = await self._generate_section_answer(question, search_results)
                    
                    task.findings.append({
                        "question": question,
                        "answer": answer,
                        "sources_count": len(search_results)
                    })
                    
                    # æ”¶é›†ä¾†æºï¼ˆå»é‡ï¼‰
                    for result in search_results:
                        source_key = f"{result.get('source', '')}_{result.get('page', '')}"
                        if not any(
                            f"{s.get('source', '')}_{s.get('page', '')}" == source_key 
                            for s in task.sources
                        ):
                            task.sources.append(result)
                    
                    task.steps[-1].result = f"æ‰¾åˆ° {len(search_results)} å€‹ç›¸é—œç‰‡æ®µ"
                else:
                    task.steps[-1].result = "æœªæ‰¾åˆ°ç›¸é—œè³‡æ–™"
                
                task.steps[-1].status = "done"
                task.steps[-1].completed_at = time.time()
                task.progress = int(15 + progress_per_question * (i + 1))
                
                # å°å»¶é²é¿å…éåº¦è«‹æ±‚
                await asyncio.sleep(0.5)
            
            # Step 2.5: å¯©æŸ¥ç ”ç©¶é€²åº¦ï¼Œæ±ºå®šæ˜¯å¦éœ€è¦æ›´å¤šç ”ç©¶
            if task.findings and self._openai_client:
                task.steps.append(ResearchStep(
                    step="ğŸ” å¯©æŸ¥ç ”ç©¶é€²åº¦",
                    status="running",
                    started_at=time.time()
                ))
                task.progress = 75

                need_more_research = await self._review_research_progress(
                    topic=task.topic,
                    findings=task.findings,
                    documents=task.documents
                )

                if need_more_research:
                    task.steps[-1].result = "éœ€è¦è£œå……ç ”ç©¶"
                    task.steps[-1].status = "done"
                    task.steps[-1].completed_at = time.time()

                    # åŸ·è¡Œè£œå……ç ”ç©¶
                    for additional_query in need_more_research[:2]:  # é™åˆ¶è£œå……æŸ¥è©¢æ•¸é‡
                        task.steps.append(ResearchStep(
                            step=f"ğŸ”„ è£œå……ç ”ç©¶: {additional_query['query'][:30]}...",
                            status="running",
                            started_at=time.time()
                        ))

                        search_results = await self._search_for_research(
                            additional_query['query'],
                            task.documents
                        )

                        if search_results:
                            answer = await self._generate_section_answer(
                                additional_query['query'],
                                search_results
                            )
                            task.findings.append({
                                "question": additional_query['query'],
                                "answer": answer,
                                "sources_count": len(search_results)
                            })

                        task.steps[-1].status = "done"
                        task.steps[-1].completed_at = time.time()
                else:
                    task.steps[-1].result = "ç ”ç©¶è³‡æ–™å……è¶³"
                    task.steps[-1].status = "done"
                    task.steps[-1].completed_at = time.time()

            # Step 3: ç”Ÿæˆæœ€çµ‚å ±å‘Š
            task.steps.append(ResearchStep(
                step="ğŸ“ æ’°å¯«ç ”ç©¶å ±å‘Š",
                status="running",
                started_at=time.time()
            ))
            task.progress = 85
            
            if task.findings:
                report = await self._generate_final_report(task.topic, task.findings)
                task.report = report
                task.steps[-1].result = "å ±å‘Šç”Ÿæˆå®Œæˆ"
            else:
                task.report = f"# {task.topic}\n\næœªèƒ½æ‰¾åˆ°è¶³å¤ çš„ç›¸é—œè³‡æ–™ä¾†ç”Ÿæˆå ±å‘Šã€‚"
                task.steps[-1].result = "è³‡æ–™ä¸è¶³ï¼Œç”ŸæˆåŸºç¤å ±å‘Š"
            
            task.steps[-1].status = "done"
            task.steps[-1].completed_at = time.time()
            task.progress = 100
            task.status = ResearchStatus.COMPLETED
            task.completed_at = time.time()
            
            logger.info(f"âœ… Research completed: {task_id}")
            
        except Exception as e:
            logger.error(f"âŒ Research failed: {e}")
            task.status = ResearchStatus.FAILED
            task.error = str(e)
            if task.steps:
                task.steps[-1].status = "error"
                task.steps[-1].error = str(e)
    
    async def _generate_sub_questions(self, topic: str) -> List[str]:
        """ç”Ÿæˆå­å•é¡Œ - ä½¿ç”¨å°ˆæ¥­çš„ç³»çµ±å•é¡Œ prompt"""
        if not self._openai_client:
            return [topic]  # ç„¡ OpenAI æ™‚ç›´æ¥ç”¨åŸä¸»é¡Œ

        try:
            # ä½¿ç”¨å°ˆæ¥­çš„ç³»çµ±å•é¡Œæç¤ºè©
            prompt = PromptTemplates.get_system_question_prompt(topic)

            response = self._openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            questions = response.choices[0].message.content.strip().split('\n')
            return [
                q.strip().lstrip('0123456789.-â€¢) ')
                for q in questions 
                if q.strip() and len(q.strip()) > 5
            ][:5]  # æœ€å¤š 5 å€‹
            
        except Exception as e:
            logger.error(f"Generate sub-questions failed: {e}")
            return [topic]
    
    async def _search_for_research(
        self,
        query: str,
        documents: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """åŸ·è¡Œå‘é‡æœå°‹ï¼ˆä½¿ç”¨ Cohere embeddingï¼Œèˆ‡ RAG ç³»çµ±ä¸€è‡´ï¼‰"""
        try:
            from qdrant_client import QdrantClient
            from qdrant_client.models import Filter, FieldCondition, MatchValue
            import cohere
            
            # ç¢ºä¿ .env å·²è¼‰å…¥
            load_env()
            
            # ä½¿ç”¨ Cohere embeddingï¼ˆ1024 ç¶­ï¼Œèˆ‡ RAG ç³»çµ±ä¸€è‡´ï¼‰
            cohere_key = os.getenv("COHERE_API_KEY")
            if not cohere_key:
                logger.error("COHERE_API_KEY not set for search")
                return []
            
            client = QdrantClient(host="localhost", port=6333)
            cohere_client = cohere.Client(cohere_key)
            
            # ç”ŸæˆæŸ¥è©¢å‘é‡ï¼ˆä½¿ç”¨ Cohereï¼‰
            embed_response = cohere_client.embed(
                texts=[query],
                model="embed-multilingual-v3.0",
                input_type="search_query"
            )
            query_vector = embed_response.embeddings[0]
            
            # å»ºç«‹ç¯©é¸æ¢ä»¶
            search_filter = None
            if documents and len(documents) > 0:
                if len(documents) == 1:
                    search_filter = Filter(
                        must=[FieldCondition(key="file_name", match=MatchValue(value=documents[0]))]
                    )
                else:
                    search_filter = Filter(
                        should=[
                            FieldCondition(key="file_name", match=MatchValue(value=f))
                            for f in documents
                        ]
                    )
            
            # åŸ·è¡Œæœå°‹
            results = client.query_points(
                collection_name="rag_knowledge_base",
                query=query_vector,
                query_filter=search_filter,
                limit=5,
                with_payload=True
            )
            
            return [
                {
                    "content": point.payload.get("text", ""),
                    "source": point.payload.get("file_name", ""),
                    "page": point.payload.get("page_label", "1"),
                    "score": point.score
                }
                for point in results.points
            ]
            
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []
    
    async def _generate_section_answer(
        self,
        question: str,
        sources: List[Dict[str, Any]]
    ) -> str:
        """ç”Ÿæˆå–®å€‹å•é¡Œçš„ç­”æ¡ˆ - ä½¿ç”¨å°ˆæ¥­çš„æœç´¢çµæœ prompt"""
        if not self._openai_client:
            return "ç„¡æ³•ç”Ÿæˆç­”æ¡ˆï¼ˆOpenAI æœªé…ç½®ï¼‰"

        try:
            context = "\n\n".join([
                f"[ä¾†æº: {s['source']}, é ç¢¼: {s['page']}]\n{s['content']}"
                for s in sources
            ])

            # ä½¿ç”¨å°ˆæ¥­çš„æœç´¢çµæœæç¤ºè©
            prompt = PromptTemplates.get_search_result_prompt(
                query=question,
                research_goal="æä¾›è©³ç´°ã€æº–ç¢ºçš„ç ”ç©¶ç™¼ç¾",
                context=context
            )

            # åŠ ä¸Šå¼•ç”¨è¦å‰‡
            citation_rules = PromptTemplates.get_citation_rules()
            full_prompt = f"{prompt}\n\n{citation_rules}"

            response = self._openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "user", "content": full_prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Generate answer failed: {e}")
            return f"ç”Ÿæˆç­”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
    
    async def _generate_final_report(
        self,
        topic: str,
        findings: List[Dict[str, Any]]
    ) -> str:
        """ç”Ÿæˆæœ€çµ‚å ±å‘Š - ä½¿ç”¨å°ˆæ¥­çš„æœ€çµ‚å ±å‘Š prompt"""
        if not self._openai_client:
            # ç„¡ OpenAI æ™‚ç”Ÿæˆç°¡å–®å ±å‘Š
            report = f"# {topic}\n\n## ç ”ç©¶ç™¼ç¾\n\n"
            for f in findings:
                report += f"### {f['question']}\n\n{f['answer']}\n\n"
            return report

        try:
            # æº–å‚™ç ”ç©¶è¨ˆåŠƒ
            plan_prompt = PromptTemplates.get_report_plan_prompt(topic)
            plan_response = self._openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": plan_prompt}],
                temperature=0.3,
                max_tokens=1000
            )
            report_plan = plan_response.choices[0].message.content

            # æ•´ç†ç ”ç©¶ç™¼ç¾
            learnings = "\n\n".join([
                f"- {f['question']}ï¼š{f['answer'][:200]}..."
                for f in findings
            ])

            # æ•´ç†ä¾†æº
            sources_text = "\n".join([
                f"- [{i+1}] {f.get('source', 'Unknown source')}"
                for i, f in enumerate(findings)
            ])

            # ä½¿ç”¨å°ˆæ¥­çš„æœ€çµ‚å ±å‘Šæç¤ºè©
            final_prompt = PromptTemplates.get_final_report_prompt(
                plan=report_plan,
                learnings=learnings,
                sources=sources_text,
                images="",  # æš«æ™‚æ²’æœ‰åœ–ç‰‡
                requirement="ç”Ÿæˆè©³ç´°ã€å°ˆæ¥­çš„ç¹é«”ä¸­æ–‡ç ”ç©¶å ±å‘Šï¼ŒåŒ…å«åŸ·è¡Œæ‘˜è¦ã€ä¸»è¦ç™¼ç¾ã€è©³ç´°åˆ†æå’Œå»ºè­°ã€‚"
            )

            # åŠ ä¸Šå¼•ç”¨ã€åœ–ç‰‡å’Œè¼¸å‡ºè¦å‰‡
            references_prompt = PromptTemplates.get_final_report_references_prompt()
            image_prompt = PromptTemplates.get_final_report_citation_image_prompt()
            output_guidelines = PromptTemplates.get_output_guidelines()

            # çµ„åˆæ‰€æœ‰è¦å‰‡
            full_prompt = f"{final_prompt}\n\n{references_prompt}\n\n{image_prompt}\n\n{output_guidelines}"

            response = self._openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "user", "content": full_prompt}
                ],
                temperature=0.4,
                max_tokens=3000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Generate report failed: {e}")
            # å¤±æ•—æ™‚è¿”å›ç°¡å–®å ±å‘Š
            report = f"# {topic}\n\n## ç ”ç©¶ç™¼ç¾\n\n"
            for f in findings:
                report += f"### {f['question']}\n\n{f['answer']}\n\n"
            return report

    async def _review_research_progress(
        self,
        topic: str,
        findings: List[Dict[str, Any]],
        documents: Optional[List[str]] = None
    ) -> Optional[List[Dict[str, str]]]:
        """å¯©æŸ¥ç ”ç©¶é€²åº¦ - ä½¿ç”¨å°ˆæ¥­çš„å¯©æŸ¥ prompt"""
        if not self._openai_client:
            return None

        try:
            # æº–å‚™è¨ˆåŠƒ
            plan = f"ç ”ç©¶ä¸»é¡Œ: {topic}"
            if documents:
                plan += f"\né™å®šæ–‡ä»¶: {', '.join(documents)}"

            # æ•´ç†å·²æœ‰ç ”ç©¶ç™¼ç¾
            learnings = "\n\n".join([
                f"Q: {f['question']}\nA: {f['answer'][:200]}..."
                for f in findings
            ])

            # ç”¨æˆ¶å»ºè­°ï¼ˆé€™è£¡å¯ä»¥åŠ å…¥ç”¨æˆ¶è¼¸å…¥ï¼‰
            suggestion = "è«‹ç¢ºä¿æ¶µè“‹ä¸»é¡Œçš„æ‰€æœ‰é‡è¦æ–¹é¢"

            # å®šç¾© schema
            output_schema = {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string"},
                        "researchGoal": {"type": "string"}
                    }
                }
            }

            # ä½¿ç”¨å°ˆæ¥­çš„å¯©æŸ¥ prompt
            review_prompt = PromptTemplates.get_review_prompt(
                plan=plan,
                learnings=learnings,
                suggestion=suggestion,
                output_schema=output_schema
            )

            response = self._openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": review_prompt}],
                temperature=0.3,
                max_tokens=500
            )

            # è§£æ JSON å›æ‡‰
            import json
            import re
            content = response.choices[0].message.content
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', content)
            if json_match:
                queries = json.loads(json_match.group(1))
                return queries if queries else None
            return None

        except Exception as e:
            logger.error(f"Review research progress failed: {e}")
            return None


# å…¨åŸŸæœå‹™å¯¦ä¾‹
_research_service: Optional[ResearchService] = None


async def get_research_service() -> ResearchService:
    """å–å¾—ç ”ç©¶æœå‹™å–®ä¾‹"""
    global _research_service
    if _research_service is None:
        _research_service = ResearchService()
        await _research_service.initialize()
    return _research_service
