#!/usr/bin/env python3
"""
æ¸¬è©¦æ—¥èªŒä¸€è‡´æ€§ - ç¢ºä¿æ²’æœ‰é‡è¤‡çš„ icons
"""

import asyncio
from src.core.logger import structured_logger
# from src.core.models import LogCategory

async def simulate_log_output():
    """æ¨¡æ“¬å„ç¨®æ—¥èªŒè¼¸å‡ºï¼Œæª¢æŸ¥ä¸€è‡´æ€§"""

    print("=" * 80)
    print("ğŸ§ª æ¸¬è©¦æ—¥èªŒ Icon ä¸€è‡´æ€§")
    print("=" * 80)
    print("\nåŸå‰‡ï¼šæ¯ç¨®æ—¥èªŒé¡å‹åªæœ‰ä¸€å€‹çµ±ä¸€çš„ icon\n")

    # æ¨¡æ“¬å„ç¨®æ—¥èªŒ
    test_logs = [
        # ç³»çµ±æ—¥èªŒ
        ("ğŸš€ Initializing OpenCode Platform", "system", "initialize"),
        ("ğŸš€ Processing request: query...", "system", "process"),
        ("âœ… Processing completed", "system", "complete"),

        # LLM æ—¥èªŒ - åªæœ‰ä¸€å€‹ icon
        ("ğŸ¤– LLM Call: gpt-4o", "llm", "call"),

        # æ€è€ƒéšæ®µæ—¥èªŒ
        ("ğŸ” Stage 1: Problem Understanding", "thinking", "stage1"),
        ("ğŸ’­ Stage 1 Result: [analysis...]", "thinking", "stage1_result"),

        # æœç´¢æ—¥èªŒ
        ("ğŸ” Generating search queries...", "search", "query_generation"),
        ("ğŸŒ Searching 1/3: query1...", "search", "performing"),
        ("âœ… Search complete", "search", "complete"),

        # çŸ¥è­˜åº«æ—¥èªŒ
        ("ğŸ”¢ Generating embeddings...", "knowledge", "embedding"),
        ("ğŸ“š RAG Search in knowledge base...", "rag", "search"),
        ("ğŸ“– Found 5 relevant documents", "rag", "results"),

        # æ·±åº¦ç ”ç©¶æ—¥èªŒ
        ("ğŸ“ Creating research plan...", "deep_research", "planning"),
        ("ğŸ“‹ Executing 5 search tasks...", "deep_research", "tasks"),
        ("ğŸ“‘ Writing final report...", "deep_research", "final_report"),

        # å·¥å…·æ±ºç­–
        ("ğŸ”§ Tool Decision: deep_thinking", "tool", "decision"),

        # æ€§èƒ½æ—¥èªŒ
        ("âš¡ process_thinking", "perf", "timing"),

        # éŒ¯èª¤æ—¥èªŒ
        ("âŒ Error occurred: exception", "error", "exception"),
    ]

    print("ğŸ“‹ æ¨™æº–æ—¥èªŒæ ¼å¼ï¼š\n")
    print("-" * 40)

    for message, category, context in test_logs:
        print(f"[{category:15}] {message}")

    print("\n" + "=" * 80)
    print("âœ… æª¢æŸ¥çµæœï¼š")
    print("-" * 40)

    # æª¢æŸ¥é‡è¤‡
    icons = {}
    duplicates = []

    for message, category, context in test_logs:
        icon = message.split()[0] if message else ""
        if icon and icon[0] in "ğŸš€âœ…ğŸ¤–ğŸ”ğŸ’­ğŸŒğŸ”¢ğŸ“šğŸ“–ğŸ“ğŸ“‹ğŸ“‘ğŸ”§âš¡âŒ":
            if category not in icons:
                icons[category] = icon
            elif icons[category] != icon and category not in ["system", "search", "rag", "deep_research"]:
                duplicates.append(f"{category}: {icons[category]} vs {icon}")

    if duplicates:
        print("âš ï¸  ç™¼ç¾é‡è¤‡ iconsï¼š")
        for dup in duplicates:
            print(f"  - {dup}")
    else:
        print("âœ… æ²’æœ‰ç™¼ç¾é‡è¤‡çš„ icons")
        print("\næ¯å€‹é¡åˆ¥çš„æ¨™æº– iconï¼š")
        for cat, icon in sorted(icons.items()):
            print(f"  {cat:15} â†’ {icon}")

    print("=" * 80)

async def show_before_after():
    """å±•ç¤ºä¿®æ”¹å‰å¾Œçš„å°æ¯”"""

    print("\n\nğŸ“Š ä¿®æ”¹å‰å¾Œå°æ¯”")
    print("=" * 80)

    print("âŒ ä¿®æ”¹å‰ï¼ˆæœ‰é‡è¤‡ï¼‰ï¼š")
    print("-" * 40)
    print("[INFO] ğŸ¤– LLM Call: gpt-4o [tokens=1425, time=15929ms]")
    print("[INFO] ğŸ¤– LLM Response: ## 1. Problem Understanding...")
    print("       ^^^ å…©å€‹ ğŸ¤– é‡è¤‡äº†ï¼")

    print("\nâœ… ä¿®æ”¹å¾Œï¼ˆçµ±ä¸€ï¼‰ï¼š")
    print("-" * 40)
    print("[INFO] ğŸ¤– LLM Call: gpt-4o [tokens=1425, time=15929ms]")
    print("       ^^^ åªæœ‰ä¸€å€‹ ğŸ¤– icon")

    print("\n" + "=" * 80)

async def main():
    """ä¸»å‡½æ•¸"""

    # æ¸¬è©¦æ—¥èªŒä¸€è‡´æ€§
    await simulate_log_output()

    # å±•ç¤ºä¿®æ”¹å‰å¾Œå°æ¯”
    await show_before_after()

    print("\nâœ¨ æ—¥èªŒ Icon å·²çµ±ä¸€ï¼")

if __name__ == "__main__":
    asyncio.run(main())