#!/usr/bin/env python3
"""
Test script for parallel search optimization
"""

import asyncio
import time
from typing import List, Dict
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ¨¡æ“¬æœç´¢é…ç½®
from dataclasses import dataclass
from enum import Enum


class SearchProviderType(Enum):
    TAVILY = "tavily"
    EXA = "exa"
    SERPER = "serper"
    DUCKDUCKGO = "duckduckgo"
    BING = "bing"


@dataclass
class SearchEngineConfig:
    """æœç´¢å¼•æ“é…ç½®"""
    primary: SearchProviderType = SearchProviderType.TAVILY
    fallback_chain: List[SearchProviderType] = None
    max_results: int = 10
    timeout: float = 30.0
    parallel_searches: int = 3
    enable_race_mode: bool = False
    enable_batch_parallel: bool = True
    batch_size: int = 3
    parallel_strategy: str = "batch"  # batch | race | hybrid

    def __post_init__(self):
        if self.fallback_chain is None:
            self.fallback_chain = [
                SearchProviderType.EXA,
                SearchProviderType.SERPER,
                SearchProviderType.DUCKDUCKGO
            ]

        # æ ¹æ“šç­–ç•¥è¨­ç½®å°æ‡‰çš„æ¨™èªŒ
        if self.parallel_strategy == "race":
            self.enable_race_mode = True
            self.enable_batch_parallel = False
        elif self.parallel_strategy == "batch":
            self.enable_race_mode = False
            self.enable_batch_parallel = True
        elif self.parallel_strategy == "hybrid":
            self.enable_race_mode = True
            self.enable_batch_parallel = True


# æ¨¡æ“¬æœç´¢å‡½æ•¸
async def mock_search_provider(provider: str, query: str, delay: float = 1.0) -> Dict:
    """æ¨¡æ“¬æœç´¢æä¾›å•†"""
    start_time = time.time()
    await asyncio.sleep(delay)  # æ¨¡æ“¬ç¶²çµ¡å»¶é²

    return {
        "provider": provider,
        "query": query,
        "sources": [f"Result {i} from {provider}" for i in range(3)],
        "time": time.time() - start_time
    }


async def test_batch_parallel_search(queries: List[str], config: SearchEngineConfig):
    """æ¸¬è©¦æ‰¹æ¬¡å¹³è¡Œæœç´¢"""
    logger.info(f"\n{'='*60}")
    logger.info(f"Testing BATCH PARALLEL search")
    logger.info(f"Queries: {queries}")
    logger.info(f"Batch size: {config.batch_size}")
    logger.info(f"{'='*60}")

    start_time = time.time()
    results = []

    # åˆ†æ‰¹åŸ·è¡Œ
    for i in range(0, len(queries), config.batch_size):
        batch = queries[i:i+config.batch_size]
        logger.info(f"\nBatch {i//config.batch_size + 1}: {batch}")

        # ä¸¦è¡ŒåŸ·è¡Œæ‰¹æ¬¡å…§çš„æœç´¢
        batch_tasks = [
            mock_search_provider("tavily", query, delay=1.0)
            for query in batch
        ]

        batch_results = await asyncio.gather(*batch_tasks)
        results.extend(batch_results)

        for result in batch_results:
            logger.info(f"  âœ… {result['query']} - {result['provider']} - {result['time']:.2f}s")

    total_time = time.time() - start_time
    logger.info(f"\nğŸ“Š Batch Parallel Summary:")
    logger.info(f"  Total queries: {len(queries)}")
    logger.info(f"  Total time: {total_time:.2f}s")
    logger.info(f"  Average time per query: {total_time/len(queries):.2f}s")

    return results


async def test_race_mode_search(query: str, config: SearchEngineConfig):
    """æ¸¬è©¦ç«¶é€Ÿæ¨¡å¼æœç´¢"""
    logger.info(f"\n{'='*60}")
    logger.info(f"Testing RACE MODE search")
    logger.info(f"Query: {query}")
    logger.info(f"Providers: {[p.value for p in [config.primary] + config.fallback_chain]}")
    logger.info(f"{'='*60}")

    start_time = time.time()

    # å‰µå»ºæ‰€æœ‰æœç´¢ä»»å‹™ï¼ˆä¸åŒå»¶é²æ¨¡æ“¬ä¸åŒé€Ÿåº¦ï¼‰
    providers = [config.primary] + config.fallback_chain
    search_tasks = [
        asyncio.create_task(
            mock_search_provider(provider.value, query, delay=(i+1)*0.5)
        )
        for i, provider in enumerate(providers)
    ]

    logger.info(f"\nğŸ Starting race with {len(providers)} providers...")

    # ä½¿ç”¨ as_completed ç²å–ç¬¬ä¸€å€‹å®Œæˆçš„çµæœ
    done, pending = await asyncio.wait(search_tasks, return_when=asyncio.FIRST_COMPLETED)

    # ç²å–ç¬¬ä¸€å€‹å®Œæˆçš„çµæœ
    result = await list(done)[0]
    total_time = time.time() - start_time
    logger.info(f"\nğŸ† Winner: {result['provider']} - {result['time']:.2f}s")
    logger.info(f"Total race time: {total_time:.2f}s")

    # å–æ¶ˆå…¶ä»–æœªå®Œæˆçš„ä»»å‹™
    for task in pending:
        task.cancel()

    return result

    return None


async def test_hybrid_mode(queries: List[str], config: SearchEngineConfig):
    """æ¸¬è©¦æ··åˆæ¨¡å¼ï¼šæ‰¹æ¬¡åŸ·è¡Œ + æ¯å€‹æŸ¥è©¢ä½¿ç”¨ç«¶é€Ÿ"""
    logger.info(f"\n{'='*60}")
    logger.info(f"Testing HYBRID MODE search")
    logger.info(f"Queries: {queries}")
    logger.info(f"Batch size: {config.batch_size}")
    logger.info(f"Race mode per query: True")
    logger.info(f"{'='*60}")

    start_time = time.time()
    results = []

    # åˆ†æ‰¹åŸ·è¡Œ
    for i in range(0, len(queries), config.batch_size):
        batch = queries[i:i+config.batch_size]
        logger.info(f"\nBatch {i//config.batch_size + 1}: {batch}")

        # æ¯å€‹æŸ¥è©¢éƒ½ä½¿ç”¨ç«¶é€Ÿæ¨¡å¼
        batch_tasks = []
        for query in batch:
            # ç‚ºæ¯å€‹æŸ¥è©¢å‰µå»ºç«¶é€Ÿä»»å‹™
            providers = [config.primary] + config.fallback_chain[:2]  # é™åˆ¶æä¾›å•†æ•¸é‡
            race_tasks = [
                mock_search_provider(provider.value, query, delay=(j+1)*0.3)
                for j, provider in enumerate(providers)
            ]
            batch_tasks.append(asyncio.create_task(
                get_first_result(query, race_tasks)
            ))

        batch_results = await asyncio.gather(*batch_tasks)
        results.extend(batch_results)

        for result in batch_results:
            logger.info(f"  âœ… {result['query']} - Winner: {result['provider']} - {result['time']:.2f}s")

    total_time = time.time() - start_time
    logger.info(f"\nğŸ“Š Hybrid Mode Summary:")
    logger.info(f"  Total queries: {len(queries)}")
    logger.info(f"  Total time: {total_time:.2f}s")
    logger.info(f"  Average time per query: {total_time/len(queries):.2f}s")

    return results


async def get_first_result(query: str, race_tasks: List):
    """ç²å–ç¬¬ä¸€å€‹å®Œæˆçš„çµæœ"""
    # å‰µå»ºä»»å‹™
    tasks = [asyncio.create_task(t) for t in race_tasks]

    # ç­‰å¾…ç¬¬ä¸€å€‹å®Œæˆ
    done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)

    # ç²å–çµæœ
    if done:
        result = await list(done)[0]
        # å–æ¶ˆå…¶ä»–ä»»å‹™
        for task in pending:
            task.cancel()
        return result
    return None


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""

    # æ¸¬è©¦æŸ¥è©¢
    test_queries = [
        "Python asyncio best practices",
        "React hooks tutorial",
        "Machine learning algorithms",
        "Docker containerization",
        "GraphQL vs REST API",
        "TypeScript generics"
    ]

    # 1. æ¸¬è©¦æ‰¹æ¬¡å¹³è¡Œæœç´¢
    batch_config = SearchEngineConfig(parallel_strategy="batch", batch_size=3)
    await test_batch_parallel_search(test_queries, batch_config)

    # 2. æ¸¬è©¦ç«¶é€Ÿæ¨¡å¼
    race_config = SearchEngineConfig(parallel_strategy="race")
    await test_race_mode_search(test_queries[0], race_config)

    # 3. æ¸¬è©¦æ··åˆæ¨¡å¼
    hybrid_config = SearchEngineConfig(parallel_strategy="hybrid", batch_size=2)
    await test_hybrid_mode(test_queries[:4], hybrid_config)

    logger.info(f"\n{'='*60}")
    logger.info(f"All tests completed successfully! âœ…")
    logger.info(f"{'='*60}")


if __name__ == "__main__":
    asyncio.run(main())