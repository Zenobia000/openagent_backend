#!/usr/bin/env python3
"""
å¢å¼·ç‰ˆå¼•ç”¨çµ±è¨ˆæ¸¬è©¦
æ¸¬è©¦æ–°å¢çš„è©³ç´°çµ±è¨ˆåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- å¼•ç”¨æ¬¡æ•¸çµ±è¨ˆ
- ç„¡æ•ˆå¼•ç”¨æª¢æ¸¬
- å¼•ç”¨åˆ†ä½ˆåˆ†æ
- æœ€å¸¸å¼•ç”¨æ–‡ç»æ’å
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from core.processor import DeepResearchProcessor


def test_basic_citation_analysis():
    """æ¸¬è©¦åŸºæœ¬å¼•ç”¨åˆ†æåŠŸèƒ½"""
    print("\n" + "=" * 70)
    print("Test 1: Basic Citation Analysis")
    print("=" * 70)

    processor = DeepResearchProcessor(None)

    # æ¸¬è©¦å ±å‘Š - åŒ…å«å¤šæ¬¡å¼•ç”¨åŒä¸€æ–‡ç»
    test_report = """
    ## Introduction
    Recent AI advances [1] have transformed healthcare [2][3].
    Deep learning [1] is particularly important [4].

    ## Applications
    Medical imaging [1][2] shows great promise.
    Drug discovery [5] is accelerating [1].
    """

    test_references = [
        {'id': 1, 'title': 'AI in Healthcare 2024', 'url': 'http://example1.com'},
        {'id': 2, 'title': 'Medical Imaging AI', 'url': 'http://example2.com'},
        {'id': 3, 'title': 'Healthcare Transformation', 'url': 'http://example3.com'},
        {'id': 4, 'title': 'Deep Learning Primer', 'url': 'http://example4.com'},
        {'id': 5, 'title': 'AI Drug Discovery', 'url': 'http://example5.com'},
        {'id': 6, 'title': 'Uncited Paper', 'url': 'http://example6.com'},
    ]

    cited_refs, uncited_refs, stats = processor._analyze_citations(test_report, test_references)

    print(f"\nâœ… Results:")
    print(f"  - Cited: {len(cited_refs)} sources")
    print(f"  - Uncited: {len(uncited_refs)} sources")
    print(f"  - Total citations: {stats['total_citations']}")
    print(f"  - Avg per source: {stats['avg_citations_per_source']:.2f}")

    print(f"\nğŸ† Citation Ranking:")
    for ref in cited_refs:
        print(f"  [{ref['id']}] {ref['title']} - Ã—{ref['citation_count']}")

    # é©—è­‰
    assert len(cited_refs) == 5, "Should have 5 cited references"
    assert len(uncited_refs) == 1, "Should have 1 uncited reference"
    assert stats['total_citations'] == 9, "Should have 9 total citations ([1]Ã—4 + [2]Ã—2 + [3]Ã—1 + [4]Ã—1 + [5]Ã—1)"
    assert cited_refs[0]['citation_count'] == 4, "Ref [1] should be cited 4 times"

    print("\nâœ… Test 1 PASSED!")


def test_invalid_citations():
    """æ¸¬è©¦ç„¡æ•ˆå¼•ç”¨æª¢æ¸¬"""
    print("\n" + "=" * 70)
    print("Test 2: Invalid Citation Detection")
    print("=" * 70)

    processor = DeepResearchProcessor(None)

    # æ¸¬è©¦å ±å‘Š - åŒ…å«ç„¡æ•ˆå¼•ç”¨ç·¨è™Ÿ
    test_report = """
    Recent research [1][2] shows promising results.
    However, some studies [99] contradict this [100][3].
    Further investigation is needed [999].
    """

    test_references = [
        {'id': 1, 'title': 'Valid Paper 1', 'url': 'http://example1.com'},
        {'id': 2, 'title': 'Valid Paper 2', 'url': 'http://example2.com'},
        {'id': 3, 'title': 'Valid Paper 3', 'url': 'http://example3.com'},
        {'id': 4, 'title': 'Uncited Valid Paper', 'url': 'http://example4.com'},
    ]

    cited_refs, uncited_refs, stats = processor._analyze_citations(test_report, test_references)

    print(f"\nâš ï¸  Invalid Citations Detected:")
    print(f"  - Count: {len(stats['invalid_citations'])}")
    print(f"  - IDs: {stats['invalid_citations']}")

    print(f"\nâœ… Valid Citations:")
    for ref in cited_refs:
        print(f"  [{ref['id']}] {ref['title']}")

    # é©—è­‰
    assert len(stats['invalid_citations']) == 3, "Should detect 3 invalid citations"
    assert 99 in stats['invalid_citations'], "Should detect [99]"
    assert 100 in stats['invalid_citations'], "Should detect [100]"
    assert 999 in stats['invalid_citations'], "Should detect [999]"
    assert len(cited_refs) == 3, "Should have 3 valid cited references"

    print("\nâœ… Test 2 PASSED!")


def test_citation_distribution():
    """æ¸¬è©¦å¼•ç”¨åˆ†ä½ˆçµ±è¨ˆ"""
    print("\n" + "=" * 70)
    print("Test 3: Citation Distribution Analysis")
    print("=" * 70)

    processor = DeepResearchProcessor(None)

    # æ¸¬è©¦å ±å‘Š - ä¸å‡å‹»çš„å¼•ç”¨åˆ†ä½ˆ
    test_report = """
    # Highly Cited Papers
    The seminal work [1][1][1][1][1] is foundational.

    # Moderately Cited
    Related studies [2][2][2] and [3][3] support this.

    # Single Citations
    Additional research [4][5][6][7] provides context.
    """

    test_references = [
        {'id': 1, 'title': 'Seminal Work', 'url': 'http://example1.com'},
        {'id': 2, 'title': 'Supporting Study 1', 'url': 'http://example2.com'},
        {'id': 3, 'title': 'Supporting Study 2', 'url': 'http://example3.com'},
        {'id': 4, 'title': 'Context Paper 1', 'url': 'http://example4.com'},
        {'id': 5, 'title': 'Context Paper 2', 'url': 'http://example5.com'},
        {'id': 6, 'title': 'Context Paper 3', 'url': 'http://example6.com'},
        {'id': 7, 'title': 'Context Paper 4', 'url': 'http://example7.com'},
        {'id': 8, 'title': 'Not Cited', 'url': 'http://example8.com'},
    ]

    cited_refs, uncited_refs, stats = processor._analyze_citations(test_report, test_references)

    print(f"\nğŸ“Š Citation Distribution:")
    print(f"  - Total citations: {stats['total_citations']}")
    print(f"  - Unique sources: {stats['unique_citations']}")
    print(f"  - Average: {stats['avg_citations_per_source']:.2f} citations/source")

    print(f"\nğŸ† Top 5 Most Cited:")
    for ref_id, count in stats['most_cited']:
        title = next(r['title'] for r in test_references if r['id'] == ref_id)
        print(f"  [{ref_id}] {title}: {count} times")

    print(f"\nğŸ“ˆ Full Distribution:")
    for ref_id, count in sorted(stats['citation_distribution'].items(), key=lambda x: x[1], reverse=True):
        title = next(r['title'] for r in test_references if r['id'] == ref_id)
        bar = "â–ˆ" * count
        print(f"  [{ref_id:2d}] {bar} ({count})")

    # é©—è­‰
    assert stats['total_citations'] == 14, "Should have 14 total citations"
    assert stats['unique_citations'] == 7, "Should have 7 unique citations"
    assert stats['most_cited'][0] == (1, 5), "Ref [1] should be most cited with 5 citations"
    assert stats['most_cited'][1] == (2, 3), "Ref [2] should be second with 3 citations"

    print("\nâœ… Test 3 PASSED!")


def test_formatted_output():
    """æ¸¬è©¦æ ¼å¼åŒ–è¼¸å‡º"""
    print("\n" + "=" * 70)
    print("Test 4: Enhanced Formatted Output")
    print("=" * 70)

    processor = DeepResearchProcessor(None)

    test_report = """
    ## Research Summary
    Multiple studies [1][2][3] demonstrate effectiveness.
    Key findings [1][4] are significant.
    """

    test_references = [
        {'id': 1, 'title': 'Primary Study', 'url': 'http://example1.com', 'query': 'main research'},
        {'id': 2, 'title': 'Supporting Study', 'url': 'http://example2.com'},
        {'id': 3, 'title': 'Related Work', 'url': 'http://example3.com'},
        {'id': 4, 'title': 'Key Findings', 'url': 'http://example4.com'},
        {'id': 5, 'title': 'Background Paper', 'url': 'http://example5.com'},
    ]

    cited_refs, uncited_refs, stats = processor._analyze_citations(test_report, test_references)
    formatted = processor._format_report_with_categorized_references(
        test_report, cited_refs, uncited_refs, citation_stats=stats
    )

    print(f"\nğŸ“„ Formatted Report Preview:")
    print("-" * 70)

    # é¡¯ç¤ºå¼•ç”¨çµ±è¨ˆéƒ¨åˆ†
    stats_start = formatted.find("## ğŸ“Š å¼•ç”¨çµ±è¨ˆ")
    if stats_start > -1:
        print(formatted[stats_start:stats_start+1000])

    # é©—è­‰æ ¼å¼åŒ–è¼¸å‡ºåŒ…å«æ‰€éœ€å…ƒç´ 
    assert "ğŸ“š åƒè€ƒæ–‡ç» (Cited References)" in formatted
    assert "ğŸ“– ç›¸é—œæ–‡ç» (Related Sources - Not Cited)" in formatted
    assert "ğŸ“Š å¼•ç”¨çµ±è¨ˆ (Citation Statistics)" in formatted
    assert "åŸºæœ¬æŒ‡æ¨™" in formatted
    assert "å¼•ç”¨æ·±åº¦åˆ†æ" in formatted
    assert "ç¸½å¼•ç”¨æ¬¡æ•¸" in formatted
    assert "å¹³å‡æ¯ç¯‡æ–‡ç»è¢«å¼•ç”¨" in formatted
    assert "æœ€å¸¸å¼•ç”¨" in formatted
    assert "Ã—2" in formatted  # Citation count indicator for ref [1]

    print("\nâœ… Test 4 PASSED!")


def main():
    """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
    print("\n" + "ğŸš€" * 35)
    print("Enhanced Citation Statistics Test Suite")
    print("å¢å¼·ç‰ˆå¼•ç”¨çµ±è¨ˆæ¸¬è©¦å¥—ä»¶")
    print("ğŸš€" * 35)

    try:
        test_basic_citation_analysis()
        test_invalid_citations()
        test_citation_distribution()
        test_formatted_output()

        print("\n" + "=" * 70)
        print("ğŸ‰ ALL TESTS PASSED! æ‰€æœ‰æ¸¬è©¦é€šéï¼")
        print("=" * 70)

        print("\nâœ… å¢å¼·åŠŸèƒ½é©—è­‰å®Œæˆï¼š")
        print("  âœ“ å¼•ç”¨æ¬¡æ•¸è¿½è¹¤")
        print("  âœ“ ç„¡æ•ˆå¼•ç”¨æª¢æ¸¬")
        print("  âœ“ å¼•ç”¨åˆ†ä½ˆåˆ†æ")
        print("  âœ“ æœ€å¸¸å¼•ç”¨æ’å")
        print("  âœ“ è©³ç´°çµ±è¨ˆè¼¸å‡º")

    except AssertionError as e:
        print(f"\nâŒ TEST FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False
    except Exception as e:
        print(f"\nâŒ ERROR: {e}")
        import traceback
        traceback.print_exc()
        return False

    return True


if __name__ == "__main__":
    import sys
    success = main()
    sys.exit(0 if success else 1)
