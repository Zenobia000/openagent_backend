#!/usr/bin/env python
"""
æ¸¬è©¦å¢å¼·ç‰ˆ DeepResearchProcessor
æ¼”ç¤º SSE Streamingã€å¤šæœç´¢å¼•æ“é…ç½®å’Œäº‹ä»¶é©…å‹•æ¶æ§‹
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from core.enhanced_deep_research import (
    EnhancedDeepResearchProcessor,
    SearchEngineConfig,
    SearchProviderType,
    ResearchEvent
)
from core.models import ProcessingContext, Request, Response, ProcessingMode


class ResearchEventHandler:
    """ç ”ç©¶äº‹ä»¶è™•ç†å™¨ - æ¨¡æ“¬å‰ç«¯äº‹ä»¶è™•ç†"""

    def __init__(self):
        self.events = []
        self.start_time = None

    async def handle_event(self, event: ResearchEvent):
        """è™•ç†ç ”ç©¶äº‹ä»¶"""
        if self.start_time is None:
            self.start_time = datetime.now()

        elapsed = (datetime.now() - self.start_time).total_seconds()
        self.events.append(event)

        # æ ¹æ“šäº‹ä»¶é¡å‹è™•ç†
        if event.type == "progress":
            print(f"\nâ±ï¸ [{elapsed:.1f}s] Progress: {event.step} - {event.data.get('status')}")
            if 'message' in event.data:
                print(f"   ğŸ“¢ {event.data['message']}")

        elif event.type == "message":
            content = event.data.get('content', '')
            if len(content) > 200:
                print(f"\nğŸ“ [{elapsed:.1f}s] {event.step}: {content[:200]}...")
            else:
                print(f"\nğŸ“ [{elapsed:.1f}s] {event.step}: {content}")

        elif event.type == "reasoning":
            print(f"\nğŸ¤” [{elapsed:.1f}s] Reasoning: {event.data.get('message')}")

        elif event.type == "search_result":
            print(f"\nğŸ” [{elapsed:.1f}s] Search Result:")
            print(f"   Query: {event.data.get('query')}")
            print(f"   Sources: {event.data.get('sources_count')}")

        elif event.type == "error":
            print(f"\nâŒ [{elapsed:.1f}s] Error: {event.data}")


async def test_streaming_research():
    """æ¸¬è©¦ SSE Streaming åŠŸèƒ½"""
    print("=" * 60)
    print("Testing SSE Streaming Support")
    print("=" * 60)

    # å‰µå»ºäº‹ä»¶è™•ç†å™¨
    event_handler = ResearchEventHandler()

    # é…ç½®æœç´¢å¼•æ“ï¼ˆæ¨¡æ“¬ï¼‰
    search_config = SearchEngineConfig(
        primary=SearchProviderType.TAVILY,
        fallback_chain=[
            SearchProviderType.SERPER,
            SearchProviderType.DUCKDUCKGO,
            SearchProviderType.MODEL
        ],
        max_results=5,
        parallel_searches=2
    )

    # å‰µå»ºè™•ç†å™¨
    processor = EnhancedDeepResearchProcessor(
        llm_client=None,  # æ¨¡æ“¬æ¨¡å¼
        services={},  # ç„¡çœŸå¯¦æœå‹™
        search_config=search_config,
        event_callback=event_handler.handle_event
    )

    # å•Ÿç”¨ streaming
    processor.enable_streaming(True)

    # æ¸¬è©¦æŸ¥è©¢
    test_query = "What are the latest breakthroughs in quantum computing?"
    context = ProcessingContext(
        request=Request(query=test_query),
        response=Response(
            result="",
            mode=ProcessingMode.DEEP_RESEARCH,
            trace_id="test-001"
        )
    )

    print(f"\nğŸš€ Starting research: {test_query}")
    print("-" * 50)

    try:
        # æ¨¡æ“¬ streaming è™•ç†
        async for sse_event in processor.process_with_streaming(context):
            # é€™è£¡æœƒè¼¸å‡º SSE æ ¼å¼çš„äº‹ä»¶
            if sse_event.startswith("data:"):
                print(f"\nğŸ“¡ SSE Event: {sse_event[:100]}...")

    except Exception as e:
        print(f"\nâŒ Error during streaming: {e}")

    # æ‰“å°äº‹ä»¶çµ±è¨ˆ
    print("\n" + "=" * 60)
    print("Event Statistics:")
    print("-" * 50)
    event_types = {}
    for event in event_handler.events:
        event_types[event.type] = event_types.get(event.type, 0) + 1

    for event_type, count in event_types.items():
        print(f"  {event_type}: {count} events")

    print(f"\nTotal events: {len(event_handler.events)}")
    print(f"Total time: {(datetime.now() - event_handler.start_time).total_seconds():.1f}s")


async def test_search_engine_fallback():
    """æ¸¬è©¦æœç´¢å¼•æ“é™ç´šæ©Ÿåˆ¶"""
    print("\n" + "=" * 60)
    print("Testing Search Engine Fallback")
    print("=" * 60)

    # é…ç½®æœç´¢å¼•æ“éˆ
    search_config = SearchEngineConfig(
        primary=SearchProviderType.TAVILY,  # å‡è¨­é€™å€‹æœƒå¤±æ•—
        fallback_chain=[
            SearchProviderType.SERPER,    # ç¬¬ä¸€å‚™é¸
            SearchProviderType.BRAVE,      # ç¬¬äºŒå‚™é¸
            SearchProviderType.MODEL       # æœ€çµ‚é™ç´šåˆ°æ¨¡å‹
        ],
        max_results=3,
        timeout=5.0
    )

    # å‰µå»ºè™•ç†å™¨
    processor = EnhancedDeepResearchProcessor(
        llm_client=None,  # æœƒè§¸ç™¼ MODEL fallback
        services={},  # ç„¡çœŸå¯¦æœç´¢æœå‹™ï¼Œæœƒè§¸ç™¼ fallback
        search_config=search_config
    )

    print(f"\nğŸ“‹ Search Configuration:")
    print(f"  Primary: {search_config.primary.value}")
    print(f"  Fallback chain: {[p.value for p in search_config.fallback_chain]}")
    print(f"  Timeout: {search_config.timeout}s")

    # æ¸¬è©¦æœç´¢
    test_query = "quantum computing applications"
    search_result = await processor._perform_deep_search(
        query=test_query,
        goal="Find practical applications"
    )

    print(f"\nâœ… Search completed:")
    print(f"  Provider: {search_result.get('provider', 'unknown')}")
    print(f"  Sources: {len(search_result.get('sources', []))}")
    print(f"  Has summary: {'summary' in search_result}")


async def test_parallel_search_execution():
    """æ¸¬è©¦ä¸¦è¡Œæœç´¢åŸ·è¡Œ"""
    print("\n" + "=" * 60)
    print("Testing Parallel Search Execution")
    print("=" * 60)

    # é…ç½®ä¸¦è¡Œæœç´¢
    search_config = SearchEngineConfig(
        primary=SearchProviderType.MODEL,
        parallel_searches=3,  # åŒæ™‚åŸ·è¡Œ3å€‹æœç´¢
        max_results=5
    )

    # å‰µå»ºè™•ç†å™¨
    processor = EnhancedDeepResearchProcessor(
        llm_client=None,
        services={},
        search_config=search_config
    )

    # å‰µå»ºå¤šå€‹æœç´¢ä»»å‹™
    search_tasks = [
        {"query": "quantum computing basics", "researchGoal": "Understand fundamentals", "priority": 1},
        {"query": "quantum algorithms", "researchGoal": "Learn about algorithms", "priority": 2},
        {"query": "quantum hardware", "researchGoal": "Explore hardware", "priority": 1},
        {"query": "quantum applications", "researchGoal": "Find applications", "priority": 3},
        {"query": "quantum challenges", "researchGoal": "Identify challenges", "priority": 2},
    ]

    print(f"\nğŸ“‹ Test Setup:")
    print(f"  Total tasks: {len(search_tasks)}")
    print(f"  Parallel limit: {search_config.parallel_searches}")
    print(f"  Expected batches: {(len(search_tasks) + search_config.parallel_searches - 1) // search_config.parallel_searches}")

    context = ProcessingContext(
        request=Request(query="test"),
        response=Response(
            result="",
            mode=ProcessingMode.DEEP_RESEARCH,
            trace_id="test-002"
        )
    )

    start_time = datetime.now()
    results = await processor._execute_search_tasks(context, search_tasks)
    elapsed = (datetime.now() - start_time).total_seconds()

    print(f"\nâœ… Execution completed:")
    print(f"  Time taken: {elapsed:.2f}s")
    print(f"  Results: {len(results)}")
    print(f"  Success rate: {sum(1 for r in results if r['result'].get('sources')) / len(results) * 100:.1f}%")


async def test_event_callback_system():
    """æ¸¬è©¦äº‹ä»¶å›èª¿ç³»çµ±"""
    print("\n" + "=" * 60)
    print("Testing Event Callback System")
    print("=" * 60)

    # è‡ªå®šç¾©äº‹ä»¶è™•ç†å™¨
    class CustomEventProcessor:
        def __init__(self):
            self.plan_events = []
            self.search_events = []
            self.report_events = []

        def process_event(self, event: ResearchEvent):
            """åˆ†é¡è™•ç†äº‹ä»¶"""
            if event.step == "plan":
                self.plan_events.append(event)
                print(f"ğŸ“ Plan Event: {event.type}")
            elif "search" in event.step:
                self.search_events.append(event)
                print(f"ğŸ” Search Event: {event.type} - {event.step}")
            elif event.step == "final_report":
                self.report_events.append(event)
                print(f"ğŸ“‘ Report Event: {event.type}")

    # å‰µå»ºäº‹ä»¶è™•ç†å™¨
    event_processor = CustomEventProcessor()

    # å‰µå»ºè™•ç†å™¨ä¸¦è¨­ç½®å›èª¿
    processor = EnhancedDeepResearchProcessor(
        llm_client=None,
        services={},
        event_callback=event_processor.process_event
    )

    # æ¨¡æ“¬ç™¼é€äº‹ä»¶
    test_events = [
        ResearchEvent(type="progress", step="plan", data={"status": "start"}),
        ResearchEvent(type="message", step="plan", data={"content": "Test plan"}),
        ResearchEvent(type="progress", step="search", data={"status": "start"}),
        ResearchEvent(type="search_result", step="search", data={"sources_count": 5}),
        ResearchEvent(type="progress", step="final_report", data={"status": "start"}),
        ResearchEvent(type="message", step="final_report", data={"content": "Test report"}),
    ]

    print("\nğŸ“¡ Sending test events...")
    for event in test_events:
        await processor._emit_event(event)

    # ç­‰å¾…äº‹ä»¶è™•ç†
    await asyncio.sleep(0.1)

    print(f"\nğŸ“Š Event Statistics:")
    print(f"  Plan events: {len(event_processor.plan_events)}")
    print(f"  Search events: {len(event_processor.search_events)}")
    print(f"  Report events: {len(event_processor.report_events)}")


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("\nğŸš€ Enhanced Deep Research Processor Tests")
    print("=" * 80)

    # Test 1: Streaming
    # await test_streaming_research()

    # Test 2: Search Engine Fallback
    await test_search_engine_fallback()

    # Test 3: Parallel Search
    await test_parallel_search_execution()

    # Test 4: Event Callbacks
    await test_event_callback_system()

    print("\n" + "=" * 80)
    print("ğŸ‰ All Tests Completed!")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())