#!/usr/bin/env python
"""
Test script for verifying reference categorization in DeepResearchProcessor
æ¸¬è©¦ DeepResearchProcessor çš„åƒè€ƒæ–‡ç»åˆ†é¡åŠŸèƒ½
"""

import asyncio
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from core.processor import DeepResearchProcessor
from core.models_v2 import ProcessingContext, Request
from core.errors import ErrorClassifier


async def test_reference_categorization():
    """æ¸¬è©¦åƒè€ƒæ–‡ç»çš„å¼•ç”¨åˆ†é¡åŠŸèƒ½"""
    print("=" * 60)
    print("Testing Reference Categorization in Deep Research")
    print("=" * 60)

    # å‰µå»ºè™•ç†å™¨å¯¦ä¾‹ï¼ˆæ¨¡æ“¬æ¨¡å¼ï¼‰
    processor = DeepResearchProcessor(
        llm_client=None,
        services={}
    )

    # æ¸¬è©¦æ¡ˆä¾‹ï¼šç ”ç©¶ AI ç™¼å±•è¶¨å‹¢
    test_query = "åˆ†æäººå·¥æ™ºæ…§åœ¨é†«ç™‚é ˜åŸŸçš„æœ€æ–°æ‡‰ç”¨èˆ‡æœªä¾†ç™¼å±•è¶¨å‹¢"

    context = ProcessingContext(
        request=Request(query=test_query)
    )

    try:
        print(f"\nğŸ“ Research Query: {test_query}")
        print("-" * 50)

        # åŸ·è¡Œæ·±åº¦ç ”ç©¶
        result = await processor.process(context)

        # é©—è­‰çµæœ
        print("\nâœ… Research completed successfully!")
        print("-" * 50)

        # æª¢æŸ¥æ˜¯å¦åŒ…å«å¼•ç”¨åˆ†é¡
        if "ğŸ“š åƒè€ƒæ–‡ç» (Cited References)" in result:
            print("âœ“ Found cited references section")
        else:
            print("âœ— Cited references section missing")

        if "ğŸ“– ç›¸é—œæ–‡ç» (Related Sources - Not Cited)" in result:
            print("âœ“ Found uncited sources section")
        else:
            print("âœ— Uncited sources section missing")

        if "ğŸ“Š å¼•ç”¨çµ±è¨ˆ (Citation Statistics)" in result:
            print("âœ“ Found citation statistics")
        else:
            print("âœ— Citation statistics missing")

        # è§£æå¼•ç”¨çµ±è¨ˆ
        import re
        cited_match = re.search(r"å¯¦éš›å¼•ç”¨æ–‡ç»:\s*(\d+)", result)
        uncited_match = re.search(r"ç›¸é—œæœªå¼•ç”¨æ–‡ç»:\s*(\d+)", result)
        citation_rate = re.search(r"å¼•ç”¨ç‡:\s*([\d.]+)%", result)

        if cited_match and uncited_match and citation_rate:
            cited_count = int(cited_match.group(1))
            uncited_count = int(uncited_match.group(1))
            rate = float(citation_rate.group(1))

            print(f"\nğŸ“Š Citation Statistics:")
            print(f"  - Cited references: {cited_count}")
            print(f"  - Uncited references: {uncited_count}")
            print(f"  - Citation rate: {rate}%")
            print(f"  - Total sources: {cited_count + uncited_count}")

        # æª¢æŸ¥ workflow state
        if "workflow_state" in context.intermediate_results:
            state = context.intermediate_results["workflow_state"]
            print(f"\nğŸ”„ Workflow Statistics:")
            print(f"  - Status: {state.get('status')}")
            print(f"  - Iterations: {state.get('iterations', 0)}")
            print(f"  - Steps completed: {state.get('steps', [])}")

        # è¼¸å‡ºå ±å‘Šæ‘˜è¦
        print("\nğŸ“‘ Report Preview (first 500 chars):")
        print("-" * 50)
        print(result[:500] + "...")

        # è¼¸å‡ºåƒè€ƒæ–‡ç»éƒ¨åˆ†é è¦½
        ref_section_start = result.find("## ğŸ“š åƒè€ƒæ–‡ç»")
        if ref_section_start > -1:
            print("\nğŸ“š References Section Preview:")
            print("-" * 50)
            print(result[ref_section_start:ref_section_start+800] + "...")

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        error_category = ErrorClassifier.classify(e)
        print(f"Error Category: {error_category}")

        # æ‰“å°éŒ¯èª¤è©³æƒ…
        if hasattr(e, 'error_context'):
            print(f"Error Context: {e.error_context}")

        import traceback
        traceback.print_exc()
        return False

    print("\n" + "=" * 60)
    print("Test Completed Successfully! âœ…")
    print("=" * 60)
    return True


async def test_citation_analysis():
    """æ¸¬è©¦å¼•ç”¨åˆ†æåŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("Testing Citation Analysis Function")
    print("=" * 60)

    # å‰µå»ºæ¸¬è©¦ç”¨çš„è™•ç†å™¨
    processor = DeepResearchProcessor(None)

    # æ¸¬è©¦å ±å‘Šæ–‡æœ¬
    test_report = """
    ## Introduction

    Recent advances in AI have shown remarkable progress [1]. Machine learning
    techniques, particularly deep learning [2], have revolutionized many fields.

    ## Medical Applications

    AI is being used for disease diagnosis [3] and drug discovery [4][5].
    Some promising applications include medical imaging [1] and patient monitoring.

    ## Future Trends

    Experts predict continued growth [6] in AI applications.
    """

    # æ¸¬è©¦åƒè€ƒæ–‡ç»åˆ—è¡¨
    test_references = [
        {'id': 1, 'title': 'AI Progress Report 2024', 'url': 'http://example1.com'},
        {'id': 2, 'title': 'Deep Learning Review', 'url': 'http://example2.com'},
        {'id': 3, 'title': 'AI in Diagnosis', 'url': 'http://example3.com'},
        {'id': 4, 'title': 'Drug Discovery with ML', 'url': 'http://example4.com'},
        {'id': 5, 'title': 'Pharmaceutical AI', 'url': 'http://example5.com'},
        {'id': 6, 'title': 'Future of AI', 'url': 'http://example6.com'},
        {'id': 7, 'title': 'Uncited Paper 1', 'url': 'http://example7.com'},
        {'id': 8, 'title': 'Uncited Paper 2', 'url': 'http://example8.com'},
    ]

    # åˆ†æå¼•ç”¨ï¼ˆå¢å¼·ç‰ˆï¼‰
    cited_refs, uncited_refs, citation_stats = processor._analyze_citations(test_report, test_references)

    print(f"\nğŸ“Š Basic Analysis Results:")
    print(f"  - Cited references: {len(cited_refs)}")
    print(f"  - Uncited references: {len(uncited_refs)}")

    print(f"\nğŸ“ˆ Enhanced Statistics:")
    print(f"  - Total citations: {citation_stats['total_citations']}")
    print(f"  - Unique citations: {citation_stats['unique_citations']}")
    print(f"  - Avg citations per source: {citation_stats['avg_citations_per_source']:.1f}")
    print(f"  - Invalid citations: {citation_stats['invalid_citations']}")

    print(f"\nğŸ† Most Cited (Top 5):")
    for ref_id, count in citation_stats['most_cited']:
        ref_title = next((r['title'] for r in test_references if r['id'] == ref_id), 'Unknown')
        print(f"  [{ref_id}] {ref_title} - {count} times")

    print(f"\nâœ… Cited References (sorted by citation count):")
    for ref in cited_refs:
        citation_count = ref.get('citation_count', 0)
        print(f"  [{ref['id']}] {ref['title']} (Ã—{citation_count})")

    print(f"\nğŸ“– Uncited References:")
    for ref in uncited_refs:
        print(f"  â€¢ {ref['title']}")

    # æ ¼å¼åŒ–å®Œæ•´å ±å‘Šï¼ˆå¢å¼·ç‰ˆï¼‰
    formatted_report = processor._format_report_with_categorized_references(
        test_report, cited_refs, uncited_refs, citation_stats=citation_stats
    )

    print(f"\nğŸ“‘ Formatted Report Length: {len(formatted_report)} chars")

    # é©—è­‰æ ¼å¼
    assert "ğŸ“š åƒè€ƒæ–‡ç» (Cited References)" in formatted_report
    assert "ğŸ“– ç›¸é—œæ–‡ç» (Related Sources - Not Cited)" in formatted_report
    assert "ğŸ“Š å¼•ç”¨çµ±è¨ˆ (Citation Statistics)" in formatted_report

    print("\nâœ… Citation Analysis Test Passed!")
    return True


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("\nğŸš€ Starting Reference Categorization Tests")
    print("=" * 80)

    # Test 1: å¼•ç”¨åˆ†æåŠŸèƒ½
    test1_result = await test_citation_analysis()

    # Test 2: å®Œæ•´çš„æ·±åº¦ç ”ç©¶æµç¨‹
    print("\n" + "=" * 80)
    print("Note: Full deep research test requires real LLM services")
    print("Skipping full integration test in mock mode...")
    # test2_result = await test_reference_categorization()

    print("\n" + "=" * 80)
    print("ğŸ‰ All Tests Completed!")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())