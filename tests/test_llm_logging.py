#!/usr/bin/env python3
"""
æ¸¬è©¦ LLM Call å’Œ LLM Response çš„å€åˆ¥
"""

import asyncio
from unittest.mock import AsyncMock, MagicMock
from src.core.processor import ThinkingProcessor
from src.core.models import Request, Response, ProcessingContext
from src.core.logger import structured_logger

async def test_llm_logging():
    """æ¸¬è©¦ LLM æ—¥èªŒè¼¸å‡º"""

    print("=" * 80)
    print("ğŸ§ª æ¸¬è©¦ LLM Call å’Œ LLM Response æ—¥èªŒ")
    print("=" * 80)
    print()

    # å‰µå»º mock LLM client
    mock_llm = AsyncMock()

    # æ¨¡æ“¬ LLM å›æ‡‰
    mock_response = """## Deep Analysis of the Query

This is a comprehensive response from the LLM that includes:
1. Problem understanding
2. Critical analysis
3. Deep reasoning
4. Synthesis and conclusion

The response demonstrates how the LLM processes and responds to queries with detailed analysis and structured output."""

    # è¨­ç½® mock è¿”å›å€¼ (åŒ…å« token è³‡è¨Š)
    mock_llm.generate.return_value = (
        mock_response,
        {
            "prompt_tokens": 125,
            "completion_tokens": 89,
            "total_tokens": 214
        }
    )

    # å‰µå»ºè™•ç†å™¨
    processor = ThinkingProcessor(structured_logger)
    processor.llm_client = mock_llm

    # å‰µå»ºè«‹æ±‚ä¸Šä¸‹æ–‡
    request = Request(query="æ¸¬è©¦æŸ¥è©¢ï¼šLLM æ—¥èªŒå€åˆ¥", mode="thinking")
    response = Response(result="", mode="thinking", trace_id="test-trace-123")
    context = ProcessingContext(request=request, response=response)

    print("ğŸ“ ç™¼é€æ¸¬è©¦æŸ¥è©¢...")
    print("-" * 40)

    # èª¿ç”¨ _call_llm
    response = await processor._call_llm("Test prompt for LLM logging", context)

    print("\n" + "=" * 80)
    print("âœ… æ¸¬è©¦çµæœèªªæ˜ï¼š")
    print("-" * 40)
    print()
    print("ä½ æ‡‰è©²çœ‹åˆ°å…©ç¨®ä¸åŒçš„æ—¥èªŒï¼š")
    print()
    print("1. ğŸ¤– LLM Call: gpt-4o")
    print("   - é¡¯ç¤º token æ•¸é‡ (tokens=214)")
    print("   - é¡¯ç¤ºåŸ·è¡Œæ™‚é–“ (time=XXXms)")
    print("   - ç”¨æ–¼æ€§èƒ½ç›£æ§")
    print()
    print("2. ğŸ’¬ LLM Response: ## Deep Analysis...")
    print("   - é¡¯ç¤ºå¯¦éš›ç”Ÿæˆçš„å…§å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰")
    print("   - ç”¨æ–¼èª¿è©¦å’Œè¿½è¹¤ LLM è¼¸å‡º")
    print()
    print("é€™å…©ç¨®æ—¥èªŒæœå‹™ä¸åŒçš„ç›®çš„ï¼Œéƒ½æ˜¯èª¿è©¦å’Œç›£æ§æ‰€å¿…éœ€çš„ã€‚")
    print("=" * 80)

if __name__ == "__main__":
    asyncio.run(test_llm_logging())