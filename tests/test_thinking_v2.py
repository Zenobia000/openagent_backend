#!/usr/bin/env python3
"""
æ¸¬è©¦ Thinking æ¨¡å¼ - é©—è­‰åˆ†éšæ®µåœ¨æ—¥èªŒä¸­è¼¸å‡ºï¼Œæœ€çµ‚åªè¿”å›çµæœ
"""

import asyncio
from src.core.engine import RefactoredEngine
from src.services.llm.openai_client import OpenAILLMClient
from src.core.models import ProcessingMode, Request
from src.core.logger import structured_logger
import os
import time

async def test_thinking_mode():
    """æ¸¬è©¦ thinking æ¨¡å¼çš„æ–°è¼¸å‡ºçµæ§‹"""

    print("=" * 80)
    print("ğŸ§ª æ¸¬è©¦ Thinking æ¨¡å¼ - åˆ†éšæ®µæ—¥èªŒ + æœ€çµ‚çµæœè¼¸å‡º")
    print("=" * 80)

    # åˆå§‹åŒ– LLM å®¢æˆ¶ç«¯
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âš ï¸  ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼ (ç„¡ API Key)")
        llm_client = None
    else:
        print("âœ… ä½¿ç”¨çœŸå¯¦ OpenAI API")
        llm_client = OpenAILLMClient(api_key=api_key)

    # åˆå§‹åŒ–å¼•æ“
    engine = RefactoredEngine(llm_client=llm_client)

    # æº–å‚™æ¸¬è©¦æŸ¥è©¢
    test_query = "ä»€éº¼æ˜¯é‡å­è¨ˆç®—ï¼Ÿ"

    print(f"\nğŸ“ æ¸¬è©¦æŸ¥è©¢: {test_query}")
    print("-" * 80)

    # å‰µå»ºè«‹æ±‚
    request = Request(
        query=test_query,
        mode=ProcessingMode.THINKING,
        context={}
    )

    # æ¨¡æ“¬ç›£è½æ—¥èªŒè¼¸å‡º
    class LogMonitor:
        def __init__(self):
            self.logs = []

        def capture(self, message):
            timestamp = time.strftime("%H:%M:%S")
            self.logs.append(f"[{timestamp}] {message}")
            # å³æ™‚é¡¯ç¤ºæ—¥èªŒ
            print(f"ğŸ“‹ LOG: {message[:100]}..." if len(message) > 100 else f"ğŸ“‹ LOG: {message}")

    monitor = LogMonitor()

    print("\nğŸš€ é–‹å§‹è™•ç†...")
    print("-" * 80)
    print("ğŸ“Š æ€è€ƒéç¨‹å°‡åœ¨æ—¥èªŒä¸­é¡¯ç¤º:")
    print()

    try:
        # è™•ç†è«‹æ±‚
        start_time = time.time()
        response = await engine.process_request(request)
        end_time = time.time()

        print("\n" + "=" * 80)
        print("âœ¨ æœ€çµ‚å›æ‡‰ (åªåŒ…å«çµæœ):")
        print("=" * 80)
        print(response.response)

        print("\n" + "=" * 80)
        print("ğŸ“Š è™•ç†çµ±è¨ˆ:")
        print(f"  - ç¸½ Token ä½¿ç”¨: {response.context.total_tokens}")
        print(f"  - è™•ç†æ™‚é–“: {end_time - start_time:.2f} ç§’")
        print("=" * 80)

        # é¡¯ç¤ºæ—¥èªŒæ‘˜è¦
        print("\nğŸ“ æ€è€ƒéšæ®µæ—¥èªŒæ‘˜è¦:")
        print("-" * 80)
        # é€™è£¡æ‡‰è©²å¾å¯¦éš›çš„æ—¥èªŒæ–‡ä»¶è®€å–ï¼Œå±•ç¤ºå„éšæ®µçš„æ—¥èªŒ
        log_file = f"logs/opencode_{time.strftime('%Y%m%d')}.log"
        if os.path.exists(log_file):
            print(f"è©³ç´°æ—¥èªŒè«‹æŸ¥çœ‹: {log_file}")
        else:
            print("(æ—¥èªŒæ–‡ä»¶æœªæ‰¾åˆ°)")

    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

async def simulate_output_structure():
    """æ¨¡æ“¬å±•ç¤ºç†æƒ³çš„è¼¸å‡ºçµæ§‹"""

    print("\n" + "=" * 80)
    print("ğŸ“– ç†æƒ³è¼¸å‡ºçµæ§‹ç¤ºç¯„")
    print("=" * 80)

    # æ¨¡æ“¬æ—¥èªŒè¼¸å‡º
    stages = [
        ("ğŸ” Stage 1: Problem Understanding", "åˆ†æå•é¡Œæ ¸å¿ƒè¦ç´ ..."),
        ("ğŸ’­ Stage 1 Result", "å•é¡Œç†è§£å®Œæˆï¼Œè­˜åˆ¥å‡ºé—œéµæ¦‚å¿µ..."),
        ("ğŸ” Stage 2: Critical Analysis", "é€²è¡Œæ‰¹åˆ¤æ€§åˆ†æ..."),
        ("ğŸ’­ Stage 2 Result", "å¤šè§’åº¦åˆ†æå®Œæˆï¼Œç™¼ç¾æ½›åœ¨è­°é¡Œ..."),
        ("ğŸ” Stage 3: Deep Reasoning", "æ·±åº¦æ¨ç†é€²è¡Œä¸­..."),
        ("ğŸ’­ Stage 3 Result", "æ¨ç†éˆå»ºç«‹å®Œæˆ..."),
        ("ğŸ” Stage 4: Synthesis", "ç¶œåˆæ‰€æœ‰åˆ†æ..."),
        ("ğŸ’­ Stage 4 Result", "åæ€èˆ‡æ”¹é€²å®Œæˆ..."),
        ("ğŸ¯ Stage 5: Final Answer", "ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ...")
    ]

    print("\nğŸ“‹ æ—¥èªŒè¼¸å‡º (é¡¯ç¤ºæ€è€ƒéç¨‹):")
    print("-" * 40)
    for stage, desc in stages[:-1]:  # é™¤äº†æœ€å¾Œä¸€å€‹éšæ®µ
        print(f"[LOG] {stage}: {desc}")
        await asyncio.sleep(0.5)

    print("\n" + "=" * 40)
    print("âœ¨ æœ€çµ‚å›æ‡‰ (ä½¿ç”¨è€…çœ‹åˆ°çš„):")
    print("=" * 40)
    print("""
é‡å­è¨ˆç®—æ˜¯ä¸€ç¨®åŸºæ–¼é‡å­åŠ›å­¸åŸç†çš„è¨ˆç®—æ–¹å¼ï¼Œèˆ‡å‚³çµ±è¨ˆç®—æœ‰æœ¬è³ªå€åˆ¥ï¼š

1. **åŸºæœ¬å–®ä½**ï¼šä½¿ç”¨é‡å­ä½ï¼ˆqubitï¼‰è€Œéå‚³çµ±ä½å…ƒ
2. **æ ¸å¿ƒç‰¹æ€§**ï¼š
   - ç–ŠåŠ æ…‹ï¼šé‡å­ä½å¯åŒæ™‚è™•æ–¼ 0 å’Œ 1 çš„ç‹€æ…‹
   - ç³¾çºï¼šå¤šå€‹é‡å­ä½å¯ç›¸äº’é—œè¯
   - é‡å­å¹²æ¶‰ï¼šåˆ©ç”¨æ³¢å‡½æ•¸ç‰¹æ€§å„ªåŒ–è¨ˆç®—

3. **æ‡‰ç”¨é ˜åŸŸ**ï¼šå¯†ç¢¼å­¸ã€è—¥ç‰©ç ”ç™¼ã€ææ–™ç§‘å­¸ã€äººå·¥æ™ºæ…§ç­‰

é‡å­è¨ˆç®—æœ‰æœ›è§£æ±ºå‚³çµ±è¨ˆç®—æ©Ÿé›£ä»¥è™•ç†çš„è¤‡é›œå•é¡Œã€‚
""")

async def main():
    """ä¸»å‡½æ•¸"""

    # é¦–å…ˆå±•ç¤ºç†æƒ³çš„è¼¸å‡ºçµæ§‹
    await simulate_output_structure()

    # è©¢å•æ˜¯å¦è¦æ¸¬è©¦å¯¦éš›åŠŸèƒ½
    print("\n" + "=" * 80)
    print("æ˜¯å¦è¦æ¸¬è©¦å¯¦éš›çš„ Thinking æ¨¡å¼ï¼Ÿ(éœ€è¦ OpenAI API Key)")
    print("è¼¸å…¥ 'y' ç¹¼çºŒï¼Œå…¶ä»–ä»»ä½•è¼¸å…¥è·³é")

    if input("> ").lower() == 'y':
        await test_thinking_mode()
    else:
        print("è·³éå¯¦éš›æ¸¬è©¦")

    print("\nâœ¨ æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main())